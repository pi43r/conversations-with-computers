<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Conversations with Computers</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  
</head>
<body>
<header id="title-block-header">
<h1 class="title">Conversations with Computers</h1>
</header>
<h1 id="hello-world">Hello, World!</h1>
<p>The common first letters a programmer types into its digital computing machine is some form of ‘hello world’ along with braces, punctuation, and words the machine should interpret. In my favorite language, JavaScript, it can look as simple as this <code>console.log(“Hello, World!”)</code>. After executing this short string of text in the browser, the computer will perform a series of events and likewise respond with ‘Hello, World!’ in the developer console.</p>
<p>This ritual of greeting each other (and the world) goes back to Brian W. Kernighan, who wrote the popular guide <em>The C Programming Language</em><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> in 1978, where he proclaims that the only way to learn a programming language is by writing programs in it.</p>
<p>I start this introduction with the same greeting, and as I press these letters on my keyboard, they simultaneously appear on the screen in front of me. This translation from the tactical key press to the pixels on the screen becomes possible through a chain of electrical signals that reach my retina in a matter of milliseconds and close the loop. Thousands of people have created these intricate systems which interoperate and depend on each other, each new layer abstracting underlying operations further. Only the text editor I am using to write these lines already has hundreds of contributors writing thousands of lines of code, which in turn rely on the functions of the operating system created by kernel developers.</p>
<p>This chain of creativity represents the core of open source software development based on collaboration and sharing knowledge. Every contribution, no matter how small or insignificant it may seem, is valuable in creating something more significant than what was there before. Whether it is a bug fix, a feature request, or a new idea - every contribution makes a difference.</p>
<p>In this thesis, I focus on the known and unknown human connections we make with and through computers, specifically in machine learning. My hypothesis is that the current trend of framing ‘Artificial Intelligence’ as autonomous computational beings would be better described as ‘Co-Intelligence,’ where programming such systems is a collaborative effort with many hidden actors. While I address some technical details of current machine learning systems, I will put them into a social context because software inherently is a social tool. To describe the social inheritance, I use my own and other artists’ artworks to gain a broader aesthetic perspective, which can go beyond logic and language.</p>
<p>Even though I focus on the social nature of computing and am influenced by many of my peers, I am describing these topics from my subjective perspective. I don’t claim any objective truths on the descriptions of my collaborative works and am naturally biased toward my contribution to them. As I write this thesis in the context of an art program, I deviate from rigorous scientific methods and describe my observations more freely. Instead of trying to answer the question of the nature of AI as subjective entities, I focus on the practices we developed through the engagement with that question.</p>
<h2 id="dreaming">Dreaming</h2>
<figure>
<img src="6ocuQsZ.jpeg" alt="“PuppySlug” - posted by a deleted user on /r/creepy with the title “This image was generated by a computer on its own (from a friend working on AI)” on January 10th, 2015. Seven days before the Google blog post" /><figcaption aria-hidden="true">“PuppySlug” - posted by a deleted user on /r/creepy with the title “This image was generated by a computer on its own (from a friend working on AI)” on January 10th, 2015. Seven days before the Google blog post</figcaption>
</figure>
<p>My journey into the hype machine of ‘Artificial Intelligence’ started around 2015, when Google released DeepDream<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> on its research blog. The developers Alexander Mordvintsev, Michael Tyka, and Christopher Olah were initially trying to peek inside an ‘Artificial Neural Network’ that was ‘trained’ for image classification tasks. They reversed the task of the classifier, and instead of identifying what a set of pixels look like, the pixel values are changed to look more similar to what the network has ‘learned.’ This created images that amplified the textures embedded in their networks, transforming the input image into swirls of PuppySlugs.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> This imagery that reminded people of bad dreams and hallucinogenic trips was widely shared on the internet, which skyrocketed the awareness that ‘Deep Learning’ and biologically inspired computing have returned from their hibernation during the AI winter.</p>
<p>In 2012 ‘Artificial Neural Networks’ made an incredible comeback into the field of computer vision. A team around Fei-Fei Li created ImageNet,<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> a dataset of images organized into categories by anonymous workers from the internet. The ImageNet project has held a yearly competition since 2010. For the first two years, the best algorithm recognized these images with a 74% accuracy until an ‘Artificial Neural Network’ topped the score with 85% accuracy and woke the computer vision community to their potential powers.</p>
<p>With DeepDream, this technique became tangible for the general public as it created something to look at, something for humans to empathize with the outputs of an abstract mathematical model. This tendency to anthropomorphize this type of software becomes apparent in how we use language to describe it. We talk of ‘Neural Networks’ as biological entities that can be ‘taught’ and which ‘learn,’ ‘experience,’ and ‘read’ data from the world. This turning point got me and many other artists interested in ‘collaborating’ with seemingly autonomous machines. Machines that we do not have to understand through mathematics but through interpretation and experimentation of ‘their dreams.’ Yet, the outputs of DeepDream quickly became kitsch. Google shared the code with an open source license, and many people created apps and APIs to generate PuppySlug textures on top of their own images.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> As with most other memes on the internet, the hype around DeepDream died quickly, and by the end of 2015, the world was already saturated with computer-generated hallucinogenic images. Other researchers have since picked up<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> on visualizing nodes in ‘Artificial Neural Networks,’ and Alex Mordvintsev—together with his wife—has since become an artist, exhibiting in art fairs.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> What stayed was the notion that ‘Artificial Intelligence’ became some form of computational being different from the humans who wrote the code, labeled, and sorted the data.</p>
<h2 id="terms">Terms</h2>
<p>I have deliberately used quotation marks around some of the previous words, as I am critical of the language used when discussing AI systems. In his book <em>The Artist in the Machine</em> Arthur I. Miller concludes that machines could be seen as creative and will be considered “artists, writers, and musicians in their own right.”<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> He is using a typical techno-utopian argument that the technology is not quite there yet to <em>really</em> be creative but that it will change in the foreseeable future. At the same time, Miller explains in great detail the actual creative work of Mordvintsev and his human experience of insomnia to come up<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> with the generative system for DeepDream and how he shared it with his peers at Google.</p>
<p>Alex Mordvintsev was not collaborating with his computer; he created an emergent algorithmic system with it. The software does not hang pictures on exhibition walls, talk to gallerists, and has no agency in the process if it were to generate images or not. Peter Weibel has formulated it bluntly: Artificial intelligence does not exist. But an ensemble of machines, media, programs, algorithms, hardware, and software has resulted in an extraordinarily large, diverse, and productive field of research called AI.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a></p>
<p>Where Arthur Miller is feeding the narrative of humanoid robots with glowing blue brains,<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> most computer scientists in the field of artificial intelligence today are working in the subdiscipline of ‘Machine Learning.’ The terms have converged in the media landscape in the last ten years. Still, where intelligence is rejected as a suitcase word with a multiplicity of meanings, ‘Machine Learning’ tries to define the task more narrowly to some form of pattern recognition and extrapolation of existing data. They use a variety of computational and statistical techniques to form abstract models for domain-specific problems. In these fields, ’Artificial Intelligence’ is a buzzword to convince governments and venture capitalists to fund projects. The artist and researcher Francis Hunger recently shared a list of alternative terms in an attempt to dehumanize our language for AI systems:</p>
<ol type="1">
<li>‘Artificial Intelligence’ =&gt; ‘Automated Pattern Recognition’</li>
<li>‘Machine Learning’ =&gt; ‘Machine Conditioning’ OR ‘Automated Classification’</li>
<li>‘Neural Network’ =&gt; ‘Weighted Network’</li>
<li>‘Deep Learning’ =&gt; ‘Deep Conditioning’</li>
<li>‘Neuron’ =&gt; ‘Weight’ or ‘Node’<br />
<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a></li>
</ol>
<p>In an accompanying talk<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>, he explains the aim of those terms is to invoke passivity, that we deal with machines and humans set those machines in motion, even when, in the end, we form ‘human-machine assemblages.’ I like many of the proposed terms, even though they are still closely associated with biological operations. The conditioning of machines, for example, reminds me of Pavlov’s dog experiments or B.F. Skinner’s box to modify pigeon behavior by reinforcement or punishment.<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> This analogy serves well to create an image of the machine as a system that can be controlled by changing the parameters of its virtual environment. Therefore I will use ‘conditioning’ and ‘weighted networks’ where applicable.</p>
<p>Using ‘Automated Pattern Recognition’ instead of ‘Artificial Intelligence,’ however, becomes too narrow of a definition and is counterintuitive to me, as AI serves precisely the function of being ill-defined. Pei Wang has made a great effort to define the different strands of AI research and their working definitions.<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> He clusters them into Structure-AI (recreating the human brain), Behavior-AI (recreating human actions), Capability-AI (domain problem solving), Function-AI (developing cognitive functions), and Principle-AI (finding underlying principles) and comes up with a working definition to where AI research should be headed and how it can be unified. My initial goal for this thesis was to avoid the term’ Artificial Intelligence’ altogether, but as I have already failed in that task and coming up with a less anthropomorphic term does not seem feasible to convey the research in the field and its media reception. Therefore I will keep using the abbreviation AI.</p>
<p>Contrary to articles and sci-fi novels, I will not use the personification of ‘an AI’ but instead talk of AI systems, meaning complex emergent programs. Many of the systems today use statistical modeling. Yet, nobody would ask if statistics can be creative, so I decided not to engage with philosophical questions of consciousness and creativity. Instead, I want to explore how AI systems can include the human knowledge and work that goes into building them, challenging the AI ideology of machine autonomy and proposing human-centric goals rather than creating a machine as a goal in itself.</p>
<h2 id="getting-started">Getting Started</h2>
<p>[[Revision Needed]]</p>
<p>I structured this thesis around four chapters, which combine historical, computational, and collective knowledge. Starting with a history of talking machines, from Wolfgang von Kempelen’s speech automatons to digital assistants today, not forgetting that the first computers were women performing calculations. The literal act of speaking to computers sets the base of defining that we are talking through computers with other humans. The second chapter deals with the building blocks for complex statistical modeling in AI systems. To make such systems possible, researchers need to create large datasets, often using ethically questionable techniques aggregating data from internet users. I will look closely into the StyleGAN dataset, as it serves a dual purpose, because the model defined another turning point for artists to generate synthetic media. The same is true for GPT-2, a model that can generate coherent looking text based on large amounts of scraped websites and books. In the third chapter I will explore the transformer architecture and how artists are using it to make (non-)sense automatic writing. Lastly I am revisiting collective experiences that I have been organizing with other artists. I had the great pleasure to work with the net culture initiative servus.at to organize the <em>Silicon Friend Camp</em> in the Austrian mountains, where we invited 17 artists and researchers for a week long retreat, focusing on human computer conversations. The camp resulted in the exhibition <em>Camping with Computers</em> and an online symposium on <em>Conversations with Computers</em>.</p>
<p><strong>Bitte hier erwähnen, dass Arbeiten von anderen Kunstschaffenden in die verschiedenen Kapitel theoretisch eingewebt wurden, da sie dort beispielhaft deine thesen untermauern…</strong></p>
<p><strong>Außerdem bitte hier abschließend erwähnen, dass in dieser theoretischen Masterarbeit nur jene Arbeiten von dir präsentiert werden, die direkt mit diesem Inhalt in Verbindung stehen. Alle weiteren Arbeiten, die während deiner Zeit an der Kunstuni entstanden, bitte kurz beschrieben in den Anhang stellen… Danke!</strong></p>
<hr />
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-baileyDeepDreamCreatorUnveils" class="csl-entry" role="doc-biblioentry">
Bailey, Jason. n.d. <span>“<span>DeepDream Creator Unveils Very First Images After Three Years</span> — <span>Artnome</span>.”</span> Accessed March 4, 2023. <a href="https://www.artnome.com/news/2018/12/30/deepdream-creator-unveils-very-first-images-after-three-years">https://www.artnome.com/news/2018/12/30/deepdream-creator-unveils-very-first-images-after-three-years</a>.
</div>
<div id="ref-BetterImagesAI" class="csl-entry" role="doc-biblioentry">
<span>“Better <span>Images</span> of <span>AI</span>.”</span> n.d. Accessed March 4, 2023. <a href="https://betterimagesofai.org">https://betterimagesofai.org</a>.
</div>
<div id="ref-francishungerArtificialIntelligenceAutomated2021" class="csl-entry" role="doc-biblioentry">
Francis Hunger. 2021. <span>“1. ’<span>Artificial Intelligence</span>’ =<span><span class="math inline">&gt;</span></span> ’ <span>Automated Pattern Recognition</span>’ 2. ’<span>Machine Learning</span>’ =<span><span class="math inline">&gt;</span></span> ’<span>Machine Conditioning</span>’ <span>OR</span> <span>‘<span>Automated Classification</span>’</span> 3. ’<span>Neural Network</span>’ =<span><span class="math inline">&gt;</span></span> ’<span>Weighted Network</span>’ 4. <span>‘<span>Deep Learning</span>’</span> =<span><span class="math inline">&gt;</span></span> <span>‘<span>Deep Conditioning</span>’</span> 5. <span>‘<span>Neuron</span>’</span> =<span><span class="math inline">&gt;</span></span> <span>‘<span>Weight</span>’</span> or <span>‘<span>Node</span>’</span>.”</span> Tweet. <span>Twitter</span>. July 9, 2021. <a href="https://twitter.com/databaseculture/status/1413462059291975680">https://twitter.com/databaseculture/status/1413462059291975680</a>.
</div>
<div id="ref-hungerTalkUnhypeAI2021" class="csl-entry" role="doc-biblioentry">
Hunger, Francis. 2021. <span>“Talk: <span>Unhype AI</span> (2021).”</span> April 28, 2021. <a href="https://www.irmielin.org/unhype-ai/">https://www.irmielin.org/unhype-ai/</a>.
</div>
<div id="ref-ImageNet" class="csl-entry" role="doc-biblioentry">
<span>“<span>ImageNet</span>.”</span> n.d. Accessed March 4, 2023. <a href="https://image-net.org/index.php">https://image-net.org/index.php</a>.
</div>
<div id="ref-InceptionismGoingDeeper2015" class="csl-entry" role="doc-biblioentry">
<span>“Inceptionism: <span>Going Deeper</span> into <span>Neural Networks</span>.”</span> 2015. June 17, 2015. <a href="https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html">https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html</a>.
</div>
<div id="ref-millerArtistMachineWorld2019" class="csl-entry" role="doc-biblioentry">
Miller, Arthur I. 2019. <em>The Artist in the Machine: The World of <span>AI</span> Powered Creativity</em>. <span>Cambridge, Massachusetts</span>: <span>The MIT Press</span>.
</div>
<div id="ref-molnar10LearnedFeaturesa" class="csl-entry" role="doc-biblioentry">
Molnar, Christoph. n.d. <em>10.1 <span>Learned Features</span> | <span>Interpretable Machine Learning</span></em>. Accessed March 4, 2023. <a href="https://christophm.github.io/interpretable-ml-book/cnn-features.html">https://christophm.github.io/interpretable-ml-book/cnn-features.html</a>.
</div>
<div id="ref-tykaDeepdreamInceptionismRecap" class="csl-entry" role="doc-biblioentry">
Tyka, Mike. n.d. <span>“Deepdream/<span>Inceptionism</span> - Recap.”</span> Accessed March 4, 2023. <a href="http://mtyka.github.io/code/2015/07/21/one-month-after-deepdream.html">http://mtyka.github.io/code/2015/07/21/one-month-after-deepdream.html</a>.
</div>
<div id="ref-wangDefiningArtificialIntelligence2019" class="csl-entry" role="doc-biblioentry">
Wang, Pei. 2019. <span>“On <span>Defining Artificial Intelligence</span>.”</span> <em>Journal of Artificial General Intelligence</em> 10 (January): 1–37. <a href="https://doi.org/10.2478/jagi-2019-0002">https://doi.org/10.2478/jagi-2019-0002</a>.
</div>
<div id="ref-weibelAAA" class="csl-entry" role="doc-biblioentry">
Weibel, Peter. n.d. <span>“AAA.”</span> <span>www.kunstforum.de</span>. Accessed January 16, 2022. <a href="https://www.kunstforum.de/artikel/aaa/">https://www.kunstforum.de/artikel/aaa/</a>.
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>The C Programming Language Book defined many standards of programming languages today and how technical descriptions are written. While it focuses on C and the UNIX system, I find this advice from <em>Chapter 1.1 Getting Started</em> particularly interesting “On other systems, the rules will be different; check with a local expert.” as it describes the social necessity of learning computers specifically.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>See <span class="citation" data-cites="InceptionismGoingDeeper2015"><a href="#ref-InceptionismGoingDeeper2015" role="doc-biblioref"><span>“Inceptionism: <span>Going Deeper</span> into <span>Neural Networks</span>”</span></a> (<a href="#ref-InceptionismGoingDeeper2015" role="doc-biblioref">2015</a>)</span><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>The initial classifier was conditioned on ImageNet, which contains many images of dog breeds. Therefore DeepDream is biased to generate textures of dog faces.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>See <span class="citation" data-cites="ImageNet"><a href="#ref-ImageNet" role="doc-biblioref"><span>“<span>ImageNet</span>”</span></a> (<a href="#ref-ImageNet" role="doc-biblioref">n.d.</a>)</span><a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>Mike Tyka has compiled a list of projects, released within a month of publishing the source code. See <span class="citation" data-cites="tykaDeepdreamInceptionismRecap"><a href="#ref-tykaDeepdreamInceptionismRecap" role="doc-biblioref">Tyka</a> (<a href="#ref-tykaDeepdreamInceptionismRecap" role="doc-biblioref">n.d.</a>)</span><a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>A collection of tools and papers for feature visualization is collected at the GitHub repository tensorflow/lucid. Note that Chris Olah and Alex Mordvintsev are contributors. Even more examples and explanations are collected in the interpretable machine learning book by the statistician Christoph Molnar, who also notes that “Feature visualizations give unique insight into the working of neural networks,” but the “visualizations can convey the illusion that we understand what the neural network is doing.” <span class="citation" data-cites="molnar10LearnedFeaturesa"><a href="#ref-molnar10LearnedFeaturesa" role="doc-biblioref">Molnar</a> (<a href="#ref-molnar10LearnedFeaturesa" role="doc-biblioref">n.d.</a>)</span><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>Interview with Alexander Mordvintsev by artnome. See <span class="citation" data-cites="baileyDeepDreamCreatorUnveils"><a href="#ref-baileyDeepDreamCreatorUnveils" role="doc-biblioref">Bailey</a> (<a href="#ref-baileyDeepDreamCreatorUnveils" role="doc-biblioref">n.d.</a>)</span><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p><span class="citation" data-cites="millerArtistMachineWorld2019"><a href="#ref-millerArtistMachineWorld2019" role="doc-biblioref">Miller</a> (<a href="#ref-millerArtistMachineWorld2019" role="doc-biblioref">2019</a>)</span>, p.122<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Mordvintsev was inspired by a previous paper exploring the generative potential of CNNs from Karen Simonyan: Simonyan, Vedaldi, and Zisserman 2014.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>Translated from the article ‘AAA - Art, Algorithmen, Artificial Intelligence’ at Kunstforum Bd. 278. See <span class="citation" data-cites="weibelAAA"><a href="#ref-weibelAAA" role="doc-biblioref">Weibel</a> (<a href="#ref-weibelAAA" role="doc-biblioref">n.d.</a>)</span><a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>Referring to typical AI stock images. Alternative imagery is currently gathered by betterimagesofai.org. See <span class="citation" data-cites="BetterImagesAI"><a href="#ref-BetterImagesAI" role="doc-biblioref"><span>“Better <span>Images</span> of <span>AI</span>”</span></a> (<a href="#ref-BetterImagesAI" role="doc-biblioref">n.d.</a>)</span><a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>Twitter post by Francis Hunger. See <span class="citation" data-cites="francishungerArtificialIntelligenceAutomated2021"><a href="#ref-francishungerArtificialIntelligenceAutomated2021" role="doc-biblioref">Francis Hunger</a> (<a href="#ref-francishungerArtificialIntelligenceAutomated2021" role="doc-biblioref">2021</a>)</span><a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>See <span class="citation" data-cites="hungerTalkUnhypeAI2021"><a href="#ref-hungerTalkUnhypeAI2021" role="doc-biblioref">Hunger</a> (<a href="#ref-hungerTalkUnhypeAI2021" role="doc-biblioref">2021</a>)</span><a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>In behaviorist psychology Ivan Pavlov’s experiments with dogs is known as ‘classical conditioning’ and B.F. Skinner who experimented on rats and pigeons using lever machines is called ‘operant conditioning.’<a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p><span class="citation" data-cites="wangDefiningArtificialIntelligence2019"><a href="#ref-wangDefiningArtificialIntelligence2019" role="doc-biblioref">Wang</a> (<a href="#ref-wangDefiningArtificialIntelligence2019" role="doc-biblioref">2019</a>)</span><a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
