<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Conversations with Computers</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  
</head>
<body>
<header id="title-block-header">
<h1 class="title">Conversations with Computers</h1>
</header>
<h1 id="co-intelligence"><strong>Co-Intelligence</strong></h1>
<blockquote>
<p>Ubuntu: I am, because you are<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
</blockquote>
<p>The cognitive scientist Abeba Birhane takes the South African humanist philosophy of <em>Ubuntu</em> as an argument against a western tradition of the <em>self</em> as autonomous beings.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> According to <em>Ubuntu</em> a person becomes a person, only through the relationships with others. The personality is shaped by the interactions with each other and is fluidly shifting between different states. I am a different person, when talking to my mother, my friends and strangers on the street. At the same time, my upbringing and cultural influences define my own self-image. Birhane traces back the flaws in western theories of the mind to René Descartes ‘cogito ergo sum’ – I think, therefore I am. In his famous meditation the French philosopher tried to strip back all things of uncertainty to arrive at the foundation of inner thought as proof of existence. In turn this individualistic ‘I’ and the method of logical reasoning have become a successful story in western sciences. The idea of a separate mind and body was already present in Plato’s dualism, and the scientific method of breaking down complex natural phenomenons into simplified quantifiable parts is at least as old. In the past 200 years scientists, philosophers and theologists defined the ‘body-mind problem,’ coming up with theories of how the immaterial ‘soul’ interacts with the fleshy human body: Why are we conscious of the world around us, ourselves and others?</p>
<p>We concluded that the brain must do the thinking<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> and using deductive reasoning the brain was separated into smaller parts until synapses and neurons were defined and described. But the physical functioning of the brain does not explain the emotional experience of the self. The groundwork was done by the mathematician Gottfried Wilhelm Leibniz, who proposed the existence of fundamental ‘monads’ that transcend all matter in the universe, which function as an intermediary between mind and matter. Sir John Eccles applied this theory to the model of synaptic actions that he developed through experimentation with electricity and the brain, he called the mysterious forces through which we control the brain ‘psychons.’ But neither psychons nor monads served as a sufficient explanation for the bridge between mind and matter.</p>
<p>Dualism continues to have a major impact on the way we think about artificial intelligence and consciousness. For example, the influential cyberneticists Norbert Wiener and Claude Shannon both based their work on the assumption that information is a separate entity from matter and energy. This assumption has led to a disembodiment of information, and a false separation of the physical world (the ‘hardware’) from the world of ideas (the ‘software’).<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> Following a materialist logic, consciousness becomes information embedded in the physical substrate of the brain. In that sense, we only need to measure all physical activities to duplicate and simulate the experience of being human. The metaphor of the brain as a computer defines our present and justifies predictions of ‘downloading’ consciousness and achieving digital immortality. It culminates in the popular simulation hypothesis that proposes we already live in a simulated environment.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> Computational neuroscientists use and develop instruments to quantify electric impulses in the brain and create massive amounts of experimental data, which in turn need statistical models and ever growing computing power to be analyzed. On the other spectrum, simplified models of the brain in the form of artificial ‘neural networks’ are used to compute and sort higher order abstractions. This focus on the individual brain in the search to replicate intelligence leaves aside a physical and social environment, in which conscious beings are embodied.</p>
<p>In order to understand human cognition and intelligence, we need to explore the complex dialogic connections between human actors. Current machine learning programs abstract intelligence into simple task solving mechanisms and make us believe that the underlying algorithm becomes a rational agent. But on closer examination the program reveals an astonishing amount of human collaboration: from the creation of programming languages as protocols for interaction to the enormous amounts of data aggregation and labeling. Instead of looking at AI systems and seeing them as a subjective entity we can also see them as artifacts of collective cognition. By embedding current machine learning algorithms back into the social structure I hope to gain experimental insight on how these new forms of collective computations are used as a creative medium. In the following I will present my experiences working within Co-Intelligent systems in different constellations.</p>
<h2 id="metaconversations-with-computers"><strong>Metaconversations with Computers</strong></h2>
<figure>
<img src="Flowchart---Metaconversation-Piece-stitch.jpg.png" alt="Metaconversations, Miro Flowchart" /><figcaption aria-hidden="true">Metaconversations, Miro Flowchart</figcaption>
</figure>
<p>In October 2020 I participated in <em>Freeport 1: Anatomies of a black box</em><a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> and was part of a group with Gabriela Gordillo, Mario Romera and Fabian Frei in which we started a conversation about computers that ended in simulating our own conversations.</p>
<p><em>Anatomies of a black box</em> was a laboratory curated by Bani Brusadin for Matadero Madrid about mapping contemporary complex systems in infrastructures of exploitation. During the month long program we met in video conferences with Vladan Joler and other groups to explore mapping as a form of non-linear storytelling. The starting point was the conceptual map ‘Anatomy of an AI system’<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> that he created with the researcher Kate Crawford as a case study of the life cycle of an Amazon Echo device, from unearthing the raw materials to its networked software components.</p>
<p>During the <em>Freeport</em> program we, like most others during continuous lockdowns, have only engaged with each other through our screens. In the beginning we decided to look closer into the way we communicate with technological devices. First we wanted to place our focus on conversations in natural language, as speaking to computers seems to be an emerging phenomenon. After discussions on Signal<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> and Jitsi<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> that opened more questions than we could ever answer, we seemed to end up in high dimensional constructions. Our thoughts revolved around the heuristic measures of current machine learning models. Specifically those dealing with language. Large language models, which use texts from the internet to approximate a pattern in word tokens. Patterns that can generate endless amounts of coherent sounding text. Even though there are many flaws with these models, we wanted to understand how we can use these prediction machines to understand what we were chatting about. A traditional approach of text analysis would center around creating graphs and networks from the dataset we have collectively created through our conversations. Instead, we chose to mix it up with the pre-existing language model GPT-2 and analyze the output it generates instead. These outputs come in the form of a chat log. Statistical constellations from the hyperspace conversing about mostly nonsensical topics, often getting stuck in repetition. We asked ourselves what we could learn about us from these synthetic conversations.</p>
<p>The interpretation of ourselves through this machine learning lens was straight forward: quite often the patterns of who speaks and what we speak about seemed logical and in line with our real characters and the conversations we had. Yet, we know that we are biased towards finding our own images in these generated text blocks. The model acts as a parrot that lets us rediscover what we spoke about and creates a distance through which we can interpret our written conversations, as if they were someone else’s. The output is not coherent, but this imprecision is what makes reading the generated exchanges attractive.</p>
<p>As a way of communicating this process, we re-enacted the computer generated phrases in one of our weekly online meetings. The performance makes a full circle by completing the generated output with the appearance and experiences of our bodies in front of our computers.</p>
<p>The exercise of using an algorithmic model in combination with our dataset, is a way of looking towards our group process, with a tool that exposes its statistics as a probability projection in the form of verbal language. The output reflects the rhythms and patterns in our communication, that worked as a fictional mirror for us. Resembling the logic of dreams, we complete their meaning with our own interpretation and connotations, we observe we want to see.</p>
<pre><code>How exactly do these black box systems work and how are they perceived by a user.txt


Mr: I might be too absorbed in my project to finish our Q&amp;A
Mr: lets make of it what we see is funny
G: Happily.
G: No homework tomorrow, tomorrow for science!
G: I leave you with a cartoon I did a while back about the mind of a button : https://m.youtube.com/watch?v=h7BFToUaq4Y
F: what is the scientific word for &quot;intelligent&quot; ... is it cognitive, is it behavioral, semantic, artistic, etc.? is it hard to pin down, or is it a mix?
G: I can&#39;t think of a good one right now. My favourites are &quot;of theses&quot; and &quot;tractations&quot; - they&#39;re not tied to a research topic, but can be applied to any scientific question Mining Simulations: Theory and Experiment Design Automatic Feature Selection: Experimental Methods Multidimensional Pruning: Descriptive Bayes Categories: Human-Computer Interaction
G: :)
Ma: I think &quot;multidimensional&quot; is misleading. There are actually 3 dimensions to everything: a physical thing, an process of information and control, and a human interaction element. These 3 dimensions can be broken down into &quot;physical&quot; (things we are) &quot;mathematical&quot; (computations &amp; algorithms used to make them) and &quot;social&quot; (the way humans interact with other humans).
G: sorry
G: (I am using &quot;multidimensional&quot; in a cartoony way)
Ma: Cartoons are multidimensional. Most people are tall and thin. Most people are also obese.
G: Ahh yes. &quot;multidimentional&quot; is a nice word to describe this kind of thing.
G: (I think &quot;multidimensional&quot; is a bit narrow)
Ma: (I am using the term &quot;multidimensional&quot; in a cartoony way)
Ma: (I am using the term &quot;multidimensional&quot; in a cartoony way)
Ma: (using the word &quot;multidimensional&quot; in a scientific way)
G: (I think the other 2 are just fine for me)
Ma: Mixture: Theory Iteration: Experiment Design Image Identification: Feature Selection: Topic Analysis: Language Creation: Syntax Fish: Multidimensional Belief Systems: Belief Records for Computer Aided Speech (Basescim): Multidimensional Validation: The Bell Curve: SphereMapping: Element relations: Graphs: Anonymous scripting: Language models: Language learning: Syntax blind: Interactives: Syntax escapists: Syntax junkies: (I didn&#39;t type much) (I should change the last line) (I am tired) (I am sleepy) (I have nothing to say)
G: Ahh, I love it. Now I have to take care of the bad lines
G: I love it when he writes in his slowness
Mr: https://twitter.com/awokehuman/status/1328183467595718656
Mr: hi
G: hi
G: do we send it as a jpeg?
F: i think on inet message is enough
G: colors...
Mr: just in case
Mr: green, black, yellow, red, green, yellow, black, red
Mr: these</code></pre>
<h2 id="silicon-friend-camp"><strong>Silicon Friend Camp</strong></h2>
<p>The Silicon Friend Camp was a 5-day working retreat in Gosau, Upper Austria, for artists and researchers working on Artificial Intelligence. The summer camp was organized by servus.at with funding from LINZimPULS. Together with the curator Davide Bevilacqua, we started to develop the program in summer 2020. The artist Rosi Grillmair joined as facilitator and program supervisor in early 2021.</p>
<p>Due to changing pandemic conditions, a vacation home in the mountains was rented so that, despite close contact between participants, the risk of infection from the outside could be kept to a minimum. So instead of holding the program as a hackathon in the city in spring, it was moved to the summer and took place from July 20th to July 25th.</p>
<p>To create a selection of artists we published an Open Call that was distributed as a website<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> designed by Alyona Ciobanu. Inspired by a previous call for a residency at Babycastles<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>, we decided to create a form that does not ask for CVs or portfolios, but focuses on a project idea and what kind of knowledge the participant is seeking from others and is able to share. 31 artists based in Europe and the Americas responded to the call of which 12 were selected by us. The artists were chosen with a view to diversity of their projects, origin and gender. Among others, people from China, Japan, USA, Brazil, Colombia, Russia, Germany, Poland and Slovenia were invited to gather in Austria. The planned projects ranged from remote-controlled robots, to philosophical debates, to music pieces with embodied AI.</p>
<p>But before we physically met in Gosau an internet forum<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> was set up for participants to introduce themselves and initiate discussions and suggestions on content. The forum also served to communicate organizational necessities in an easily accessible and quick manner. Apart from the asynchronous text-based interaction, we held two video conferences in which Rosi read a story on narratives of AI that served as a basis for discussion.</p>
<p>One participant from Colombia joined us from the Andes mountains during the project week and would stay in contact with us only through the forum and video conferences.</p>
<figure>
<img src="Screenshot_20210721-201648_Instagram.jpg" alt="Video Call with Sebastián Mira|150" /><figcaption aria-hidden="true">Video Call with Sebastián Mira|150</figcaption>
</figure>
<p>Our preparation for the schedule of the physical work session involved the participants by asking them to contribute discussions, workshops and presentations. But also gave them enough flexibility to decide on individual and group projects.</p>
<p>The first day got off to a leisurely start with 10 participants: arriving at the train station throughout the day and being picked up and brought to the house. Together we slowly cleaned the garage, attic and living room. All while a dinner was prepared by Hess Jeon, who took care of the food for the next 5 days. We set up a table in the garden and used the time to introduce the project and welcome everyone. Before dinner, I generated a daily meal prayer with GPT-3 that was recited by us together.</p>
<pre><code>Eating is a sacred, human right
But food is getting scarce
There are humans who are hungry
And there are humans who are fat
We must ask ourselves,
Who are the humans?
I am the human
You are the human
We are the human
Because I am the human,
You are the human
We are the human
Because you are the human,
I am the human
Because we are the human,
You are the human
Because I am the human</code></pre>
<p><img src="IMG_0336.jpg" alt="Meal Prayer | 400" /> The morning of the second day was used for a group meeting in which we established general rules and defined the goals of the camp together. The participants presented their projects and what they would like to achieve in the next days.</p>
<p>In the afternoon the time could be used independently. While some sank into their laptops, others explored the surroundings around the house. We built up an area-wide network and cleared the attic and the garage so that they could be used as working places.</p>
<p>Towards the evening, a daily <em>Group Validation</em> took place, in which the participants individually summarized what they had done today, what they planned to do next and what they needed help with.</p>
<p>After dinner, time was spent together in the attic, where carpets, mattresses, speakers and a projector were installed as a <em>Digital Campfire</em>. On the first evening we were engaged in storytelling around anthropomorphic beings. In between, the sound duo EKHEO played live electronic music.</p>
<figure>
<img src="2021_07_22_selforga_brighter.jpeg" alt="Self Organizatioon" /><figcaption aria-hidden="true">Self Organizatioon</figcaption>
</figure>
<p>Day 3 began without electricity. This was especially tragic because we had a video call scheduled with researcher and artist Caroline Sinders. With some delay we got reception back to the internet and could follow Caroline’s talk about the impact, misuse and politics of ‘artificial intelligence’ on society. This was followed by a discussion on how models of machine learning can be looked at through a feminist lens.</p>
<p>The rest of the day was self structured and people used it to prototype their projects. At night in front of the <em>digital campfire</em> Dasha Ilina presented her work dealing with inconveniences of technological devices. Afterwards Naoto Hieda showed improvised choreographies created with dance and live code.</p>
<p>On the morning of Day 4, three texts were presented for discussion in a reading circle before dinner. The texts dealt with self-representations in global networks, intelligence without cognition, and root networks as a metaphor for the mind.<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a></p>
<p>Since this was the last full day to finish our projects, the day was used intensively. Many sat in front of their laptops working, for example, on a film they had previously made or trying out AI systems, such as voice cloning and generative image models, with which to realize their visions.</p>
<figure>
<img src="210721-SFC-_0010660.jpg" alt="Artists working | 350" /><figcaption aria-hidden="true">Artists working | 350</figcaption>
</figure>
<p>The <em>digital campfire</em> in the attic also got intense in the evening: after an introduction to artificial neural networks by Błażej Kotowski, Giacomo Piazzi gave a presentation on the history of AI. Mariana Marangoni spoke about esoteric programming languages that challenge accepted definitions of code and language. Lastly, Davide Bevilacqua highlighted green washing methods used by well-known internet companies.</p>
<figure>
<img src="IMG_20210723_234140.jpg" alt="The Marvelous World of Esolangs | 300" /><figcaption aria-hidden="true">The Marvelous World of Esolangs | 300</figcaption>
</figure>
<p>The last day together was used in the morning to finalize our projects, which were shown after lunch. Dasha Ilina, Erica Jewell and Lina Schwarzenberg presented <em>GRAVE</em> a video in the form of a Public Service Announcement to prepare access to digital devices and services for posterity. Naoto Hieda and So Kanno explained a work in which they rebuilt a toy robot and made it controllable via the Internet. EKHEO performed a piece for which they developed synthetic voices from all participants. Błażej Kotowski showed a video about a fictional deity in which text and images were generated using machine learning algorithms. Yuxi Liu explained how she used a camera to create a dataset of birds. Mariana Marangoni conceptualized a programming language that could be grown like a tree.</p>
<p>We spent the rest of the afternoon at a mountain lake, where we got caught in a storm, which—at least for me—was the most terrifying experience. But after drying up in the house and eating freshly baked pizzas, the rest of the evening turned into a dance party. Still Maks Valenčič gave another lecture on <em>The End of Philosophy</em> with a soft soundtrack by Błażej. Sebastián Mira also joined us from Colombia and showed us a digital world in which he connected the Andes with the Alps. Finally I used GPT-3 again to print Certificates of Excellence that were handed out in a little ceremony.</p>
<p>The next day we cleaned the house and already parted. Although our short encounter together would not end there. Friendships have formed and further collaboration on an exhibition in Linz was organized online.</p>
<h2 id="camping-with-computers">Camping with Computers</h2>
<p>The exhibition took place in the WHA Gallery from 10th to 19th of November, 2021. It tied the projects we developed during the summer camp together into a coherent presentation, where the distinction between individual artist and collective effort gets broken down. To achieve this, Davide Bevilacqua and Giacomo Piazzi created an exhibition design that takes inspiration from camping trips. With metal rods, camping stools, tarp, rocks and string they literally tied the works together. We intentionally left out exhibition signage that explains each of the works, so that a visitor would find themselves exploring the exhibition, trying to make sense of it holistically. The information about individual artists and their works was presented online, where the exhibition was mirrored for a global audience.</p>
<p>I worked on the visual identity and was inspired by the design of an old computer, the Canon Cat from 1987. It was the creation of Jef Raskin, who also invented the user interface of the first Apple Macintosh.<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a> The Canon Cat however was not a commercial success. It took away the mouse and streamlined the user interface to be centered around word processing with extra keys for fast shortcuts. It was mainly marketed as a productivity tool for office workers. The gray and beige color scheme with accents in red and blue and the hand written signature gave the computer a remarkably friendly face. I transformed this color scheme into a contemporary website with a simple generative logo that randomly exchanges some characters with emoticons, like smiley faces and hearts. The posters were also generated in the browser and embedded a QR code to the website itself. With a generative text-to-image model RuDALL-E<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> I created uncanny ‘stock images’ that were randomly placed and stretched.</p>
<figure>
<img src="20211004_171321.jpg" alt="Canon Cat with extracted colors | 300" /><figcaption aria-hidden="true">Canon Cat with extracted colors | 300</figcaption>
</figure>
<figure>
<img src="13%20Camping%20with%20Computers.jpg" alt="Example of a Poster | 300" /><figcaption aria-hidden="true">Example of a Poster | 300</figcaption>
</figure>
<p>The connection between online and offline was most notable in the work of So Kanno with the title <em>Crawler</em>. It was a continuation of the remotely controlled toy robot, he developed during the camp and a body of work he calls <em>Avatars</em><a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>. This time he modified an Apple Macbook, so that it can be controlled from the internet. On a custom laptop stand he attached wheels, so that a visitor to the website could roll around the exhibition space. Additionally the user interface was heavily customized, using notifications, web browsers and two separate webcams with face tracking to cover the faces of our visitors. The <em>Crawler</em> functioned as an autonomous object inside of the gallery space and could be seen as ‘an AI’ for video surveillance, because the actual people who control the device are hidden inside of this gray box. With this, it resembles the faux AI practice by the Colombian-owned startup Kiwi Campus, which builds a ‘self-driving’ delivery robot for US Universities. The Kiwibot is first filled by a regular delivery driver on a bicycle and then slowly rolls a few hundred meters to its destination under supervision of a human operator.<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a></p>
<figure>
<img src="crawling.jpg" alt="Screenshot of the Crawler Interface" /><figcaption aria-hidden="true">Screenshot of the Crawler Interface</figcaption>
</figure>
<p>Another work that created a juxtaposition of digital and physical elements was from Sebastián Mira. The Colombian artist created 3D reconstructions of our laptops as avatars to be used in a fictional place where the Andes and the Alps meet. Throughout the exhibition space, laptops were arranged as sculptural objects with self referential video loops, where you could see a laptop randomly rolling around computer generated landscapes. The videos were taken from the game <em>Everything</em><a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a>, in which a player can control various lifeforms and inanimate objects in procedurally generated worlds.</p>
<figure>
<img src="Opening_10.11.21(21).jpg" alt="A visitor viewing one of the laptops by Sebastián Miras | 300" /><figcaption aria-hidden="true">A visitor viewing one of the laptops by Sebastián Miras | 300</figcaption>
</figure>
<p>Naoto Hieda in turn took the 3D models of our laptop avatars and created a collage—a sort of ‘group photo’ of the participants and the toy robot mascot with me in the background—and turned it into a large banner. When I asked him if this might be too much of an inside joke, he replied that he does not care if anyone outside the group understands it, because he wants to make art for us. This made me think about the audience I try to address with my artworks. When I work on projects, I think of a fuzzy global audience, something that can be written into history books and shown in museums, but what if I just make artworks for my friends? Something so niche that only selected people understand it. This idea is so innocent and simple, yet it caught me by surprise.</p>
<figure>
<img src="Exhibition(22).jpg" alt="Naoto Hiedas Banner and Laptop showing the exhibition website | 300" /><figcaption aria-hidden="true">Naoto Hiedas Banner and Laptop showing the exhibition website | 300</figcaption>
</figure>
<p>For the exhibition I wanted to make something with the images we collected and shared online. Pictures that document our time togehter, which we shared on the forum, in our group chat and uploaded to the cloud. My initial thought was to train a GAN and create abstract synthetic images that fail to represent our collective experience. When I looked through the photo archive as a dataset, first as a large grid of images and then in rapid succession to identify outliers, I became awestruck: even though I spent less than a second with each image, some of them would trigger deep emotional states and immediately transport me back to the house in Gosau. Thinking about Naoto’s satement of “making art for my friends” I decided to use all 767 images in a rapid slideshow of 32 seconds. Each of the 24 frames per second a different image, stretched to fit a 16:9 TV that got damaged on the way to the camp. I disassembled the TV and separated the LCD panel from it’s backlight, making the images only visible from a certain angle. The title of the work “we are the human” is borrowed from one of the meal prayers. All these elements make up the work, which is both a slide show and movie, documentation and narrative, digital and analog.</p>
<figure>
<img src="Exhibition(17).jpg" alt="we are the human | 300" /><figcaption aria-hidden="true">we are the human | 300</figcaption>
</figure>
<p>The best viewing angle for my work was from a sunbed, which had a stereo speaker setup that played “LEEWA” from Ekheo. In this experimental sound piece the artists used recordings of our voices to create a communal voice clone. With the <em>Oracle</em> they came up with a name and backstory for a new character and added anecdotal field recordings from the camp. Together these works create an eerie experience based on the digitally altered collective memories of our week in the alps.</p>
<p><img src="Opening_10.11.21(16).jpg" alt="A visitor listening to LEEWA| 300" /> <img src="Opening_10.11.21(18).jpg" alt="View from the sunbed | 300" /></p>
<p>Next to these pieces is a CRT TV displaying a fire with a contraption for a pot hanging above it. The pot contains a printed recipe created by Hess Jeon with GPT-3 that we didn’t dare to cook for the opening.</p>
<pre><code>Chocolate Milk Pasta
The following is an algorithm for a vegetarian One-Pot-Wonder that was served at the &quot;Camping with Computers&quot; art exhibitions for silicon friends.

Ingredients:

1 stick butter

4 cups fresh veggies, chopped (see below)

1 cup dry pasta or broken spaghetti noodles

12 ounces water or chicken broth (chicken broth is better)

2 cups milk (chocolate milk is even better)

3/4 cup cheese (cheddar is best)

Assemble the ingredients and place them in a large pot over medium heat. Wait until the butter melts. Then turn up the heat. By now the butter should be sizzling and popping as it heats up the veggies and pasta. At this point you can add garlic, onions, corn, peas, or whatever else strikes your fancy. The key is to use fresh veggies that you like; this way you won&#39;t notice that you&#39;re eating veggies at all. Once the veggies and pasta are nice and hot (and they will be), add the water/broth and stir them thoroughly. Now the cooking begins! Put on a movie or text message competition with your friends and let them know you&#39;ll be cooking for about five minutes. The trick here is to make sure that the pasta isn&#39;t too soft; you don&#39;t want it to disintegrate into a big blob of mush like most of your ex-girlfriends did. Now make sure you have a timer handy on your phone or on a wall clock or something. After five minutes have elapsed, turn off the heat, but leave the pot on the stove. Now for the next step: pour in the milk/chocolate milk and stir it vigorously for about 15 seconds. This will ensure that the cheese melts properly so that all its flavor can be absorbed by your tastebuds. Stir in the cheese until it&#39;s completely melted, then serve it up! Serve with crusty bread so that you can sop up all of those yummy juices, but only use one piece of bread per person because it will fill you up fast. You want to save room for dessert! This recipe tastes best cold because then you can use that leftover cold chocolate milk to drink with it! If any is left over, put it in the fridge overnight so that it absorbs more of those yummy flavors. Then eat it cold for breakfast with a side of bacon or ham! Yum yum!!</code></pre>
<figure>
<img src="Exhibition(6).jpg" alt="Hess Jeon “Chocolate Milk Pasta”|300" /><figcaption aria-hidden="true">Hess Jeon “Chocolate Milk Pasta”|300</figcaption>
</figure>
<p>On another set of monitors Yuxi Liu showed a 3-channel video installation in which she is exploring the non-human world. During the first Covid-19 lockdown she used a motion-sensor camera to capture the birds visiting her balcony. This served as an image set for a GAN model, which after finetuning was supposed to recreate the images of the visiting birds but instead abstracted the animal so much that merely the surrounding was visible. This served as an interesting metaphor of how the digitization of the natural world and statistical operations on it sometimes disregard the life within. During her stay at the camp Yuxi wanted to capture more animals with a DIY raspberry pi camera, and even though she tried her best to lure more birds, in the end the camera did not sense any. This got us to discuss the role of human and non-human connections within cities and outside of them. While inner cities objectively have less animal life, the scarcity of resources make them live closer to humans. In her last installment she was recording birds over the rooftops and on the port of Rotterdam overlooking the city and it’s environment.</p>
<figure>
<img src="Exhibition(31).jpg" alt="Yuxi Liu" /><figcaption aria-hidden="true">Yuxi Liu</figcaption>
</figure>
<p>Davide Bevilacquas <em>POND</em>, a 4-channel video installation also addresses the digitization of natural phenomena. The screens are lying flat on the floor on a tarp resembling a small pond inside of the exhibition space. The images of the water surface are morphing between each other creating an unusual and oddly familiar ripple effect. It looks both like the scattering of sunlight on top of a water surface and the glitch artifacts we know when a video file is not loading properly.</p>
<figure>
<img src="Exhibition(25).jpg" alt="Exhibition view of POND by Davide Bevilacqua" /><figcaption aria-hidden="true">Exhibition view of POND by Davide Bevilacqua</figcaption>
</figure>
<p>Giacomo Piazzis <em>The Monkey</em> is a monolithic work consisting of two rows of red glowing displays continuously changing the pattern of the lit screens. He uses the infinite monkey theorem which proclaims that if a monkey were to hit a random letter on a keyboard for an infinite amount of time it would eventually write the complete works of Shakespear, or almost surely any other finite text. <em>The Monkey</em> in Giacomos work is a random number generator that turns a segment of the display either on or off, possibly creating any string of text. While a 7-segment display with it’s 128 possible states is mostly used in digital clocks and meters because of their ability to show numerical values easily, it is also possible to show most letters of the latin alphabet. Because of their simplicity and due to their widespread use in electronic devices, Giacomo flips the monkey theorem on it’s head and becomes more interested in the human interpretation of the arbitrary values displayed on the screen.</p>
<figure>
<img src="Exhibition(12).jpg" alt="Giacomo Piazzi, The Monkeys |300" /><figcaption aria-hidden="true">Giacomo Piazzi, The Monkeys |300</figcaption>
</figure>
<p>Another work that focuses on text and it’s representation in artificial neural networks is <em>Latent Space Divination</em><a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a> by Błażej Kotowski. In this piece he created an interactive meditation for one person in a tent to reflect on the position of word embeddings and their spacial relation within a sentence. A visitor sits down in front of a tablet computer with headphones and types in their intention. The word embeddings of the sentence in turn impact how a 3 dimensional graph will be created. While the graph is slowly unfolding a sonification is generated for the participant and after around 5 minutes the object rotates around itself to create a solid object representing the intention.</p>
<figure>
<img src="Opening_10.11.21(6).jpg" alt="Visitor at the end of Latent Space Divination" /><figcaption aria-hidden="true">Visitor at the end of Latent Space Divination</figcaption>
</figure>
<p>Finally <em>1-800-MYGRAVE</em> by Erica Jewel and Dasha Ilina is an installation in the center of the room that imagines a call center where the visitor becomes a worker for a fictional company that provides digital afterlife service. It is based on a video they made with Lina Schwarzenberg during the camp. The infomercial in the style of a 1980s public service announcement warns the viewer of their accumulated data and offers some simple steps to protect digital files and avoid embarrassment after death. The cubicle in the gallery is fitted with a corded telephone and an inspirational poster where the visitor switches roles and takes on (automated) calls from people who ask or complain about the service. An instruction manual tells the participant how to respond and which buttons to press.</p>
<figure>
<img src="Exhibition(21).jpg" alt="1-800-MYGRAVE installation view" /><figcaption aria-hidden="true">1-800-MYGRAVE installation view</figcaption>
</figure>
<p>The open call for the camp had the goal “to enable embodied networks through the development of new forms of computational intelligence.”<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a> Looking back to the exhibition and the camp after over a year I see a multitude of connections. While the works are separated by space and author they often address the same thing from a different angle. We explored anthropomorphous robots by embodying a virtual friend inside of a plastic toy, but most closely we looked into the process of capturing the world through digital computers and how we relate to and interpret our data bodies. Maybe real AI is the friends we made along the way.<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a></p>
<hr />
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-AnatomyAISystem2018" class="csl-entry" role="doc-biblioentry">
<span>“Anatomy of an <span>AI System</span>.”</span> 2018. <span>Anatomy of an AI System</span>. 2018. <a href="http://www.anatomyof.ai">http://www.anatomyof.ai</a>.
</div>
<div id="ref-Avatars" class="csl-entry" role="doc-biblioentry">
<span>“Avatars.”</span> n.d. <span>So Kanno</span>. Accessed April 28, 2022. <a href="https://www.kanno.so/project/avatars">https://www.kanno.so/project/avatars</a>.
</div>
<div id="ref-Babycastles" class="csl-entry" role="doc-biblioentry">
<span>“Babycastles.”</span> n.d. <span>Babycastles</span>. Accessed January 30, 2022. <a href="https://www.babycastles.com">https://www.babycastles.com</a>.
</div>
<div id="ref-bostromAreYouLiving2001" class="csl-entry" role="doc-biblioentry">
Bostrom, Nick. 2001. <span>“Are <span>You Living</span> in a <span>Computer Simulation</span>?”</span> 14. <a href="https://www.simulation-argument.com/simulation.pdf">https://www.simulation-argument.com/simulation.pdf</a>.
</div>
<div id="ref-DescartesWasWrong2017" class="csl-entry" role="doc-biblioentry">
<span>“Descartes Was Wrong: <span>‘A Person Is a Person Through Other Persons’</span> | <span>Aeon Ideas</span>.”</span> 2017. <span>Aeon</span>. April 7, 2017. <a href="https://aeon.co/ideas/descartes-was-wrong-a-person-is-a-person-through-other-persons">https://aeon.co/ideas/descartes-was-wrong-a-person-is-a-person-through-other-persons</a>.
</div>
<div id="ref-EverythingDLVIDOREILLY" class="csl-entry" role="doc-biblioentry">
<span>“Everything — <span>DΛVID OREILLY</span> • Computer Art &amp; Research.”</span> n.d. Accessed April 28, 2022. <a href="https://www.davidoreilly.com/everything/">https://www.davidoreilly.com/everything/</a>.
</div>
<div id="ref-FREEPORTANATOMIESBLACK" class="csl-entry" role="doc-biblioentry">
<span>“<span>FREEPORT</span> 1: <span>ANATOMIES OF A BLACK BOX</span>.”</span> n.d. <span>Matadero Madrid</span>. Accessed April 23, 2022. <a href="https://www.mataderomadrid.org/en/calls/freeport-1-anatomies-black-box">https://www.mataderomadrid.org/en/calls/freeport-1-anatomies-black-box</a>.
</div>
<div id="ref-gadeWhatUbuntuDifferent2012" class="csl-entry" role="doc-biblioentry">
Gade, Christian B. N. 2012. <span>“What Is <span><em>Ubuntu</em></span> ,? <span>Different Interpretations</span> Among <span>South Africans</span> of <span>African Descent</span>.”</span> <em>South African Journal of Philosophy</em> 31 (3): 484–503. <a href="https://doi.org/10.1080/02580136.2012.10751789">https://doi.org/10.1080/02580136.2012.10751789</a>.
</div>
<div id="ref-HumanguidedBurritoBots2019" class="csl-entry" role="doc-biblioentry">
<span>“Human-Guided Burrito Bots Raise Questions about the Future of Robo-Delivery.”</span> 2019. <span>The Hustle</span>. June 3, 2019. <a href="https://thehustle.co/kiwibots-autonomous-food-delivery/">https://thehustle.co/kiwibots-autonomous-food-delivery/</a>.
</div>
<div id="ref-RuDALLE" class="csl-entry" role="doc-biblioentry">
<span>“<span class="nocase">ruDALL-E</span>.”</span> n.d. <span>ruDALL-E</span>. Accessed April 28, 2022. <a href="http://rudalle.ru/en/">http://rudalle.ru/en/</a>.
</div>
<div id="ref-CanonCatMac2014" class="csl-entry" role="doc-biblioentry">
<span>“The <span>Canon Cat The Mac</span>’s <span>Ancestor</span>.”</span> 2014. October 25, 2014. <a href="https://web.archive.org/web/20141025053109/http://www.jagshouse.com/swyft.html">https://web.archive.org/web/20141025053109/http://www.jagshouse.com/swyft.html</a>.
</div>
<div id="ref-zarkadakesOurOwnImage2016" class="csl-entry" role="doc-biblioentry">
Zarkadakēs, Giōrgos. 2016. <em>In Our Own Image: Savior or Destroyer?: The History and Future of Artificial Intelligence</em>. First Pegasus books hardcover edition. <span>New York, NY</span>: <span>Pegasus Books LLC</span>.
</div>
</div>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>The term Ubuntu originates from southern Africa and is used to describe a humanist philosophy according to which persons are interconnected. It is often used in phrases such as the Zulu ‘Umuntu ngumuntu ngabantu,’ which translates to ‘A person is a person through other persons.’ The term for personhood (ubuntu) itself is not clearly defined and has different meanings in different areas. <span class="citation" data-cites="gadeWhatUbuntuDifferent2012"><a href="#ref-gadeWhatUbuntuDifferent2012" role="doc-biblioref">Gade</a> (<a href="#ref-gadeWhatUbuntuDifferent2012" role="doc-biblioref">2012</a>)</span><a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p><span class="citation" data-cites="DescartesWasWrong2017"><a href="#ref-DescartesWasWrong2017" role="doc-biblioref"><span>“Descartes Was Wrong: <span>‘A Person Is a Person Through Other Persons’</span> | <span>Aeon Ideas</span>”</span></a> (<a href="#ref-DescartesWasWrong2017" role="doc-biblioref">2017</a>)</span><a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>In the story <em>On Having No Head</em> D.E. Harding describes the realization that one can never experience their own head, because the most important sensual organs are embedded in it. I don’t remember where I read it, but there is an argument that the reason we place consciousness in the brain is because we mostly experience the world from the position of our head.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p><span class="citation" data-cites="zarkadakesOurOwnImage2016"><a href="#ref-zarkadakesOurOwnImage2016" role="doc-biblioref">Zarkadakēs</a> (<a href="#ref-zarkadakesOurOwnImage2016" role="doc-biblioref">2016</a>)</span> p.189<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>The simulation argument was first proposed by Nick Bostrom. He argues that if we were able to create realistic simulated minds and worlds in the future it is likely that we already live in a simulation. <span class="citation" data-cites="bostromAreYouLiving2001">(<a href="#ref-bostromAreYouLiving2001" role="doc-biblioref">Bostrom 2001</a>)</span> The theory was<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p><span class="citation" data-cites="FREEPORTANATOMIESBLACK"><a href="#ref-FREEPORTANATOMIESBLACK" role="doc-biblioref"><span>“<span>FREEPORT</span> 1: <span>ANATOMIES OF A BLACK BOX</span>”</span></a> (<a href="#ref-FREEPORTANATOMIESBLACK" role="doc-biblioref">n.d.</a>)</span><a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p><span class="citation" data-cites="AnatomyAISystem2018"><a href="#ref-AnatomyAISystem2018" role="doc-biblioref"><span>“Anatomy of an <span>AI System</span>”</span></a> (<a href="#ref-AnatomyAISystem2018" role="doc-biblioref">2018</a>)</span><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>Signal is an encrypted messaging app. See: https://www.signal.org<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>Jitsi Meet is an open source video conferencing software. See: https://meet.jit.si/<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>See: https://cwc.radical-openness.org/siliconfriendcamp/<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>Babycastles is a NYC based collective fostering and amplifying diverse voices in videogame culture. Babycastles provides artists support to actualize ideas and expose that work to new audiences. <span class="citation" data-cites="Babycastles"><a href="#ref-Babycastles" role="doc-biblioref"><span>“Babycastles”</span></a> (<a href="#ref-Babycastles" role="doc-biblioref">n.d.</a>)</span><a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn12" role="doc-endnote"><p>The open source forum software <em>Discourse</em> was hosted at the local servus.at data center.<a href="#fnref12" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn13" role="doc-endnote"><p>Bogna Konior, <em>The Dark Forest Theory of the Internet</em>; Rodney Brooks, Intelligence without Representation_; Matteo Pasquinelli, <em>The Arborescent Mind: The Intelligence of an Inverted Tree</em><a href="#fnref13" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn14" role="doc-endnote"><p>See: <span class="citation" data-cites="CanonCatMac2014"><a href="#ref-CanonCatMac2014" role="doc-biblioref"><span>“The <span>Canon Cat The Mac</span>’s <span>Ancestor</span>”</span></a> (<a href="#ref-CanonCatMac2014" role="doc-biblioref">2014</a>)</span><a href="#fnref14" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn15" role="doc-endnote"><p>See: <span class="citation" data-cites="RuDALLE"><a href="#ref-RuDALLE" role="doc-biblioref"><span>“<span class="nocase">ruDALL-E</span>”</span></a> (<a href="#ref-RuDALLE" role="doc-biblioref">n.d.</a>)</span><a href="#fnref15" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn16" role="doc-endnote"><p>Together with the artist yang02, So Kanno modified multiple objects that could be remotely controlled from the web. See: <span class="citation" data-cites="Avatars"><a href="#ref-Avatars" role="doc-biblioref"><span>“Avatars”</span></a> (<a href="#ref-Avatars" role="doc-biblioref">n.d.</a>)</span><a href="#fnref16" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn17" role="doc-endnote"><p>See: <span class="citation" data-cites="HumanguidedBurritoBots2019"><a href="#ref-HumanguidedBurritoBots2019" role="doc-biblioref"><span>“Human-Guided Burrito Bots Raise Questions about the Future of Robo-Delivery”</span></a> (<a href="#ref-HumanguidedBurritoBots2019" role="doc-biblioref">2019</a>)</span><a href="#fnref17" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn18" role="doc-endnote"><p>Everything is an interactive experience by David OReilly from 2017. See: <span class="citation" data-cites="EverythingDLVIDOREILLY"><a href="#ref-EverythingDLVIDOREILLY" role="doc-biblioref"><span>“Everything — <span>DΛVID OREILLY</span> • Computer Art &amp; Research”</span></a> (<a href="#ref-EverythingDLVIDOREILLY" role="doc-biblioref">n.d.</a>)</span><a href="#fnref18" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn19" role="doc-endnote"><p>See: http://lsd.blazejkotowski.com/<a href="#fnref19" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn20" role="doc-endnote"><p>Generated by GPT3 with some context<a href="#fnref20" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn21" role="doc-endnote"><p>Based on a tweet by the user mind_backup https://twitter.com/mind_backup/status/1601131037609730048<a href="#fnref21" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
