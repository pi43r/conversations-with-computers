# **Co-Intelligence**

> Ubuntu: I am because you are [^1]

The cognitive scientist Abeba Birhane takes the South African humanist philosophy of _ubuntu_ as an argument against a Western tradition of the _self_ as autonomous beings.[^2] According to _ubuntu_ a person becomes a person only through relationships with others. The interactions we have with each other shape our personality, and it is fluidly shifting between different states. I am a different person when talking to my mother, my friends, and strangers on the street. At the same time, my upbringing and cultural influences define my own self-image. Birhane traces back the flaws in Western theories of the mind to René Descartes’ ‘cogito ergo sum’ – I think, therefore I am. In his famous meditation, the French philosopher tried to strip back all things of uncertainty to arrive at the foundation of inner thought as proof of existence. In turn, this individualistic ‘I’ and the method of logical reasoning have become a success story in Western sciences. The idea of a separate mind and body was already present in Plato’s dualism. The scientific method of breaking down complex natural phenomena into simplified quantifiable parts is at least as old. In the past 200 years, scientists, philosophers, and theologists defined the ‘body-mind problem’, coming up with theories of how the immaterial ‘soul’ interacts with the fleshy human body: Why are we conscious of the world around us, ourselves, and others?

We concluded that the brain must do the thinking[^3], and using deductive reasoning, the brain was separated into smaller parts until synapses and neurons were defined and described. But the physical functioning of the brain does not explain the emotional experience of the self. 
The groundwork was done by the mathematician Gottfried Wilhelm Leibniz, who proposed the existence of fundamental ‘monads’ that transcend all matter in the universe, which function as an intermediary between mind and matter. Sir John Eccles applied this theory to the model of synaptic actions he developed through experimentation with electricity and the brain; he called the mysterious forces through which we control the brain ‘psychons’. But neither psychons nor monads served as a sufficient explanation for the bridge between mind and matter.

Dualism continues to significantly impact how we think about artificial intelligence and consciousness. For example, the influential cyberneticists Norbert Wiener and Claude Shannon both based their work on the assumption that information is a separate entity from matter and energy. This assumption has led to a disembodiment of information and a false separation of the physical world (the ‘hardware’) from the world of ideas (the ‘software’).[^4] Following a materialist logic, consciousness becomes information embedded in the physical substrate of the brain. In that sense, we only need to measure all physical activities to duplicate and simulate the human experience. The metaphor of the brain as a computer defines our present and justifies predictions of ‘downloading’ consciousness and achieving digital immortality. It culminates in the popular simulation hypothesis, which proposes that we live in a simulated environment.[^5]
Computational neuroscientists use and develop instruments to quantify electric impulses in the brain and create massive amounts of experimental data, which in turn need statistical models and ever-growing computing power to be analyzed. On the other spectrum, simplified models of the brain in the form of artificial ‘neural networks’ are used to compute and sort higher-order abstractions. This focus on the individual brain in the search to replicate intelligence leaves aside a physical and social environment in which conscious beings are embodied.

To understand human cognition and intelligence, we need to explore the complex dialogic connections between human actors. Current machine learning programs abstract intelligence into simple task-solving mechanisms, making us believe that the underlying algorithm becomes a rational agent, but on closer examination, the program reveals an astonishing amount of human collaboration: from the creation of programming languages as protocols for interaction to the enormous amounts of data aggregation and labeling. Instead of looking at AI systems and seeing them as subjective entities, we can also see them as artifacts of collective cognition.
By embedding current machine learning algorithms back into the social structure, I hope to gain experimental insight into how these new forms of collective computations are used as a creative medium. In the following, I will present my experiences working within Co-Intelligent systems in different constellations.


## Metaconversations with Computers
![Metaconversations, Miro Flowchart](Flowchart---Metaconversation-Piece-stitch.jpg.png)

In October 2020, I participated in *Freeport 1: Anatomies of a black box*[^6] and was part of a group with Gabriela Gordillo, Mario Romera, and Fabian Frei. We started a conversation about computers that ended up simulating our internal conversations.

*Anatomies of a black box* was a laboratory curated by Bani Brusadin for Matadero Madrid about mapping contemporary complex systems in infrastructures of exploitation. During the month-long program, we met in video conferences with Vladan Joler and other groups to explore mapping as a form of non-linear storytelling. The starting point was the conceptual map ‘Anatomy of an AI system’ [^7] that he created with the researcher Kate Crawford as a case study of the life cycle of an Amazon Echo device, from unearthing the raw materials to its networked software components. 

During the *Freeport* program, we, like most others during continuous lockdowns, have only engaged with each other through our screens. Initially, we decided to look closer into how we communicate with technological devices. First, we wanted to focus on conversations in natural language, as speaking to computers is an emerging phenomenon. After discussions on Signal and Jitsi[^8] that opened more questions than we could ever answer, we ended up in high-dimensional constructions. Our thoughts revolved around the heuristic measures of current machine learning models. Specifically, those dealing with language. Large language models, which use texts from the internet to approximate a pattern in word tokens, patterns that can generate endless amounts of coherent-sounding text. Even though these models have many flaws, we wanted to understand how we could use these prediction machines to understand what we were chatting about. A traditional text analysis approach would center around creating graphs and networks from the dataset we collectively created through conversations. Instead, we chose to mix it up with the pre-existing language model GPT-2 and analyze the output it generates instead. These outputs come in the form of a chat log. Statistical constellations from the hyperspace were conversing about mostly nonsensical topics, often getting stuck in repetition. We asked ourselves what we could learn about our fragmented selves from these synthetic conversations.

The interpretation of ourselves through this machine-learning lens was straightforward. Quite often, the patterns of who speaks and what we speak about seemed logical and in line with our real characters and the conversations we had. Yet, we know that we are biased toward finding our own images in these generated text blocks.
The model acts as a parrot that lets us rediscover what we spoke about and creates a distance through which we can interpret our written conversations as if they were someone else’s. The output is not coherent, but this imprecision is what makes reading the generated exchanges attractive.

To communicate this process, we re-enacted the computer-generated phrases in one of our weekly online meetings. The performance makes a full circle by completing the generated output with the appearance and experiences of our bodies in front of our computers. 

The exercise of using an algorithmic model in combination with our dataset is a way of looking at our group process with a tool that exposes its statistics as a probability projection in the form of verbal language. The output reflects the rhythms and patterns in our communication that worked as a fictional mirror for us. Resembling the logic of dreams, we complete their meaning with our interpretation and connotations; we observe what we want to see.

```
How exactly do these black box systems work and how are they perceived by a user.txt


Mr: I might be too absorbed in my project to finish our Q&A
Mr: lets make of it what we see is funny
G: Happily.
G: No homework tomorrow, tomorrow for science!
G: I leave you with a cartoon I did a while back about the mind of a button : https://m.youtube.com/watch?v=h7BFToUaq4Y
F: what is the scientific word for "intelligent"... is it cognitive, is it behavioral, semantic, artistic, etc.? is it hard to pin down, or is it a mix?
G: I can’t think of a good one right now. My favourites are "of theses" and "tractations" - they’re not tied to a research topic, but can be applied to any scientific question Mining Simulations: Theory and Experiment Design Automatic Feature Selection: Experimental Methods Multidimensional Pruning: Descriptive Bayes Categories: Human-Computer Interaction
G: :)
Ma: I think "multidimensional" is misleading. There are actually 3 dimensions to everything: a physical thing, an process of information and control, and a human interaction element. These 3 dimensions can be broken down into "physical" (things we are) "mathematical" (computations & algorithms used to make them) and "social" (the way humans interact with other humans).
G: sorry
G: (I am using "multidimensional" in a cartoony way)
Ma: Cartoons are multidimensional. Most people are tall and thin. Most people are also obese.
G: Ahh yes. "multidimentional" is a nice word to describe this kind of thing.
G: (I think "multidimensional" is a bit narrow)
Ma: (I am using the term "multidimensional" in a cartoony way)
Ma: (I am using the term "multidimensional" in a cartoony way)
Ma: (using the word "multidimensional" in a scientific way)
G: (I think the other 2 are just fine for me)
Ma: Mixture: Theory Iteration: Experiment Design Image Identification: Feature Selection: Topic Analysis: Language Creation: Syntax Fish: Multidimensional Belief Systems: Belief Records for Computer Aided Speech (Basescim): Multidimensional Validation: The Bell Curve: SphereMapping: Element relations: Graphs: Anonymous scripting: Language models: Language learning: Syntax blind: Interactives: Syntax escapists: Syntax junkies: (I didn’t type much) (I should change the last line) (I am tired) (I am sleepy) (I have nothing to say)
G: Ahh, I love it. Now I have to take care of the bad lines
G: I love it when he writes in his slowness
Mr: https://twitter.com/awokehuman/status/1328183467595718656
Mr: hi
G: hi
G: do we send it as a jpeg?
F: i think on inet message is enough
G: colors...
Mr: just in case
Mr: green, black, yellow, red, green, yellow, black, red
Mr: these
```

## Silicon Friend Camp

The Silicon Friend Camp was a 5-day working retreat in Gosau, Upper Austria, for artists and researchers working on Artificial Intelligence. The summer camp was organized by servus.at with funding from LINZimPULS. Together with the curator Davide Bevilacqua, we started to develop the program in the summer of 2020. The artist Rosi Grillmair joined as a facilitator and program supervisor in early 2021.

Due to changing pandemic conditions, we rented a vacation home in the mountains so that the risk of infection from the outside could be kept to a minimum despite close contact between participants. So instead of holding the program as a hackathon in the city in the spring, we moved it to the summer, where it took place from July 20th to July 25th.

To create a selection of artists, we published an Open Call, distributed as a website[^9] designed by Alyona Ciobanu. Inspired by a previous call for a residency at Babycastles[^10], we created a form that does not ask for CVs or portfolios but focuses on a project idea and what kind of knowledge the participant seeks from others and is able to share. Thirty-one artists based in Europe and the Americas responded to the call, of which we selected 12. We chose the artists with a view to the diversity of their projects, origin, and gender. In the end, a wide range of people from China, Japan, the USA, Brazil, Colombia, Russia, Germany, Poland, and Slovenia gathered in Austria. The planned projects ranged from remote-controlled robots to philosophical debates to music pieces with embodied AI.

But before we physically met in Gosau, an internet forum[^11] was set up for participants to introduce themselves and initiate discussions and suggestions on content. The forum also served to communicate organizational necessities in an easily accessible and quick manner. Apart from the asynchronous text-based interaction, we held two video conferences in which Rosi read a story on narratives of AI that served as a basis for discussion.

One participant from Colombia joined us from the Andes mountains during the project week and stayed in contact with us only through the forum and video conferences.

![Video Call with Sebastián Mira|150](Screenshot_20210721-201648_Instagram.jpg)

Our preparation for the schedule of the physical work session involved the participants by asking them to contribute to discussions, workshops, and presentations. Still, we also gave them enough flexibility to decide on individual and group projects.

The first day got off to a leisurely start, with 10 participants: arriving at the train station throughout the day and being picked up and brought to the house. Together we slowly cleaned the garage, attic, and living room. While Hess Jeon, who took care of the food for the next five days, prepared dinner. We set up a table in the garden and used the time to introduce the project and welcome everyone. Before dinner, I generated a daily meal prayer with GPT-3 that we recited together.

```
Eating is a sacred, human right
But food is getting scarce
There are humans who are hungry
And there are humans who are fat
We must ask ourselves,
Who are the humans?
I am the human
You are the human
We are the human
Because I am the human,
You are the human
We are the human
Because you are the human,
I am the human
Because we are the human,
You are the human
Because I am the human
```
![Meal Prayer | 400](IMG_0336.jpg)
We used the following morning for a group meeting in which we established general rules and defined the goals of the camp together. The participants presented their projects and what they wanted to achieve in the following days.

In the afternoon, we used our time independently. While some people sank into their laptops, others explored the surrounding area around the house. We built up an area-wide network and cleared the attic and the garage to be used as working places.

Towards the evening, a daily *Group Validation* took place. The participants individually summarized what they had done that day, what they planned to do next, and what they needed help with.

After dinner, we spent time together in the attic, where we installed carpets, mattresses, speakers, and a projector as a *Digital Campfire*. On the first evening, we were engaged in storytelling around anthropomorphic beings. In between, the sound duo EKHEO played live electronic music.

![Self Organizatioon](2021_07_22_selforga_brighter.jpeg)

Day 3 began without electricity, which was especially tragic because we scheduled a video call with researcher and artist Caroline Sinders.
With some delay, we got reception back to the internet. We could follow Caroline’s talk about the impact, misuse, and politics of ‘artificial intelligence’ on society, which we followed up with a discussion on how we can view machine learning models through a feminist lens.

The rest of the day was self-structured, and people used it to prototype their projects. At night in front of the *digital campfire* Dasha Ilina presented her work dealing with the inconveniences of technological devices. Afterward, Naoto Hieda showed improvised choreographies created with dance and live code.

On the morning of Day 4, three texts were presented for discussion in a reading circle before dinner. The texts dealt with self-representations in global networks, intelligence without cognition, and root networks as a metaphor for the mind.[^12]

Since this was the last full day to finish our projects, the participants used it intensively. Many sat in front of their laptops working, for example, on a film they had previously shot or trying out AI systems, such as voice cloning and generative image models, with which to realize their visions.

![Artists working | 350](210721-SFC-_0010660.jpg)

The *digital campfire* in the attic also intensified in the evening. After an introduction to artificial neural networks by Błażej Kotowski, Giacomo Piazzi gave a presentation on the history of AI. Mariana Marangoni spoke about esoteric programming languages that challenge accepted definitions of code and language. Lastly, Davide Bevilacqua highlighted greenwashing methods used by well-known internet companies.

![The Marvelous World of Esolangs | 300](IMG_20210723_234140.jpg)

The morning of the last day was used to finalize projects, which were presented after lunch. Dasha Ilina, Erica Jewell, and Lina Schwarzenberg presented *GRAVE* a video as a Public Service Announcement to prepare access to digital devices and services for posterity. Naoto Hieda and So Kanno explained how they rebuilt a toy robot and made it controllable via the internet. EKHEO performed a piece for which they developed synthetic voices from all participants. Błażej Kotowski showed a video about a fictional deity in which text and images are generated through machine learning algorithms. Yuxi Liu explained how she used a camera to create a dataset of birds. Mariana Marangoni conceptualized a programming language that could be grown like a tree.

We spent the rest of the afternoon at a mountain lake, where we got caught in a storm, which—at least for me—was a terrifying experience. But after drying up in the house and eating freshly baked pizzas, the rest of the evening turned into a dance party. Still, Maks Valenčič gave another lecture on *The End of Philosophy* with a soft soundtrack by Błażej. Sebastián Mira also joined us from Colombia and showed us a digital world in which he connected the Andes with the Alps. Finally, I used GPT-3 again to print Certificates of Excellence that I handed out in a little ceremony.

The next day we cleaned the house and already parted. However, our short encounter together would continue. Friendships have formed, and we organized further collaboration on an exhibition in Linz online.


## Camping with Computers

The exhibition took place in the WHA Gallery from 10th to 19th November 2021. It tied the projects we developed during the summer camp into a coherent presentation, where the distinction between the individual artist and collective effort is broken down. To achieve this, Davide Bevilacqua and Giacomo Piazzi created an exhibition design inspired by camping trips. With metal rods, camping stools, tarp, rocks, and string, they—quite literally—tied the works together. We intentionally left out exhibition signage that explains each of the artworks so that a visitor would find themselves exploring the exhibition, trying to make sense of it holistically. The information about individual artists and their works was presented online, where the show was mirrored for a global audience.

I worked on the visual identity and was inspired by the design of an old computer, the Canon Cat, from 1987. It was the creation of Jef Raskin, who also invented the user interface of the first Apple Macintosh.[^13] The Canon Cat, on the other hand, was not a commercial success. It took away the mouse and streamlined the user interface to be centered around word processing with extra keys for fast shortcuts. It was mainly marketed as a productivity tool for office workers. The gray and beige color scheme with accents in red and blue and the handwritten signature gave the computer a remarkably friendly face. I transformed this color scheme into a contemporary website with a simple generative logo that randomly exchanges some characters with emoticons, like smiley faces and hearts. The posters were also generated in the browser, and a QR code was embedded to the exhibition website. With a generative text-to-image model RuDALL-E,[^14] I created uncanny ‘stock images’ that were randomly placed and stretched.

![Canon Cat with extracted colors | 300](20211004_171321.jpg)

![Example of a Poster | 300](13CampingwithComputers.jpg)

The connection between online and offline was most notable in the work of So Kanno with the title *Crawler*. It was a continuation of the remotely controlled toy robot he developed during the camp and a body of work he calls *Avatars*[^15]. This time he modified an Apple Macbook so that it could be controlled from the internet. He attached wheels on a custom laptop stand so that a visitor to the website could roll around the exhibition space. Additionally, the user interface was heavily customized, using notifications, web browsers, and two separate webcams with face tracking to cover the faces of our visitors. 
The *Crawler*  functioned as an autonomous object inside the gallery space and could be seen as ‘an AI’ for video surveillance because the actual people who control the device are hidden inside this gray box. With this, it resembles the faux AI practice by the Colombian-owned startup Kiwi Campus, which builds a ‘self-driving’ delivery robot for US Universities. The Kiwibot is first filled by a regular delivery driver on a bicycle and then slowly rolls a few hundred meters to its destination under the supervision of a human operator.[^16]

![Screenshot of the Crawler Interface](crawling.jpg)

Another work that juxtaposed digital and physical elements was from Sebastián Mira. The Colombian artist created 3D reconstructions of our laptops as avatars to be used in a fictional place where the Andes and the Alps meet. Throughout the exhibition space, laptops were arranged as sculptural objects with self-referential video loops, where you could see a laptop randomly rolling around computer-generated landscapes. The videos were taken from the game *Everything*[^17], in which a player can control various lifeforms and inanimate objects in procedurally generated worlds.

![A visitor viewing one of the laptops by Sebastián Miras | 300](Opening_10.11.21(21).jpg)

Naoto Hieda, in turn, took the 3D models of our laptop avatars and created a collage—a sort of ‘group photo’ of the participants and the toy robot mascot with me in the background—and turned it into a large banner. When I asked him if this might be too much of an inside joke, he replied that he did not care if anyone outside the group understood it because he wanted to make art for us. This comment made me think about the audience I try to address with my own artworks. When I work on projects, I think of a fuzzy global audience, something that can be written into history books and shown in museums, but why not make artworks just for my friends? Something so niche that only selected people understand it. This idea is so innocent and simple, yet it caught me by surprise.

![Naoto Hiedas Banner and Laptop showing the exhibition website | 300](Exhibition(22).jpg)

I wanted to make something for the exhibition with the images we collected and shared online, pictures that document our time together, which we shared on the forum, in our group chat, and uploaded to the cloud. My initial thought was to train a GAN and create abstract synthetic images that fail to represent our collective experience. When I looked through the photo archive as a dataset, first as a large grid of pictures and then in rapid succession to identify outliers, I became awestruck: even though I spent less than a second with each image, some of them would trigger deep emotional responses and immediately transport me back to the house in Gosau. Thinking about Naoto’s statement of “making art for my friends”, I decided to use all 767 images in a rapid slideshow of 32 seconds. Each of the 24 frames per second is a different image, stretched to fit a 16:9 TV that got damaged on the way to the camp. I disassembled the TV and separated the LCD panel from its backlight, making the images only visible from a certain angle. The title of the work “we are the human” is borrowed from one of the meal prayers. All these elements comprise the work, which is both a slide show and movie, documentation and narrative, digital and analog.

![we are the human | 300](Exhibition(17).jpg)

The best viewing angle for my work was from a sunbed with a stereo speaker setup playing “LEEWA” from Ekheo. In this experimental sound piece, the artists used recordings of our voices to create a communal voice clone. With the *Oracle*, they devised a name and backstory for a new character and added anecdotal field recordings from the camp. Together these works create an eerie experience based on the digitally altered collective memories of our week in the Alps.

![A visitor listening to LEEWA| 300](Opening_10.11.21(16).jpg)
![View from the sunbed | 300](Opening_10.11.21(18).jpg)

Next to these pieces is a CRT TV displaying a fire with a contraption for a pot hanging above it. The pot contains a printed recipe created by Hess Jeon with GPT-3 that we didn’t dare to cook for the opening.

```
Chocolate Milk Pasta
The following is an algorithm for a vegetarian One-Pot-Wonder that was served at the “Camping with Computers” art exhibitions for silicon friends.

Ingredients:

1 stick butter

4 cups fresh veggies, chopped (see below)

1 cup dry pasta or broken spaghetti noodles

12 ounces water or chicken broth (chicken broth is better)

2 cups milk (chocolate milk is even better)

3/4 cup cheese (cheddar is best)

Assemble the ingredients and place them in a large pot over medium heat. Wait until the butter melts. Then turn up the heat. By now the butter should be sizzling and popping as it heats up the veggies and pasta. At this point you can add garlic, onions, corn, peas, or whatever else strikes your fancy. The key is to use fresh veggies that you like; this way you won’t notice that you’re eating veggies at all. Once the veggies and pasta are nice and hot (and they will be), add the water/broth and stir them thoroughly. Now the cooking begins! Put on a movie or text message competition with your friends and let them know you’ll be cooking for about five minutes. The trick here is to make sure that the pasta isn’t too soft; you don’t want it to disintegrate into a big blob of mush like most of your ex-girlfriends did. Now make sure you have a timer handy on your phone or on a wall clock or something. After five minutes have elapsed, turn off the heat, but leave the pot on the stove. Now for the next step: pour in the milk/chocolate milk and stir it vigorously for about 15 seconds. This will ensure that the cheese melts properly so that all its flavor can be absorbed by your tastebuds. Stir in the cheese until it’s completely melted, then serve it up! Serve with crusty bread so that you can sop up all of those yummy juices, but only use one piece of bread per person because it will fill you up fast. You want to save room for dessert! This recipe tastes best cold because then you can use that leftover cold chocolate milk to drink with it! If any is left over, put it in the fridge overnight so that it absorbs more of those yummy flavors. Then eat it cold for breakfast with a side of bacon or ham! Yum yum!!
```

![Hess Jeon “Chocolate Milk Pasta”|300](Exhibition(6).jpg)

On another set of monitors, Yuxi Liu showed a 3-channel video installation in which she is exploring the non-human world. During the first Covid-19 lockdown, she used a motion-sensor camera to capture the birds visiting her balcony. This collection served as an image set for a GAN model, which after finetuning, was supposed to recreate the photos of the visiting birds. Instead, it abstracted the animal so much that merely the surrounding was visible. It served as an interesting metaphor for how digitizing the natural world and statistical operations on it sometimes disregard the life within. During her stay at the camp, Yuxi wanted to capture more animals with a DIY raspberry pi camera, and even though she tried her best to lure more birds, the camera did not sense any in the end. We discussed the role of human and non-human connections within and outside of cities. While inner cities objectively have less animal life, the scarcity of resources makes them live closer to humans. In her last installment, she recorded birds over the rooftops and on the port of Rotterdam, overlooking the city and its environment.

![Yuxi Liu](Exhibition(31).jpg)

Davide Bevilacqua's work *POND*, a 4-channel video installation also addresses the digitization of natural phenomena. The screens lie flat on the floor on a tarp resembling a small pond inside the exhibition space. The images of the water's surface morph between each other, creating an unusual and oddly familiar ripple effect. It looks like the scattering of sunlight on top of a water surface; looking closer, one can see glitch artifacts we know when a video file is not loading correctly. 

![Exhibition view of POND by Davide Bevilacqua](Exhibition(25).jpg)

Giacomo Piazzi's *The Monkey* is a monolithic work consisting of two rows of red glowing displays continuously changing the pattern of the lit screens. He uses the infinite monkey theorem, which proclaims that if a monkey were to hit a random letter on a keyboard for an endless amount of time, it would eventually write the complete works of Shakespeare or almost surely any other finite text. *The Monkey* in Giacomo's work is a random number generator that turns a segment of the display on or off, possibly creating any text string. While a 7-segment display with 128 possible states is primarily used in digital clocks and meters because it can easily show numerical values, it is also possible to show most letters of the Latin alphabet. Because of their simplicity and due to their widespread use in electronic devices, Giacomo flips the monkey theorem on its head and becomes more interested in the human interpretation of the arbitrary values displayed on the screen. 

![Giacomo Piazzi, The Monkeys |300](Exhibition(12).jpg)

Another work focusing on text and its representation in artificial neural networks is *Latent Space Divination*[^18] by Błażej Kotowski. In this piece, he created an interactive meditation for one person in a tent to reflect on the position of word embeddings and their spacial relation within a sentence. A visitor sits down in front of a tablet computer with headphones and types in their intention. The word embeddings of the sentence, in turn, impact how a 3-dimensional graph will be created. While the graph is slowly unfolding, a sonification is generated for the participant, and after around 5 minutes, the object rotates around itself to create a solid object which represents the initial intention. 


![Visitor at the end of Latent Space Divination](Opening_10.11.21(6).jpg)

Finally *1-800-MYGRAVE* by Erica Jewel and Dasha Ilina is an installation in the center of the room that imagines a call center where the visitor becomes a worker for a fictional company that provides digital afterlife service. It is based on a video they made with Lina Schwarzenberg during the camp. In the style of a 1980s public service announcement, the infomercial warns the viewer of their accumulated data. It offers simple steps to protect digital files and avoid embarrassment after death. The cubicle in the gallery is fitted with a corded telephone and an inspirational poster where the visitor switches roles and takes on (automated) calls from people who ask or complain about the service. An instruction manual tells the participant how to respond and which buttons to press.  

![1-800-MYGRAVE installation view](Exhibition(21).jpg)


The open call for the camp had the goal “to enable embodied networks through the development of new forms of computational intelligence.”[^19] Looking back to the exhibition and the camp over a year later, I see many connections. While the works are separated by space and author, they often address the same thing from a different angle. For example, we explored anthropomorphous robots by embodying a virtual friend inside a plastic toy. Still, most closely, we looked into the processes of capturing the world through digital computers and how we relate to our data bodies. I’ve come to the conclusion that maybe real AI is the friends we made along the way.

![Photo by Hess Jeon taken before our first dinner at the Silicon Friend Camp](IMAG0038+0039.jpg)

## Reflection

In this chapter I briefly touched on the idea of an individual and how humans—in contrast to computer systems—are situated in and grow through inter-relational connections. Machines are not designed to create meaning through relationships, we are. I picked two projects in which I, with a group of others, explored how computers are changing our social environment and how they fit in between our conversations. Ironically, we are using all kinds of technological augmentations to communicate with each other about the machines that we are using. The artworks and experiments that we created through our conversations are often critical of the technology they highlight and address another public through the artifacts and stories we tell.

Moving forward I will dive deeper into the technological aspects that enable machines to be perceived as agents. In the following chapter I will specifically focus on speech as it is one of the most fundamental forms of communication and explain how its recognition and synthesis were incorporated into the computer.

---

[^1]: See @gadeWhatUbuntuDifferent2012. The term ubuntu originates from southern Africa and describes a humanist philosophy in which persons are interconnected. It is often used in phrases such as the Zulu ‘Umuntu ngumuntu ngabantu’, which translates to ‘A person is a person through other persons’. The term for personhood (ubuntu) itself is not clearly defined and has different meanings in different areas.
[^2]: @DescartesWasWrong2017.
[^3]: In the short story _On Having No Head_ D.E. Harding describes the realization that one can never experience their own head because the most important sensual organs are embedded in it. This could be an explanation why we perceive consciousness or the ‘self’ to be in our heads.
[^4]: @zarkadakesOurOwnImage2016, p.189.
[^5]: See @bostromAreYouLiving2001. The simulation argument was first proposed by Nick Bostrom. He argues that if we were able to create realistic simulated minds and worlds in the future, it is likely that we already live in a simulation.
[^6]: @FREEPORTANATOMIESBLACK.
[^7]: @AnatomyAISystem2018.
[^8]: Signal is an encrypted messaging app and Jitsi Meet is an open source video conferencing software.
[^9]: See cwc.radical-openness.org/siliconfriendcamp.
[^10]:  See @Babycastles which is a NYC based collective fostering and amplifying diverse voices in video game culture.
[^11]: The open source forum software _Discourse_ was hosted at the local servus.at data center.
[^12]: Bogna Konior, _The Dark Forest Theory of the Internet_; Rodney Brooks, Intelligence without Representation_; Matteo Pasquinelli, _The Arborescent Mind: The Intelligence of an Inverted Tree_.
[^13]: See @CanonCatMac2014.
[^14]: See @RuDALLE.
[^15]: See @Avatars. Together with the artist yang02, So Kanno modified multiple objects that could be remotely controlled from the web.
[^16]: See @HumanguidedBurritoBots2019.
[^17]: See @EverythingDLVIDOREILLY.
[^18]: See @kotowskiLatentSpaceDivination2021.
[^19]: This nonsensical sentence was generated by GPT3, prompting it to write the Open Call for the summer camp.
