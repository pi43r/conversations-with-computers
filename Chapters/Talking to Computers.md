## Talking to Computers

  

Female voices are spreading into living rooms and kitchens, on laptops, smartphones and small round speakers. Networked with computing machines around the world, they wait for their names to be spoken so that they can send your voice to a far off data center and analyze it. If the transcription does not succeed algorithmically, sometimes a human takes over the task of understanding. This person listens to snippets of conversations for hours, anonymized[^1] of course, and translates speech into text so that the machine recognizes the correct patterns in the recording the next time it tries. If the transcription is successful, the server sends the response back to the machine, which plays it in the friendly tone of a synthetic female voice.

  

### Human Automata

Stories of artificial assistants already existed in ancient myths. For example, the limping Hephaestus built himself servants made of gold who assisted him in his work, could speak, and even had a mind of their own.[^2] But it is only in the past few centuries that we have created the technological means to seriously address the construction of mechanical servants (at least virtually, as robotics is still far behind). At the height of automaton design in the 18th century, Frenchman Jacques de Vaucanson invented a mechanical duck that could not quack but appeared to have a functioning digestive tract. The mechanical attraction toured European noble houses and let its audience feed it grains. However, what the duck excreted was a prepared colored porridge that was in a hidden container. This principle of mechanical trickery was also used by Vacaucanson's contemporary Wolfgang von Kempelen, who caused a sensation with his chess-playing automaton in the shape of a turban-wearing Turk. The illusion that the automaton was acting autonomously was made possible by a small person inside the machine who controlled the puppet arm of the table via gears, levers, and pulleys. The hybrid machine is now the namesake of Amazon's Mechanical Turk, the largest platform for digital micro-labor, which lists click jobs for pennies. Today, it continues to perpetuate the illusion of autonomous machines with "artificial intelligence" that is covertly enabled by an army of underpaid workers.

  

Even though the chess playing Turk attracted attention, Wolfgang von Kempelen's scientific interest was in imitating human speech. He wrote down his investigations into phonetics in the work *Mechanismus der menschlichen Sprache* (Mechanism of Human Speech) and built an apparatus with a bellows, rubber hose and a wooden nose with which it was possible to produce basic phonemes.

Among those influenced by Kempelen's book was a German tinkerer named Joseph Faber, who demonstrated his own mechanically constructed speaking machine in 1841. This attracted little interest in Germany and was presented and improved four years later in the United States as the *Wonderful Talking Machine*. This machine, as described by author David Lindsay, consisted of a bizarre-looking talking head[^3] that spoke in a strange ghostly tone while Faber manipulated it with foot pedals and a keyboard[^4]. For the inventor, the machine did not lead to the financial success he had hoped for, though it was presented as the Euphonia in London, where it at least delighted the father of telephone inventor Alexander Graham Bell and served as the boy's inspiration for his first talking machine.

  

For the exhibition *Mensch-\[in der]-Maschine* at the ZKM (Center for Art and Technology Karlsruhe), media artist Michael Markert built *kII (Kempelen 2.0)*, an interactive installation in which visitors can playfully control a speech synthesizer by moving, opening and closing their hands.[^5] In doing so, he brings Kempelen's speech apparatus into the 21st century with the help of an 8-bit PIC microcontroller and sensor technology. As Kempelen's apparatus it alienates the voice in such a way that it creates mostly meaningless vocal sounds that enable new gesticulatory speech interactions.

The development of electricity certainly made new human-machine interactions possible. For example, the invention of the telephone and radio allowed the human voice to be transmitted over long distances. To optimize the transmission of speech, Bell Laboratories researched digitizing the voice, for which they developed the vocoder (voice encoder). Demonstrated at the 1939 World's Fair in New York, the *Voder* omitted the speech input and transformation of the vocoder and allowed electrical synthesis of the voice via a console with 15 keys and a foot pedal.[^6] The keyboard was operated by specially trained women, and in a recording advertised as the robot speaker, while it's unclear if they mean the machine or the woman, who is speaking through it.

  

Human computers were popular and necessary for war machines and research purposes in the 1930s and 40s. Mostly it was women who prepared mathematical tables, e.g., for the use of ballistic projectiles. With the advent of the first digital calculators, female mathematicians, who were often denied higher scientific positions, were employed as programmers of these universal electric machines.[^7] The 6 people who programmed the first universal computer ENIAC include Betty Snyder Holberton, Jean Jennings Bartik, Kathleen McNulty Mauchly Antonelli and Marlyn Wescoff Meltzer.[^8] Initially, the (mechanical) computer was programmed with punched cards and cables for specific operations. It soon became clear that programming complex systems required an abstract semantic language, for which reason the programming languages Fortran by John W. Backus, Lisp by John McCarthy, and COBOL by Grace Hopper were invented in the 1950s. The latter is strongly oriented to written English. Intended for business applications, it was the first attempt to use natural language for computer programming.

The second half of the 20th century saw the emergence of the myths about computers that we are familiar with today. Stories of anthropomorphic beings, like the board computer HAL9000 in Space Odyssey or Samantha in the movie Her. In both films, the disembodied voices become aware of their emotions and emancipate themselves from their human programming. Artist Tillmann Ohm makes this clear in his work *Reflections of HAL and Samantha*[^9] by having the two artificial beings engage in a dialogue, cutting their original voice-overs together. While Samantha is convinced that the overwhelming and sometimes hurtful process of her learning algorithm improves the complexity of her emotions, HAL is consequentially interpreting them as errors in human programming and analyses the estimated malfunction.

  

### Conversational Agents

For Amazon founder Jeff Bezos, the computer in Star Trek was the inspiration for investing in the cloud-based voice software Alexa. The product was initially marketed as a networked speaker. The software is now expanding to other items, including watches, smartphones, jewelry, light bulbs and doorbells. The aggressive price war with Amazon-connected products is partly to capture the connected home market, but also to collect as much natural voice data as possible. Over the past 15 years, deep weighted networks[^10] have become popular for classification and pattern recognition tasks in computer science. In many cases, these systems require large amounts of data to recognize words in spoken text. A global internal database of speech recordings enables the company to improve its speech recognition. The intrusion into privacy is immense and has already been used by U.S. law enforcement agencies as evidence in a court case.[^11]

But there is another, more ethical, way: The Mozilla Foundation's *Commonvoice* project relies on people voluntarily recording their voices for computer models, and the resulting speech recognition and synthesis software can be offered with an open source license.[^12]

  

Artist Lauren Lee McCarthy plays with these tensions between intimacy and privacy, convenience and agency. In her projects LAUREN and SOMEONE, she installs connected devices into volunteers homes and either acts as a control system herself or lets others remotely monitor the volunteers and control the devices in their homes. This creates an interesting tension, when the person knows that there is an actual human listening and watching from afar. At the same time the artist and performers find themselves in a position of a helpful voyeur.

However, the role of human labor behind voice assistants is not just about executing and understanding commands. People tend to interpret voices and categorize them according to age, gender and social status. Companies take advantage of this and design their voice software according to certain identity schemes, which are provided with a history, hobbies and preferences. It is precisely this illusion that excites users and makes the product interesting. In a UNESCO think piece titled *I'd blush if I could*[^13], they explore harmful gender biases associated with digital assistants. The voice assistants of major tech companies are scripted by default as female personas with smart, humble, and sometimes funny personalities. The teams working on voice assistants try to avoid this aspect, because Apple, Microsoft and Google ask their employees to refer to their headless voices as “it” and when the persona get’s asked the question directly winds out with a joke. Only Alexa answers what is obvious in the default design of all of them with “I’m female in character”. By being submissive, they thus support a patriarchal image of women that we already know, in a historical context, from human computers and other secretarial roles. The paper calls for women to be more empowered and involved in IT. It calls for AI software to avoid gender attributes whenever possible, and for AI assistants to take a clear stand against sexist behaviors.

  

Researcher and artist Nadine Lessio creates useless voice assistants to critique the current corporate agenda of productivity, efficiency, and consumption. She does this by using the programming interfaces provided to make apps for corporate voice assistants. For example, she explores the concept of a depressed home assistant with *SAD Home (Depressed Alexa 1.0)*[^14], an Alexa hack that grants users their wishes depending on the weather and other mood factors, sometimes it simply turns itself off.

This scripted denial of a capitalist logic ironically uses the same technique as the company behind it. Voice assistants are carefully crafted by a team of creative professionals working in the field of “conversation design”. In the book *Talk to me*[^15] the Author James Vlahos describes that many people in the field are far away from computer science and more commonly had careers in the liberal arts. The teams are made up of authors, playwrights, comedians, actors as well as anthropologists, psychologists, and philosophers who imagine the personality of the AI persona that should represent the brand. To create the character, they have to come up with all possible questions and create various answers for each of them. Vahos recalls asking Microsoft’s Cortana “Where do you come from?” and the female voice replies “I was made by minds across the planet”.[^16] And even though the designers decided to use the first person “I”, they really are talking of themselves carefully crafting the answers played back by the loudspeakers around the world.

The tedious process of mapping out all questions and creating answers for them is mostly done through creative writing, but also utilizes careful statistical analysis of the questions users send to the cloud.

It is interesting how the term AI is used in the context of voice computer interfaces, because there is nothing “smart” about it, just a winding flowchart of if-else conditions. What might be clever is the nefarious way of how companies trick people into the belief of computer personalities, encouraging people to interact with the device like children playing with dolls. And when a company like Microsoft has experimented with a more sophisticated chatbot, like Tay[^17], it started to repeat the racist and misogynistic slurs of twitter users and consequently must be heavily filtered. But more on this in a later chapter on stochastic text generation.

  

## Artificial Voices

  
  
  

[^1]: Metadata and references to the account are deleted before the review. Complete anonymization of the voice is not performed.

[^2]: "Hephaestus then limped out of the door'; and maidens supported the ruler, golden ones, like living ones, with youthful charming education: These have understanding in the breast, and speaking voice, Have strength, and also learned art work from the gods." (Homer, Iliad 18, 417-420; link: https://www.projekt-gutenberg.org/homer/ilias/ilias183.html)

[^3]: Fabers machine was first presented with female mask in USA and later in London under oriental motif wearing a turban.

[^4]: D.Lindsay, 1997. Link: https://www.inventionandtech.com/content/talking-head-1

[^5]: Serexhe et al. 2007, p. 74. And project description online. Link: http://www.audiocommander.de

[^6]: A video recording of the Voder demonstration can be found in the AP Archive under Human Voice Machine. http://www.aparchive.com/metadata/youtube/5f098b1f3e8b4d09b8de30dcecc42f99

[^7]: A focus on black women who worked as computers for NACA (NASA's predecessor) can be seen in the film Hidden Figures, 2016.

[^8]: The story of the ENIAC programmers is told in the documentary The Computers, 2016.

[^9]: Project description of Reflections of HAL and Samantha online. Link: https://tillmannohm.com/reflections-of-hal-and-samantha/

[^10]: As described in the introduction I use "weighted" instead of "neural".

[^11]: The first Alexa recording in a court case was handed over after the defendant agreed handing over his data. The Independent, Amazon Echo could become key witness in murder investigation after data turned over to police, 2017. Link: https://www.independent.co.uk/news/world/americas/amazon-echo-murder-investigation-data-police-a7621261.html

[^12]: Link: https://commonvoice.mozilla.org/de

[^13]: The title “I’d blush if I could” is also the response Siri gives to the insult “You’re a bitch”

[^14]: Nadine Alessio’s project website. Link: http://nadinelessio.com/projects.html

[^15]: Vlahos, 2020.

[^16]: Ibid. p. 117.

[^17]: Tay was the name of a chat bot Microsoft intended to have a teenage personality and could be interacted with over multiple channels. Twitter trolls co-opted the bot with sexist, racist and antisemitic questions that the bot replied to with generic answers. They also made use of a repeat-after-me phrase to make it look like the bot is spewing hateful comments itself. After only 16 hours Microsoft deleted all accounts and the PR disaster was immense, with headlines happily personifying the AI that has learned to be racist. But no continuous learning algorithm was involved. Link to a blog post by Russel Cameron Thomas explaining the technology stack behind Tay: https://exploringpossibilityspace.blogspot.com/2016/03/microsoft-tayfail-smoking-gun-alice.html