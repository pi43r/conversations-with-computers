# Hello, World!

The common first letters a programmer types into it's digital computing machine is some form of "hello world" along with braces, punctuation and words that the machine should interpret. After executing this short paragraph of text the computer likewise responds with "Hello, World!".
This ritual of greeting each other (and the world) is accredited to Brian W. Kernighan, who wrote the popular guide *The C Programming Language*[^1] in 1978 as he explains that the only way to learn a programming language is by writing programs in it.
I wanted to start this introduction with the same words, as I am typing text into a computer and which letters simultaneously appear on the screen in front of me. But this translation from the keyboard of my laptop to the pixels on the screen is only possible by thousands of lines code hidden in the source code of the program. There are countless amounts of people who have written the software and operating system I am currently using to write this text. And there are even more people who wrote the software, the programmers have used to write the word processor I am using right now.
In this thesis I want to focus on the known and unknown human connections we make with and through computers. My hypothesis is that the current trend of framing "Artificial Intelligence" as autonomous computational beings, would be better described as "Collective Intelligence", where the programming of such systems is a collaborative effort with many hidden players. While I address some technical details of current machine learning systems, I will put them into social context, because software is inherently a social tool. And ultimately, as an artist, address these topics through aesthetic experiences, which go beyond logic and language.

A book is never written alone, in fact everything we do is influenced by others. And while I focus on the social nature of computing and I am influenced by many of my peers and created works with others, I am describing these topics from my subjective perspective. I don't claim any objective truths on the descriptions of the collaborative works I have done and am naturally biased towards my own contribution of it. As this thesis is written in the context of an art program, I tend to deviate from rigorous scientific methods and describe my observations more freely. I am certain that there will not be a definitive answer as there is not even an answerable research question, but even more questions will come up along the way.

## Dreaming
My journey into the hype machine of "Artificial Intelligence" started around 2015, when Google released DeepDream[^2] on it's research blog. Alexander Mordvintsev, Michael Tyka and Christopher Olah were initially trying to peek inside of an "Artificial Neural Network" that was "trained" for image classification tasks. They reversed the task of the classifier and instead of identifying what a set of pixels look like, they were changing the pixel values to look more like what the network has "learned". This created images that amplified the textures embedded in their networks, transforming the input image into swirls of PuppySlugs[^3]. This imagery that reminded people of bad dreams and hallucinogenic trips was widely shared on the internet, which skyrocketed the awareness that "Deep Learning"[^4] and biologically inspired computing has come back from it's hibernation in the AI winter. Since 2012 "Artificial Neural Networks" have made an incredible comeback into the field of computer vision. Where other researchers have long moved to different techniques for image classification Yann LeCun and Ian Goodfellow have kept researching on translations of simplified brain models to computer systems and finally hit a breakthrough, due to computational power and availability of data. The latter was compiled by a team around Fei-Fei Li, who created ImageNet, a dataset of images organized into categories by anonymous workers from the internet. The ImageNet project held a yearly competition[^5] since 2010 and for the first two years the best algorithm was recognizing these images with a 74% accuracy, until AlexNet, a convolutional neural network, topped the score with 85% and woke up the computer vision community to the potential powers of "Artificial Neural Networks".
Finally with DeepDream this technique became tangible for the general public, as it created something to look at, something for humans to empathize with the outputs of an abstract mathematical model. This tendency to anthropomorphize this type of software becomes already clear in the way we use language to describe it. We talk of "Neural Networks" as if they are biological entities, that can be "taught" and which "learn", "experience" and "read" data from the world.
This was a turning point that got me and many other artists interested in "collaborating" with seemingly autonomous machines. Machines that we do not have to understand through mathematics, but through interpretation and experimentation. Yet, the outputs of DeepDream quickly became kitsch. Google shared the code with an open source license and many people created apps and APIs to generate PuppySlug textures on top of your own image[^6]. As with most other memes on the internet the hype around DeepDream died quickly and by the end of 2015 the world was already saturated with computer generated hallucinogenic images. Other researchers have since picked up[^7] on visualizing nodes in "Artificial Neural Networks" and Alex Mordvintsev has since become an artist (together with his wife), exhibiting in art fairs[^8]. What stayed was the notion that "Artificial Intelligence" became some form of computational being, different from the humans, who wrote the code and this in turn created an immense interest for artists (and anyone, really) to create images, texts and sounds based on these algorithms and large datasets.

## Terms
I have been deliberately using quotation marks around some of the previous words, as I am critical of the language we use when talking of AI systems. In his book *The Artist in the Machine* Arthur I. Miller comes to the conclusion that machines could in fact be seen as creative and will be considered "artists, writers, and musicians in their own right."[^9] He is using a typical techno-utopian argument that the technology is not quite there yet to *really* be creative, but it will change in the foreseeable future. At the same time Miller is explaining in great detail the actual creative work of Mordvintsev and his human experience of insomnia to come up with the generative system for DeepDream and how he shared it with his peers at Google. Alex Mordvintsev was not collaborating with his computer, he created an emergent algorithmic system with it. The software does not hang pictures on exhibition walls, talk to gallerists and has no agency in the process if it were to generate pictures or not.
Peter Weibel has formulated it bluntly: Artificial intelligence does not exist. But an ensemble of machines, media, programs, algorithms, hardware, and software has resulted in an extraordinarily large, diverse, and productive field of research that is called AI.[^10] Where Arthur Miller is feeding the narrative of humanoid robots with glowing blue brains[^11], most computer scientists in the field of artificial intelligence today are working in the subdiscipline of "Machine Learning". In the last 10 years the terms have converged in the media landscape, but where intelligence is rejected as a suitcase word with a multiplicity of meanings, "Machine Learning" tries to define the task more narrowly to some form of pattern recognition and extrapolation of existing data. They are using a variety of computational and statistical techniques to form abstract models for domain specific problems. In these fields "Artificial Intelligence" is a buzzword to convince governments and venture capitalists to fund projects. 
The artist and researcher Francis Hunger has recently shared a list of alternative terms in an attempt to dehumanize our language for AI systems:
> 1. 'Artificial Intelligence' => ' Automated Pattern Recognition' 
> 2. 'Machine Learning' => 'Machine Conditioning' OR ‘Automated Classification’ 
> 3. 'Neural Network' => 'Weighted Network'
> 4. ‘Deep Learning’ => ‘Deep Conditioning’ 
> 5. ‘Neuron’ => ‘Weight’ or ‘Node’
> \- [@databaseculture](https://twitter.com/databaseculture) [^12]   

In an accompanying talk[^13] he explains the aim of those terms is to invoke passivity, that we deal with machines and humans set those machines in motion, even when in the end we form "human-machine assemblages".
I like many of the proposed terms, even though they are still closely associated to biological operations. The conditioning of machines, for example, reminds me of Pavlov's dog experiments or B.F. Skinner's box to modify pigeon behavior by reinforcement or punishment.[^14] This analogy, though, serves the purpose of creating an image of the machine as a system, that can be controlled by changing the parameters of it's virtual environment. Therefor I will use "conditioning" and "weighted networks", where it is applicable. Using "Automated Pattern Recognition" instead of "Artificial Intelligence", however, becomes too narrow of a definition and is counterintuitive to me, as AI serves exactly the function of being ill-defined. Pei Wang has made a great effort in defining the different strands of AI research and their working definitions.[^15] He clusters them into Structure-AI (recreating the human brain), Behavior-AI (recreating human actions), Capability-AI (domain problem solving), Function-AI (developing cognitive functions) and Principle-AI (finding underlying principles) and comes up with his own working definition to where AI research should be headed and how it can be unified.
My initial goal for this thesis was to completely avoid the term "Artificial Intelligence", but as I have already failed in that task and coming up with a less anthropomorphic term for it does not seem feasible to convey the research in the field and it's media reception, I will keep using the abbreviation AI. Contrary to articles and sci-fi novels I will not use the personification of "an AI", but will rather talk of AI systems, meaning emergent complex programs. Many of the systems today use statistical modeling, yet nobody would ask the question, if statistics can be creative or conscious. Going forward I want to explore how AI systems can include the human knowledge and work that goes into building them, which is challenging the AI ideology of machine autonomy and proposes human-centric goals, rather than building a machine as a goal in itself.

I structured this thesis around 4 chapters, which combine historical, computational and collective knowledge. Starting with a history of talking machines from Wolfgang von Kempelen's speech automatons to digital assistants today, not forgetting that the first computers were women doing calculation. The literal act of speaking to computers sets the base of defining that we are actually talking through computers with other humans.
The second chapter deals with the building blocks for complex statistical modeling in AI systems. To make such systems possible, researchers need to create large datasets, often using ethically questionable techniques aggregating data from internet users. I will look closely into the StyleGAN dataset, as it serves a dual purpose, because the model defined another turning point for artists to generate synthetic media.
The same is true for GPT-2, a model that can generate coherent looking text based on large amounts of scraped websites and books. In the third chapter I will explore the transformer architecture and how artists are using it to make (non-)sense of it.
Lastly I am revisiting collective experiences that I have been organizing with other artists. I had the great pleasure to work with the net culture initiative servus.at to organize the *Silicon Friend Camp* in the Austrian mountains, where we invited 17 Artists for a week long retreat, focusing on human computer conversations. The camp resulted in the exhibition *Camping with Computers* and an online symposium on *Conversations with Computers*.

[^1]: *The C Programming Language Book* defined many standards of programming languages today and how technical descriptions are written. While it focuses on C and the UNIX system, I find this advice in *Chapter 1.1 Getting Started* particularly interesting "On other systems, the rules will be different; check with a local expert." as it describes the social necessity of learning computers specifically.
[^2]: https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html
[^3]: The initial classifier was conditioned on ImageNet, which contains many images of dog breeds. Therefore DeepDream is biased to generate textures of dog faces.
[^4]: The idea of convolutional neural networks dates back to the 1950s and 60s to the works of David H. Hubel and Torsten N. Wiesel, who recognized receptive fields in the visual cortex of monkey brains. Ian Goodfellow calls the technique "Deep Learning", because the .
[^5]: https://image-net.org/about.php
[^6]: Mike Tyka has compiled a list of projects, released within a month of publishing the source code http://mtyka.github.io/code/2015/07/21/one-month-after-deepdream.html
[^7]: A collection of tools and papers for feature visualization is collected at the github tensorflow/lucid repository. Note that Chris Olah and Alex Mordvintsev are contributors. Even more examples and explanations are collected in the *interpretable machine learning* book by the statistician Christoph Molnar, who also notes that "Feature visualizations give unique insight into the working of neural networks", but the "visualizations can convey the illusion that we understand what the neural network is doing". https://christophm.github.io/interpretable-ml-book/cnn-features.html
[^8]: https://www.artnome.com/news/2018/12/30/deepdream-creator-unveils-very-first-images-after-three-years
[^9]: Miller 2019, 122. 
[^10]: Translated from the article 'AAA - Art, Algorithmen, Artificial Intelligence' at Kunstforum Bd. 278 Link: https://www.kunstforum.de/artikel/aaa/
[^11]: Referring to typical AI stock images. Counter imagery is currently built by https://betterimagesofai.org/
[^12]: https://twitter.com/databaseculture/status/1413462059291975680
[^13]: *Unhype AI*, Link: http://www.irmielin.org/unhype-ai/
[^14]: In behaviorist psychology Ivan Pavlov's experiments with dogs is known as classical conditioning and B.F. Skinner who experimented on rats and pigeons using lever machines is called operant conditioning. 
[^15]: Wang 2019.