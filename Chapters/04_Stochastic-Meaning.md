# Stochastic Meaning

## Attention is all you need

Understanding language is an essential aspect for computer assistants to be truly useful. However, language is a challenging area since words can have various meanings depending on the context. Furthermore, there are multiple languages and different ways of converting spoken language into written symbols.
The use of computers for natural language processing (NLP) has been a subject of research since the invention of computers. One of the earliest examples of symbolic NLP is ELIZA, a computer program developed by Joseph Weizenbaum in the 1960s that simulated a conversation between a patient and a therapist. ELIZA used pattern matching and substitution to generate responses based on the user's input, giving the impression of understanding what was being said. For example, if the user said “I feel sad”, ELIZA might respond with “Why do you feel sad?” or “Tell me more about your feelings.”
While ELIZA was fairly limited in its capabilities, it sparked the interest and imagination of the general public 

One of the earliest examples of symbolic NLP is ELIZA, a computer program developed in the 1960s that simulated conversations between a patient and therapist. ELIZA utilized pattern matching and substitution to generate responses based on user input, creating an impression of understanding what was being said. Although ELIZA had limited capabilities, it paved the way for more advanced NLP techniques.

Another approach to NLP is through the use of conceptual ontologies, which are structured representations of knowledge in a particular domain.  These ontologies can be used to help computers understand natural language by mapping words and phrases to their corresponding concepts in the ontology. For example, if someone says "I want to buy a red car," an ontology could map "red" and "car" to their corresponding concepts and infer that the person is interested in purchasing a vehicle with a specific color.

Symbolic NLP methods also include techniques such as parsing, semantic analysis, and machine translation. Parsing involves breaking down sentences into their constituent parts (such as nouns, verbs, and adjectives) and analyzing how they relate to each other syntactically. Semantic analysis goes further by attempting to understand the meaning behind words and phrases based on their context. Machine translation uses these techniques to automatically translate text from one language into another.

While symbolic NLP methods have been successful in some applications (such as chatbots and question-answering systems), they have limitations when it comes to handling ambiguity and understanding human emotions or nuances in language. As a result, more recent approaches to NLP have focused on machine learning techniques that allow computers to learn from large amounts of data without relying on pre-defined rules or ontologies.

- Prayers to GPT
## Computing Reality
- The Chiromancer