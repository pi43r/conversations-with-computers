# Stochastic Meaning
	What I had not realized is that extremely short exposures
	to a relatively simple computer program could induce powerful de-
	lusional thinking in quite normal people.[^1]

## Symbolic Language

Understanding language is an essential aspect for computer assistants to be truly useful. However, language is a challenging area since words can have various meanings depending on the context. Furthermore, there are multiple languages and different ways of converting spoken language into written symbols.

The use of computers for natural language processing (NLP) has been a subject of research since the invention of computers. One of the earliest examples of symbolic NLP is ELIZA, a computer program developed by Joseph Weizenbaum in the 1960s that simulated a conversation by rephrasing the input to form questions. ELIZA used pattern matching and substitution to generate responses based on the user's input, giving the impression of understanding what was being said. For example, if the user said “I feel sad”, ELIZA might respond with “Why do you feel sad?” or “Tell me more about your feelings.”

While ELIZA was fairly limited in its capabilities, it sparked the interest and imagination of the general public which saw the toy program as a breakthrough in artificial intelligence. Many people were fascinated by the idea that a machine could understand and respond to human language, even if the responses were simple and scripted. Joseph Weizenbaum himself was shocked about the willingness of people to attribute consciousness to even the most simple programs, like the 200 lines of code he wrote for the DOCTOR program that simulated a Regorian psychotherapist. In a famous anecdote Weizenbaum explains that his office assistant, who was quite familiar with the program, demanded for him to leave the office because she was sharing intimate thoughts with the computer. Some psychologists even considered using such a computer program to be able to treat more people in a shorter time, which for Weizenbaum was a horrendous thought and finally made him doubt the future of humanity and computers. In his 1976 book “Computer Power and Human Reason”, Weizenbaum argues that the increasing reliance on computers to solve problems and make decisions is a dangerous trend that could lead to dehumanization and loss of autonomy of human beings. Conflating the computer with the human mind ultimately reduces the human to a computational being. He warns that we should not confuse the power of machines with human intelligence, creativity, and empathy, which are essential for ethical and meaningful interactions.[^2]

ELIZA paved the way for further development in natural language interaction. In the 1970s some programmers created text-based games like the game *Colossal Cave Adventure* (1976) which allowed users to interact with the game world using natural language commands.
At the same time the use of conceptual ontologies, which are structured representations of knowledge in a particular domain became popular. These ontologies can be used to help computers understand natural language by mapping words and phrases to their corresponding concepts in the ontology. For example, if someone says "I want to buy a red car," an ontology could map "red" and "car" to their corresponding concepts and infer that the person is interested in purchasing a vehicle with a specific color. One of the biggest endeavors in mapping words to concepts was the creation of WordNet in the 1980s, which is a lexical database of English words and their semantic relationships.

Even until the early 2000s programmers came up with larger and more complex rule-based chatbots. Creating systems like A.L.I.C.E. (1995) which used complex set of rules to simulate conversation with users. However, these systems were limited by their reliance on pre-programmed responses and lacked the ability to learn and adapt to new situations. The web application Cleverbot (2008) and it’s predecessor jabberwacky (started in 1988, online since 1997) shifted static databases to one that is constantly growing.[^3] By capturing every conversation and creating links of question-answer pairs, the system could use a fuzzy search algorithm to present the user with a likely response that was typed by another human previously.

While symbolic NLP methods have been successful in some applications (such as chatbots and question-answering systems), they have limitations when it comes to handling ambiguity and understanding human emotions or nuances in language. As a result, more recent approaches to NLP have focused on machine learning techniques that allow computers to learn from large amounts of data without relying on pre-defined rules or ontologies.

## Attention is all you need




- Prayers to GPT
## Computing Reality
- The Chiromancer

[^1]: [@weizenbaumComputerPowerHuman1976]
[^2]: Ibid.
[^3]: See [@JabberwackyThoughtsArtificial2006] & [@Cleverbot]