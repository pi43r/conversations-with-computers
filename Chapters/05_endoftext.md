# <|endoftext|>

## Termination

I started this journey making new friends through a shared interest in computers. Trying to understand what “artificial intelligence” means, where it came from and what this ideology envisions for our future with computer systems. I was intrigued by the sci-fi idea of virtual assistants and artificial pets that communicate with us through a common voice interface. However, as I delved deeper into the subject, I discovered a vast difference in how human language evolved and how computers are designed to analyze piles of data. This data scraping process is enabled by the internet and has its own politics, raising questions about consent and what it actually is that these new AI systems are ‘learning’. Ultimately, I circled back to analyze the architecture of generative text models and how they create meaningful output. Only to realize that ‘intelligent’ machines are merely an illusion which exploit our innate ability to experience empathy and sympathy, particularly when they use symbols from our written languages. It is important to note that computers are not magical devices but simply designed to perform magic tricks.

At first, my goal was to reveal the human efforts involved in constructing AI systems. This included the invention of electrical computers and coding languages, as well as the individuals who create, label, and organize data for these systems. I also recognized the significance of people utilizing these tools and how they are embedded into social structures. My hope was to change the way we perceive AI technologies by acknowledging their origins in human creativity; maybe even cherish them for the collaborative effort that makes them possible. However, I came to believe that exactly this obfuscation of human labor is a deliberate and essential part for the development and promotion of AI systems.

The myth of the self-sufficient AI agent, capable of learning and improving on its own, is a powerful marketing tool. It promises a future where machines will make our lives easier and more efficient, without requiring any human input or intervention. This vision of AI as a fully autonomous entity not only ignores the fact that humans are integral to its development, but also obscures the potential consequences of this technology. As AI systems continue to be integrated into our daily lives by large corporations with the prospect of ‘natural technological advancement’, it is important to recognize that they are not neutral or objective tools. Machines can only represent what can be abstracted and simplified and only encode a small subset of what exists in the world. They are built by humans who make selective choices and bring their own biases, values, and perspectives into the software. The computer then is used to cloak their involvement. As Joseph Weizenbaum writes:

>“The myth of technological and political and social inevitability is a powerful tranquilizer of the conscience. Its service is to remove responsibility from the shoulders of everyone who truly believes in it. But, in fact, there *are* actors!” [^1]

Weizenbaum’s comment is not only a demand for greater responsibility to those in tech industries and to look for the humans involved in actually making the decisions, he also reminds us that *we* are actors. We all have choices and responsibilities in order to shape the future of how we use computers and what we use them for. We are not, and should not, see ourselves just as victims of computational progress.

Projects like the *Silicon Friend Camp* are a way for a communal and playful interaction, not only with machines, but mainly with one another. It is a way to create collectives that digest and discuss both the technological and social implications of computer systems; it fosters an environment where people can learn from each other, share ideas, and collaborate on projects that are not driven by profit or market demand. The projects developed there deal with different subjects from the environment, other animals, virtual avatars, to or our legacy in digital data, reflecting on much broader perspectives beyond technology. Together we were able to create a collective voice, quite literally, and share it with others who were not co-present. The camp made me realize again, that technology is not a means of itself, it is a social instrument but often enough it gets in the way of communication and isolates us in front of our screens.

Both, the technological and social aspects have informed my body of work and I hope to continue my journey into *artificial social networks*, as I have come to see these strange artifacts compressing human experience into data points. There are a couple of things I would have wished to write more about, like the intricacies of coding languages and the humor of their esoteric counterparts, or the vast exploitation of labor orchestrated by computers. But for now it is time to terminate the program and spend some time with my friends.<|endoftext|>[^2]

## Contribution

Thank you to my supervisors *Manuela Naveau*, *Christa Sommerer* and *Laurent Mignonneau*.

A special thanks to *Davide Bevilacqua* and the *Servus.at* association for making the *Silicon Friend Camp*, exhibition and symposium possible.

Thank you to *Bani Budassin* who invited me to write for Temes des Disseny which formed my thoughts around Dataset Art. 

And of course to all my new and old friends, my fellow contemporaries and collaborators.
I am because you are.

[^1]: @weizenbaumComputerPowerHuman1976, p. 241
[^2]: GPT uses this token to give the model a reference when a piece of text is finished and new one beginnings. In this thesis I selectively used the models GPT-3 and GPT-3.5 (and it’s variant ChatGPT) to rephrase parts of my text, find synonyms, get inspiration when I’m stuck or correct my writing. Most of the time it created very uninspiring and generic output, but sometimes I could find exactly the right phrase or word. It also helped me validate some of the technical language I was struggling with. As I am also using spellcheckers and search engines I do not consider this unethical or plagiarism, but by using this technology I might have accidentally quoted someone without attribution.