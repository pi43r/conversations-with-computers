# <|endoftext|>

## Termination

I started this journey with new friends through a shared interest in computers, trying to understand what “artificial intelligence” means, where it came from, and what this ideology envisions for our future with computer systems. I was intrigued by the sci-fi idea of virtual assistants and artificial pets that communicate with us through a common voice interface. However, as I delved deeper into the subject, I discovered a vast difference in how human language evolved and how computers are designed to analyze piles of data. The internet enables this data scraping process and has its own politics, raising questions about consent and what these new AI systems are ‘learning’. Ultimately, I circled back to analyze the architecture of generative text models and how they create meaningful output. Only to realize that ‘intelligent’ machines are merely an illusion that exploit our innate ability to experience empathy and create meaning, particularly when interpreting symbols from our written languages. It is important to note that computers are not magical devices but are simply designed to perform magic tricks.

At first, my goal was to reveal the human efforts involved in constructing AI systems. This included the invention of electrical computers, coding languages, and the individuals who create, label, and organize data for these systems. I also recognized the significance of people utilizing these tools and how they are embedded into social structures. I hoped to change how we perceive AI technologies by acknowledging their origins in human creativity; maybe even cherish them for the collaborative effort that make them possible. However, I came to believe that exactly this obfuscation of human labor is a deliberate and essential part of the development and promotion of AI systems.

The myth of the self-sufficient AI agent, capable of learning and improving independently, is a powerful marketing tool. It promises a future where machines will make our lives easier and more efficient without requiring human input or intervention. This vision of AI as a fully autonomous entity ignores the fact that humans are integral to its development and obscures the potential consequences of this technology. As AI systems continue to be integrated into our daily lives by large corporations with the prospect of ‘natural technological advancement’, it is important to recognize that they are not neutral or objective tools. Machines can only represent what can be abstracted and simplified and only encode a small subset of what exists in the world. They are built by humans who make selective choices and bring their biases, values, and perspectives into the software. The computer is then used to cloak their involvement. As Joseph Weizenbaum writes:

>“The myth of technological and political and social inevitability is a powerful tranquilizer of the conscience. Its service is to remove responsibility from the shoulders of everyone who truly believes in it. But, in fact, there *are* actors!” [^1]

Weizenbaum’s comment is not only a demand for greater responsibility to those in tech industries and to look for the humans involved in making the decisions. He also reminds us that *we* are actors. We all have choices and responsibilities to shape the future of how we use computers and what we use them for. We are not, and should not, see ourselves just as victims of computational progress.

Projects like the *Silicon Friend Camp* are a way for communal and playful interaction, not only with machines but mainly with one another. It is a way to create collectives that digest and discuss both the technological and social implications of computer systems; it fosters an environment where people can learn from each other, share ideas, and collaborate on projects that are not driven by profit or market demand. The projects developed there deal with different subjects, from the environment, other animals, and virtual avatars, to our legacy in digital data, reflecting much broader perspectives beyond technology. Together we created a collective voice, quite literally, and shared it with others who were not co-present. The camp made me realize again that technology is not a means of itself; it is a social instrument, but often enough, it gets in the way of communication and isolates us in front of our screens.

Both the technological and social aspects have informed my body of work, and I hope to continue my journey into *artificial social networks*, as I have come to see these strange artifacts compressing the human experience into data points. I would have liked to write more about some things, like the intricacies of coding languages and the humor of their esoteric counterparts or the vast exploitation of labor orchestrated by computers. But for now, it is time to terminate the program and spend some time with my friends.<|endoftext|>[^2]

## Contribution

Thank you to my supervisors *Manuela Naveau*, *Christa Sommerer* and *Laurent Mignonneau*.

A special thanks to *Davide Bevilacqua* and the *Servus.at* association for making the *Silicon Friend Camp*, exhibition, and symposium possible.

Thank you to *Bani Budassin* who invited me to write for Temes des Disseny, which formed my thoughts around Dataset Art. 

And, of course, to all my new and old friends, contemporaries, and collaborators.
I am because you are.

[^1]: @weizenbaumComputerPowerHuman1976, p. 241
[^2]: GPT uses this token to give the model a reference when a piece of text is finished and new one beginnings. In this thesis, I selectively used the models GPT-3 and GPT-3.5 (and its variant ChatGPT) to rephrase parts of my text, find synonyms, and get inspiration when I’m stuck or correct my writing. It often created very uninspiring and generic output, but sometimes I could find precisely the right phrase or word. It also helped me validate some of the technical language I struggled with. As I am also using spellcheckers and search engines, I do not consider this unethical or plagiarism, but I might have accidentally quoted someone without attribution by using this technology.