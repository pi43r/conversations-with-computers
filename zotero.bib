
@online{AAA,
  title = {AAA},
  url = {https://www.kunstforum.de/artikel/aaa/},
  urldate = {2022-01-16},
  abstract = {AAA Art, Algorithmen, Artificial Intelligence von Peter Weibel Künstliche Intelligenz (K.I.) bzw. Artificial Intelligence (A.I.) gibt es nicht. Aber ein Ensemble von Maschinen, Medien, Programmen, Algorithmen, Hardware und Software hat zu einem außerordentlich großen, vielteiligen und produktiven Forschungsfeld geführt, das A.I. genannt wird. Anlässlich einer Konferenz im Dartmouth College haben 1956 John McCarthy und Marvin … Continued},
  langid = {german},
  organization = {{www.kunstforum.de}},
  file = {/home/mtths/Zotero/storage/3MJK7YXC/aaa.html}
}

@article{brownConditionedReflexesPavlov1928,
  title = {Conditioned {{Reflexes}}. {{By I}}. {{P}}. {{Pavlov}} . {{Translated}} and Edited by {{G}}. {{V}}. {{AnrepM}}.{{D}}., {{D}}.{{Sc}}., ({{Oxford University Press}}: {{Humphrey Milford}}. 1927. {{Pp}}. Xv + 430. {{Price}} 28s.)},
  shorttitle = {Conditioned {{Reflexes}}. {{By I}}. {{P}}. {{Pavlov}} . {{Translated}} and Edited by {{G}}. {{V}}. {{AnrepM}}.{{D}}., {{D}}.{{Sc}}., ({{Oxford University Press}}},
  author = {Brown, William},
  date = {1928-07},
  journaltitle = {Philosophy},
  volume = {3},
  number = {11},
  pages = {380--383},
  publisher = {{Cambridge University Press}},
  issn = {1469-817X, 0031-8191},
  doi = {10.1017/S0031819100028242},
  url = {https://www.cambridge.org/core/journals/philosophy/article/abs/conditioned-reflexes-by-i-p-pavlov-translated-and-edited-by-g-v-anrepmd-dsc-oxford-university-press-humphrey-milford-1927-pp-xv-430-price-28s/7A78701537AC3B74C66E676EAA3B9DDA},
  urldate = {2022-01-16},
  abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0031819100028242/resource/name/firstPage-S0031819100028242a.jpg},
  langid = {english},
  file = {/home/mtths/Zotero/storage/UMYRDUMF/7A78701537AC3B74C66E676EAA3B9DDA.html}
}

@book{europeancommission.jointresearchcentre.AIWatchDefining2020,
  title = {{{AI}} Watch: Defining {{Artificial Intelligence}} : Towards an Operational Definition and Taxonomy of Artificial Intelligence.},
  shorttitle = {{{AI}} Watch},
  author = {{European Commission. Joint Research Centre.}},
  date = {2020},
  publisher = {{Publications Office}},
  location = {{LU}},
  url = {https://data.europa.eu/doi/10.2760/382730},
  urldate = {2022-01-16},
  langid = {english}
}

@online{heStreamingEndtoendSpeech2018,
  title = {Streaming {{End-to-end Speech Recognition For Mobile Devices}}},
  author = {He, Yanzhang and Sainath, Tara N. and Prabhavalkar, Rohit and McGraw, Ian and Alvarez, Raziel and Zhao, Ding and Rybach, David and Kannan, Anjuli and Wu, Yonghui and Pang, Ruoming and Liang, Qiao and Bhatia, Deepti and Shangguan, Yuan and Li, Bo and Pundak, Golan and Sim, Khe Chai and Bagby, Tom and Chang, Shuo-yiin and Rao, Kanishka and Gruenstein, Alexander},
  date = {2018-11-15},
  eprint = {1811.06621},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1811.06621},
  urldate = {2022-01-20},
  abstract = {End-to-end (E2E) models, which directly predict output character sequences given input speech, are good candidates for on-device speech recognition. E2E models, however, present numerous challenges: In order to be truly useful, such models must decode speech utterances in a streaming fashion, in real time; they must be robust to the long tail of use cases; they must be able to leverage user-specific context (e.g., contact lists); and above all, they must be extremely accurate. In this work, we describe our efforts at building an E2E speech recognizer using a recurrent neural network transducer. In experimental evaluations, we find that the proposed approach can outperform a conventional CTC-based model in terms of both latency and accuracy in a number of evaluation categories.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/home/mtths/Zotero/storage/64JQ2A7I/He et al. - 2018 - Streaming End-to-end Speech Recognition For Mobile.pdf;/home/mtths/Zotero/storage/5L2N43LQ/1811.html}
}

@article{hintonDeepNeuralNetworks2012b,
  title = {Deep {{Neural Networks}} for {{Acoustic Modeling}} in {{Speech Recognition}}: {{The Shared Views}} of {{Four Research Groups}}},
  shorttitle = {Deep {{Neural Networks}} for {{Acoustic Modeling}} in {{Speech Recognition}}},
  author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara and Kingsbury, Brian},
  date = {2012-11},
  journaltitle = {IEEE Signal Process. Mag.},
  volume = {29},
  number = {6},
  pages = {82--97},
  issn = {1053-5888},
  doi = {10.1109/MSP.2012.2205597},
  url = {http://ieeexplore.ieee.org/document/6296526/},
  urldate = {2022-01-20},
  langid = {english},
  file = {/home/mtths/Zotero/storage/C3IAM2YE/Hinton et al. - 2012 - Deep Neural Networks for Acoustic Modeling in Spee.pdf}
}

@report{hungerKuratierenUndDessen2021,
  title = {Kuratieren und dessen statistische Automatisierung mittels Künstlicher 'Intelligenz'.},
  author = {Hunger, Francis},
  date = {2021-10-21},
  institution = {{Zenodo}},
  doi = {10.5281/zenodo.5589930},
  url = {https://zenodo.org/record/5589930},
  urldate = {2022-01-14},
  abstract = {Das in diesem Working Paper diskutierte Konzept des Post-AI-Curating untersucht das Kuratieren als wissensbildendes Verfahren, unterstützt durch Mustererkennung und gewichtete Netze, die als technische Mittel der Künstlichen ‚Intelligenz‘ zum Einsatz kommen. Dafür diskutiert der Text eine Reihe aufeinander aufbauende Konzepte wie Kuratieren, Kurator*in, das Kuratorische, kuratorische Forschung, Post-Human Curating und Post-AI Curating. Im Anschluss werden eine Reihe von Projekten, die sich dem Kuratieren mit Mitteln Künstlicher ‚Intelligenz‘ nähern, als Fallbeispiele diskutiert: The Next Biennial Should Be Curated by a Machine von UBERMORGEN, Leonardo Impett und Joasia Krysa (2021) als Meta-Kunstwerk über Kuratieren und Biennalen; Tillmann Ohms Projekt Artificial Curator (2020), welches in eine automatisiert kuratierte Ausstellung mündete; und \#Exstrange von Rebekah Modrak and Marialaura Ghidini und weiteren (2017), welches auf der Plattform Ebay die Kunstwerke als Datenobjekte inszeniert. Schließlich schält der Text zusammenfassend Eingebettet-Sein, Big-Data-Infrastrukturen, Räumlichkeit und Informationsmodell, Solutionismus und Digital Humanities, Auswahl, Ähnlichkeit als Momente des Post-AI-Curating heraus.},
  langid = {deu},
  keywords = {Das Kuratorische,Daten,Künstliche Intelligenz,Kuratieren,Kurator*in,Medienkunst,Post-Internet,Training the Archive},
  note = {Training the Archive Working Paper Series, Paper 3},
  file = {/home/mtths/Zotero/storage/GGQPFBWI/Hunger - 2021 - Kuratieren und dessen statistische Automatisierung.pdf}
}

@book{kernighanProgrammingLanguage1988,
  title = {The {{C}} Programming Language},
  author = {Kernighan, Brian W. and Ritchie, Dennis M.},
  date = {1988},
  edition = {2nd ed},
  publisher = {{Prentice Hall}},
  location = {{Englewood Cliffs, N.J}},
  isbn = {978-0-13-110370-2 978-0-13-110362-7},
  pagetotal = {272},
  keywords = {C (Computer program language)},
  note = {Includes index}
}

@online{krizhevskyOneWeirdTrick2014,
  title = {One Weird Trick for Parallelizing Convolutional Neural Networks},
  author = {Krizhevsky, Alex},
  date = {2014-04-26},
  eprint = {1404.5997},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1404.5997},
  urldate = {2022-01-20},
  abstract = {I present a new way to parallelize the training of convolutional neural networks across multiple GPUs. The method scales significantly better than all alternatives when applied to modern convolutional neural networks.},
  archiveprefix = {arXiv},
  version = {2},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/home/mtths/Zotero/storage/TKUJFK3G/Krizhevsky - 2014 - One weird trick for parallelizing convolutional ne.pdf;/home/mtths/Zotero/storage/HAQJLTBI/1404.html}
}

@software{Lucid2022,
  title = {Lucid},
  date = {2022-01-15T20:25:57Z},
  origdate = {2018-01-25T17:41:44Z},
  url = {https://github.com/tensorflow/lucid},
  urldate = {2022-01-16},
  abstract = {A collection of infrastructure and tools for research in neural network interpretability.},
  organization = {{tensorflow}},
  keywords = {colab,interpretability,jupyter-notebook,machine-learning,tensorflow,visualization}
}

@book{millerArtistMachineWorld2019,
  title = {The Artist in the Machine: The World of {{AI}} Powered Creativity},
  shorttitle = {The Artist in the Machine},
  author = {Miller, Arthur I.},
  date = {2019},
  publisher = {{The MIT Press}},
  location = {{Cambridge, Massachusetts}},
  isbn = {978-0-262-04285-7 978-0-262-53962-3},
  pagetotal = {399},
  keywords = {Art and computers,Computer art,Creative ability},
  note = {Understanding creativity -- Portrait of the computer as an artist -- Machines that make music : putting the 'rhythm into 'algorithm' -- Once upon a time : computers that tell stories -- The world's first computer-composed musical : Beyond the fence, staged by Android Lloyd Webber and friends}
}

@book{molnar10LearnedFeatures,
  title = {10.1 {{Learned Features}} | {{Interpretable Machine Learning}}},
  author = {Molnar, Christoph},
  url = {https://christophm.github.io/interpretable-ml-book/cnn-features.html},
  urldate = {2022-01-16},
  abstract = {Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable.}
}

@article{olahFeatureVisualization2017,
  title = {Feature {{Visualization}}},
  author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
  date = {2017-11-07},
  journaltitle = {Distill},
  volume = {2},
  number = {11},
  pages = {e7},
  issn = {2476-0757},
  doi = {10.23915/distill.00007},
  url = {https://distill.pub/2017/feature-visualization},
  urldate = {2022-01-16},
  abstract = {How neural networks build up their understanding of images},
  langid = {english}
}

@book{pavlovConditionedReflexesInvestigation1927,
  title = {Conditioned Reflexes: An Investigation of the Physiological Activity of the Cerebral Cortex},
  shorttitle = {Conditioned Reflexes},
  author = {Pavlov, I. P.},
  date = {1927},
  series = {Conditioned Reflexes: An Investigation of the Physiological Activity of the Cerebral Cortex},
  pages = {xv, 430},
  publisher = {{Oxford Univ. Press}},
  location = {{Oxford, England}},
  abstract = {The present volume is the first complete discussion of conditioned reflexes to be translated into one of the more familiar European languages. It contains 23 lectures, most of which were delivered in the spring of 1924 at the Military Medical Academy in Leningrad. After an initial discussion of historical background and of the technical methods employed, Pavlov discusses the following topics: the formation of conditioned reflexes by means of conditioned and direct stimuli; external and internal inhibition of conditioned reflexes; the analyzing and synthesizing activity of the cerebral hemisphere; irradiation and concentration of nervous processes in the cerebral cortex; mutual induction of excitation and inhibition; interaction of irradiation and concentration with induction; the cortex as a mosaic of functions; development of inhibition in the cortex under the influence of conditioned stimuli; internal inhibition and sleep as one and the same process with regard to their intimate mechanism; transition stages between the alert state and complete sleep-hypnotic stages; different types of nervous system; pathological disturbances of the cortex, result of functional and surgical interference; general characteristics of the present investigation and its special difficulties; discovery of certain errors necessitating the modification of some earlier interpretations; and the experimental results obtained with animals in their application to man. Attention is drawn to the similarity of the neuroses and psychoses to behavior observed in the dog during certain of the experiments. A bibliography is given of all papers published from Pavlov's laboratories upon the physiology of conditioned reflexes. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  pagetotal = {xv, 430},
  file = {/home/mtths/Zotero/storage/ECG4SZ7U/1927-02531-000.html}
}

@book{serexheWolfgangKempelenMan2007,
  title = {Wolfgang von Kempelen: Man-(in the)-Machine = Wolfgang von Kempelen: Mensch-(in der)-Maschine},
  shorttitle = {Wolfgang von Kempelen},
  editor = {Serexhe, Bernhard and Weibel, Peter and von Kempelen, Wolfgang and Zentrum für Kunst und Medientechnologie Karlsruhe},
  date = {2007},
  publisher = {{Matthes \& Seitz}},
  location = {{Berlin}},
  isbn = {978-3-88221-997-5},
  langid = {ger eng},
  pagetotal = {111},
  note = {Impressum: "... anlässlich der Ausstellung Wolfgang von Kempelen. Mensch-(in der)-Maschine, ZKM, Medienmuseum Karlsruhe, 23.06 - 02.09.2007"},
  file = {/home/mtths/Zotero/storage/LHMDMRQR/Serexhe et al. - 2007 - Wolfgang von Kempelen Man-(in the)-Machine = Wolf.pdf}
}

@online{simonyanDeepConvolutionalNetworks2014,
  title = {Deep {{Inside Convolutional Networks}}: {{Visualising Image Classification Models}} and {{Saliency Maps}}},
  shorttitle = {Deep {{Inside Convolutional Networks}}},
  author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  date = {2014-04-19},
  eprint = {1312.6034},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/1312.6034},
  urldate = {2022-01-20},
  abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/mtths/Zotero/storage/4F2FSXI8/Simonyan et al. - 2014 - Deep Inside Convolutional Networks Visualising Im.pdf;/home/mtths/Zotero/storage/PTL4QYUJ/1312.html}
}

@inproceedings{tatmanGenderDialectBias2017,
  title = {Gender and {{Dialect Bias}} in {{YouTube}}'s {{Automatic Captions}}},
  booktitle = {Proceedings of the {{First ACL Workshop}} on {{Ethics}} in {{Natural Language Processing}}},
  author = {Tatman, Rachael},
  date = {2017},
  pages = {53--59},
  publisher = {{Association for Computational Linguistics}},
  location = {{Valencia, Spain}},
  doi = {10.18653/v1/W17-1606},
  url = {http://aclweb.org/anthology/W17-1606},
  urldate = {2022-01-20},
  abstract = {This project evaluates the accuracy of YouTube’s automatically-generated captions across two genders and five dialects of English. Speakers’ dialect and gender was controlled for by using videos uploaded as part of the “accent tag challenge”, where speakers explicitly identify their language background. The results show robust differences in accuracy across both gender and dialect, with lower accuracy for 1) women and 2) speakers from Scotland. This finding builds on earlier research finding that speaker’s sociolinguistic identity may negatively impact their ability to use automatic speech recognition, and demonstrates the need for sociolinguistically-stratified validation of systems.},
  eventtitle = {Proceedings of the {{First ACL Workshop}} on {{Ethics}} in {{Natural Language Processing}}},
  langid = {english},
  file = {/home/mtths/Zotero/storage/8JEA4XT7/Tatman - 2017 - Gender and Dialect Bias in YouTube's Automatic Cap.pdf}
}

@book{vlahosTalkMeAmazon2020,
  title = {Talk to Me: {{Amazon}}, {{Google}}, {{Apple}} and the Race for Voice-Controlled {{AI}}},
  shorttitle = {Talk to Me},
  author = {Vlahos, James},
  date = {2020},
  abstract = {The next great technological disruption is coming. The titans of Silicon Valley are racing to build the last, best computer that the world will ever need. They know that whoever successfully creates it will revolutionise our relationship with technology and make billions of dollars in the process. They call it conversational AI. Computers that can speak and think like humans do may seem like the stuff of science fiction, but they are rapidly moving towards reality. In Talk to Me, veteran tech journalist James Vlahos meets the researchers at Google, Amazon and Apple who are leading the way to a voice computing revolution. He explores how voice tech will transform every sector of society handing untold new powers to businesses, upending traditional notions of privacy, revolutionising access to information, and fundamentally altering the way we understand human consciousness. And he even tries to understand the significance of the revolution firsthand - by building a chatbot version of his terminally ill father. Vlahos's research leads him to one fundamental question: What happens when our computers become as articulate, compassionate, and creative as we are?},
  isbn = {978-1-84794-264-7},
  langid = {english},
  annotation = {OCLC: 1148063381}
}

@article{wangDefiningArtificialIntelligence2019,
  title = {On {{Defining Artificial Intelligence}}},
  author = {Wang, Pei},
  date = {2019-01-01},
  journaltitle = {Journal of Artificial General Intelligence},
  volume = {10},
  pages = {1--37},
  doi = {10.2478/jagi-2019-0002},
  abstract = {This article systematically analyzes the problem of defining “artificial intelligence.” It starts by pointing out that a definition influences the path of the research, then establishes four criteria of a good working definition of a notion: being similar to its common usage, drawing a sharp boundary, leading to fruitful research, and as simple as possible. According to these criteria, the representative definitions in the field are analyzed. A new definition is proposed, according to it intelligence means “adaptation with insufficient knowledge and resources.” The implications of this definition are discussed, and it is compared with the other definitions. It is claimed that this definition sheds light on the solution of many existing problems and sets a sound foundation for the field.},
  file = {/home/mtths/Zotero/storage/VXAT5EST/Wang - 2019 - On Defining Artificial Intelligence.pdf}
}


