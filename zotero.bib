@online{2ndUnconstrainedFace,
  title = {2nd {{Unconstrained Face Detection}} and {{Open Set Recognition Challenge}}, {{ECCV-2018}}},
  url = {https://vast.uccs.edu/Opensetface/},
  urldate = {2023-03-11},
  file = {/home/ms/Zotero/storage/MJEJYMX4/Opensetface.html}
}

@online{afifi11kHands,
  title = {11k {{Hands}}},
  author = {Afifi, Mahmoud},
  url = {https://sites.google.com/view/11khands},
  urldate = {2023-03-07},
  abstract = {Welcome to the 11k Hands dataset, a collection of 11,076 hand images (1600 x 1200 pixels) of 190 subjects, of varying ages between 18 - 75 years old. Each subject was asked to open and close his fingers of the right and left hands. Each hand was photographed from both dorsal and palmar sides with},
  langid = {english},
  file = {/home/ms/Zotero/storage/27YVC5NB/11khands.html;/home/ms/Zotero/storage/CNPCJSMX/11khands.html}
}

@online{afifi11KHandsGender2018,
  title = {{{11K Hands}}: {{Gender}} Recognition and Biometric Identification Using a Large Dataset of Hand Images},
  shorttitle = {{{11K Hands}}},
  author = {Afifi, Mahmoud},
  date = {2018-09-16},
  number = {arXiv:1711.04322},
  eprint = {arXiv:1711.04322},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1711.04322},
  url = {http://arxiv.org/abs/1711.04322},
  urldate = {2023-03-07},
  abstract = {The human hand possesses distinctive features which can reveal gender information. In addition, the hand is considered one of the primary biometric traits used to identify a person. In this work, we propose a large dataset of human hand images (dorsal and palmar sides) with detailed ground-truth information for gender recognition and biometric identification. Using this dataset, a convolutional neural network (CNN) can be trained effectively for the gender recognition task. Based on this, we design a two-stream CNN to tackle the gender recognition problem. This trained model is then used as a feature extractor to feed a set of support vector machine classifiers for the biometric identification task. We show that the dorsal side of hand images, captured by a regular digital camera, convey effective distinctive features similar to, if not better, those available in the palmar hand images. To facilitate access to the proposed dataset and replication of our experiments, the dataset, trained CNN models, and Matlab source code are available at (https://goo.gl/rQJndd).},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/ms/Zotero/storage/I6DMHNLW/Afifi - 2018 - 11K Hands Gender recognition and biometric identi.pdf;/home/ms/Zotero/storage/DRAZG87W/1711.html}
}

@unpublished{amodeiDeepSpeechEndtoEnd2015,
  title = {Deep {{Speech}} 2: {{End-to-End Speech Recognition}} in {{English}} and {{Mandarin}}},
  shorttitle = {Deep {{Speech}} 2},
  author = {Amodei, Dario and Anubhai, Rishita and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Chen, Jingdong and Chrzanowski, Mike and Coates, Adam and Diamos, Greg and Elsen, Erich and Engel, Jesse and Fan, Linxi and Fougner, Christopher and Han, Tony and Hannun, Awni and Jun, Billy and LeGresley, Patrick and Lin, Libby and Narang, Sharan and Ng, Andrew and Ozair, Sherjil and Prenger, Ryan and Raiman, Jonathan and Satheesh, Sanjeev and Seetapun, David and Sengupta, Shubho and Wang, Yi and Wang, Zhiqian and Wang, Chong and Xiao, Bo and Yogatama, Dani and Zhan, Jun and Zhu, Zhenyao},
  date = {2015-12-08},
  eprint = {1512.02595},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1512.02595},
  urldate = {2022-01-21},
  abstract = {We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech‚Äîtwo vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks, end-to-end learning allows us to handle a diverse variety of speech including noisy environments, accents and different languages. Key to our approach is our application of HPC techniques, resulting in a 7x speedup over our previous system [26]. Because of this efficiency, experiments that previously took weeks now run in days. This enables us to iterate more quickly to identify superior architectures and algorithms. As a result, in several cases, our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally, using a technique called Batch Dispatch with GPUs in the data center, we show that our system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/home/ms/Zotero/storage/BVKR3QKN/Amodei et al. - 2015 - Deep Speech 2 End-to-End Speech Recognition in En.pdf}
}

@online{AnatomyAISystem2018,
  title = {Anatomy of an {{AI System}}},
  date = {2018},
  url = {http://www.anatomyof.ai},
  urldate = {2022-04-23},
  abstract = {Anatomy of an AI System - The Amazon Echo as an anatomical map of human labor, data and planetary resources. By Kate Crawford and Vladan Joler (2018)},
  langid = {english},
  organization = {{Anatomy of an AI System}},
  file = {/home/ms/Zotero/storage/N6H2MIPY/anatomyof.ai.html}
}

@online{ArsElectronicaArchiv,
  title = {Ars {{Electronica Archiv}}},
  url = {https://archive.aec.at/prix/showmode/88/},
  urldate = {2023-03-20},
  file = {/home/ms/Zotero/storage/TXLIGL44/88.html}
}

@online{Avatars,
  title = {Avatars},
  url = {https://www.kanno.so/project/avatars},
  urldate = {2022-04-28},
  langid = {american},
  organization = {{So Kanno}},
  file = {/home/ms/Zotero/storage/7BKLUWLQ/avatars.html}
}

@online{Babycastles,
  title = {Babycastles},
  url = {https://www.babycastles.com},
  urldate = {2022-01-30},
  abstract = {The online home of Babycastles},
  langid = {american},
  organization = {{Babycastles}},
  file = {/home/ms/Zotero/storage/KCKCXQLJ/www.babycastles.com.html}
}

@online{baileyDeepDreamCreatorUnveils,
  title = {{{DeepDream Creator Unveils Very First Images After Three Years}} ‚Äî {{Artnome}}},
  author = {Bailey, Jason},
  url = {https://www.artnome.com/news/2018/12/30/deepdream-creator-unveils-very-first-images-after-three-years},
  urldate = {2023-03-04},
  file = {/home/ms/Zotero/storage/7JJT2LSQ/deepdream-creator-unveils-very-first-images-after-three-years.html;/home/ms/Zotero/storage/K8IVL9WR/deepdream-creator-unveils-very-first-images-after-three-years.html}
}

@article{bandyAddressingDocumentationDebt,
  title = {Addressing "{{Documentation Debt}}" in {{Machine Learning}}: {{A Retrospective Datasheet}} for {{BookCorpus}}},
  author = {Bandy, Jack and Vincent, Nicholas},
  abstract = {This paper contributes a formal case study in retrospective dataset documentation and pinpoints several problems with the influential BookCorpus dataset. Recent work has underscored the importance of dataset documentation in machine learning research, including by addressing ‚Äúdocumentation debt‚Äù for datasets that have been used widely but documented sparsely. BookCorpus is one such dataset. Researchers have used BookCorpus to train OpenAI‚Äôs GPT-N models and Google‚Äôs BERT models, but little to no documentation exists about the dataset‚Äôs motivation, composition, collection process, etc. We offer a retrospective datasheet with key context and information about BookCorpus, including several notable deficiencies. In particular, we find evidence that (1) BookCorpus violates copyright restrictions for many books, (2) BookCorpus contains thousands of duplicated books, and (3) BookCorpus exhibits significant skews in genre representation. We also find hints of other potential deficiencies that call for future research, such as lopsided author contributions. While more work remains, this initial effort to provide a datasheet for BookCorpus offers a cautionary case study and adds to growing literature that urges more careful, systematic documentation of machine learning datasets.},
  langid = {english},
  file = {/home/ms/Zotero/storage/3J5RM7U9/Bandy and Vincent - Addressing Documentation Debt in Machine Learnin.pdf}
}

@inproceedings{benderDangersStochasticParrots2021,
  title = {On the {{Dangers}} of {{Stochastic Parrots}}: {{Can Language Models Be Too Big}}? ü¶ú},
  shorttitle = {On the {{Dangers}} of {{Stochastic Parrots}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Bender, Emily M. and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  date = {2021-03-03},
  pages = {610--623},
  publisher = {{ACM}},
  location = {{Virtual Event Canada}},
  doi = {10.1145/3442188.3445922},
  url = {https://dl.acm.org/doi/10.1145/3442188.3445922},
  urldate = {2023-04-03},
  eventtitle = {{{FAccT}} '21: 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  isbn = {978-1-4503-8309-7},
  langid = {english},
  file = {/home/ms/Zotero/storage/IS2CQZRA/Bender et al. - 2021 - On the Dangers of Stochastic Parrots Can Language.pdf}
}

@online{BetterImagesAI,
  title = {Better {{Images}} of {{AI}}},
  url = {https://betterimagesofai.org},
  urldate = {2023-03-04},
  abstract = {We are a non-profit creating more realistic and inclusive images of artificial intelligence. Visit our growing repository available for anyone to use for free under CC licences, or just to use as inspiration for more helpful and diverse representations of AI.},
  langid = {british},
  file = {/home/ms/Zotero/storage/KLQ2VM2J/betterimagesofai.org.html}
}

@article{bostromAreYouLiving2001,
  title = {Are {{You Living}} in a {{Computer Simulation}}?},
  author = {Bostrom, Nick},
  date = {2001},
  pages = {14},
  url = {https://www.simulation-argument.com/simulation.pdf},
  langid = {english},
  file = {/home/ms/Zotero/storage/C5HAHFTN/Bostrom - Are You Living in a Computer Simulation.pdf}
}

@online{breretonBingAICan2023,
  title = {Bing {{AI Can}}'t {{Be Trusted}}},
  author = {Brereton, Dmitri},
  date = {2023-02-13},
  url = {https://dkb.blog/p/bing-ai-cant-be-trusted},
  urldate = {2023-04-04},
  abstract = {Microsoft knowingly released a broken product for short-term hype},
  langid = {english},
  file = {/home/ms/Zotero/storage/TC2FACRW/bing-ai-cant-be-trusted.html}
}

@article{brownConditionedReflexesPavlov1928,
  title = {Conditioned {{Reflexes}}. {{By I}}. {{P}}. {{Pavlov}} . {{Translated}} and Edited by {{G}}. {{V}}. {{AnrepM}}.{{D}}., {{D}}.{{Sc}}., ({{Oxford University Press}}: {{Humphrey Milford}}. 1927. {{Pp}}. Xv + 430. {{Price}} 28s.)},
  shorttitle = {Conditioned {{Reflexes}}. {{By I}}. {{P}}. {{Pavlov}} . {{Translated}} and Edited by {{G}}. {{V}}. {{AnrepM}}.{{D}}., {{D}}.{{Sc}}., ({{Oxford University Press}}},
  author = {Brown, William},
  date = {1928-07},
  journaltitle = {Philosophy},
  volume = {3},
  number = {11},
  pages = {380--383},
  publisher = {{Cambridge University Press}},
  issn = {1469-817X, 0031-8191},
  doi = {10.1017/S0031819100028242},
  url = {https://www.cambridge.org/core/journals/philosophy/article/abs/conditioned-reflexes-by-i-p-pavlov-translated-and-edited-by-g-v-anrepmd-dsc-oxford-university-press-humphrey-milford-1927-pp-xv-430-price-28s/7A78701537AC3B74C66E676EAA3B9DDA},
  urldate = {2022-01-16},
  abstract = {//static.cambridge.org/content/id/urn\%3Acambridge.org\%3Aid\%3Aarticle\%3AS0031819100028242/resource/name/firstPage-S0031819100028242a.jpg},
  langid = {english},
  file = {/home/ms/Zotero/storage/UMYRDUMF/7A78701537AC3B74C66E676EAA3B9DDA.html}
}

@online{CanonCatMac2014,
  title = {The {{Canon Cat The Mac}}'s {{Ancestor}}},
  date = {2014-10-25},
  url = {https://web.archive.org/web/20141025053109/http://www.jagshouse.com/swyft.html},
  urldate = {2022-04-28},
  file = {/home/ms/Zotero/storage/95X6KXX2/swyft.html}
}

@online{chakelianJourneyManyFaces2021,
  title = {The Journey and Many Faces of the Hash Symbol},
  author = {Chakelian, Anoosh},
  date = {2021-06-09T09:12:10+00:00},
  url = {https://www.newstatesman.com/science-tech/2014/06/history-journey-and-many-faces-hash-symbol},
  urldate = {2023-03-20},
  abstract = {From the Romans to Twitter, the hash sign ‚Äì or octothorpe ‚Äì has had a rich history, and now this innocuous little character has found a mighty resurgence as the hashtag. What happened along the way?},
  langid = {american},
  organization = {{New Statesman}},
  file = {/home/ms/Zotero/storage/LUJT63QU/history-journey-and-many-faces-hash-symbol.html}
}

@article{ciresanFlexibleHighPerformance,
  title = {Flexible, {{High Performance Convolutional Neural Networks}} for {{Image Classification}}},
  author = {Ciresan, Dan C and Meier, Ueli and Masci, Jonathan and Gambardella, Luca M and Schmidhuber, Jurgen},
  abstract = {We present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants. Our feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way. Our deep hierarchical architectures achieve the best published results on benchmarks for object classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with error rates of 2.53\%, 19.51\%, 0.35\%, respectively. Deep nets trained by simple back-propagation perform better than more shallow ones. Learning is surprisingly rapid. NORB is completely trained within five epochs. Test error rates on MNIST drop to 2.42\%, 0.97\% and 0.48\% after 1, 3 and 17 epochs, respectively.},
  langid = {english},
  file = {/home/ms/Zotero/storage/E8F7FXH2/Ciresan et al. - Flexible, High Performance Convolutional Neural Ne.pdf}
}

@online{Cleverbot,
  title = {Cleverbot},
  url = {http://www.cleverbot.com/},
  urldate = {2023-03-21},
  abstract = {Cleverbot - Chat with a bot about anything and everything - AI learns from people, in context, and imitates},
  organization = {{Cleverbot}},
  file = {/home/ms/Zotero/storage/K854YBBW/human.html}
}

@online{CloneSyntheticAI,
  title = {Clone {{Synthetic AI Voices}} with {{Neural Text}} to {{Speech}}},
  url = {https://www.resemble.ai/},
  urldate = {2022-01-26},
  abstract = {Custom AI Voice Generator. Create realistic text-to-speech AI voices with Resemble's voice cloning software. Real-time API's and 44kHz audio.},
  langid = {american},
  organization = {{Resemble AI}},
  file = {/home/ms/Zotero/storage/8T6K4TDH/www.resemble.ai.html}
}

@online{cohenOpenGPT2WeReplicated2019,
  title = {{{OpenGPT-2}}: {{We Replicated GPT-2 Because You Can Too}}},
  shorttitle = {{{OpenGPT-2}}},
  author = {Cohen, Vanya},
  date = {2019-12-11T05:40:14},
  url = {https://medium.com/@vanya_cohen/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc},
  urldate = {2023-04-01},
  abstract = {By Aaron Gokaslan* and Vanya Cohen*},
  langid = {english},
  organization = {{Medium}},
  file = {/home/ms/Zotero/storage/NWR4QG7V/opengpt-2-we-replicated-gpt-2-because-you-can-too-45e34e6d36dc.html}
}

@online{coleThisHorrifyingApp2019,
  title = {This {{Horrifying App Undresses}} a {{Photo}} of {{Any Woman With}} a {{Single Click}}},
  author = {Cole, Samantha},
  date = {2019-06-26T21:48:06},
  url = {https://www.vice.com/en/article/kzm59x/deepnude-app-creates-fake-nudes-of-any-woman},
  urldate = {2022-01-24},
  abstract = {The \$50 DeepNude app dispenses with the idea that deepfakes were about anything besides claiming ownership over women‚Äôs bodies.},
  langid = {english},
  organization = {{Vice}},
  keywords = {AI,App Which Shows Women Naked,Dangers of Deepfake,Deepfakes,DeepNude app,Machine Learning},
  file = {/home/ms/Zotero/storage/85GVHWFL/deepnude-app-creates-fake-nudes-of-any-woman.html}
}

@online{CreativeCommonsBiometrics,
  title = {Creative {{Commons Biometrics}}},
  url = {https://adam.harvey.studio/creative-commons/},
  urldate = {2023-03-11},
  abstract = {Recently, a debate has emerged over whether Creative Commons licenses are still relevant in the context of how images are being collected, used, and distributed in image training datasets related to the development of artificial intelligence (AI) and in particular face recognition technologies (FRT).},
  langid = {english},
  file = {/home/ms/Zotero/storage/HHVMYH9D/creative-commons.html}
}

@online{dempsey-jonesNeuroscientistsPutDubious2018,
  title = {Neuroscientists Put the Dubious Theory of 'phrenology' through Rigorous Testing for the First Time},
  author = {Dempsey-Jones, Harriet},
  date = {2018-01-22},
  url = {http://theconversation.com/neuroscientists-put-the-dubious-theory-of-phrenology-through-rigorous-testing-for-the-first-time-88291},
  urldate = {2023-03-07},
  abstract = {The Victorians believed that the shape and size of the skull could reveal details about a person‚Äôs demeanour. Now it‚Äôs been put to the test.},
  langid = {english},
  organization = {{The Conversation}},
  file = {/home/ms/Zotero/storage/3VL23H4I/neuroscientists-put-the-dubious-theory-of-phrenology-through-rigorous-testing-for-the-first-tim.html}
}

@inproceedings{dengImageNetLargeScaleHierarchical2009,
  title = {{{ImageNet}}: {{A Large-Scale Hierarchical Image Database}}},
  booktitle = {{{CVPR09}}},
  author = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
  date = {2009},
  file = {/home/ms/Zotero/storage/Y9F2RXPC/imagenet_cvpr09.pdf}
}

@online{DescartesWasWrong2017,
  title = {Descartes Was Wrong: ‚ÄòA Person Is a Person through Other Persons‚Äô | {{Aeon Ideas}}},
  shorttitle = {Descartes Was Wrong},
  date = {2017-04-07},
  url = {https://aeon.co/ideas/descartes-was-wrong-a-person-is-a-person-through-other-persons},
  urldate = {2022-01-30},
  abstract = {What‚Äôs a better way to understand human psychology ‚Äì ‚ÄòI think, therefore I am‚Äô or ‚ÄòA person is a person through other persons‚Äô?},
  langid = {english},
  organization = {{Aeon}},
  file = {/home/ms/Zotero/storage/6UQPGPZU/descartes-was-wrong-a-person-is-a-person-through-other-persons.html}
}

@online{DIGITALSQUARE,
  title = {{{DIGITAL SQUARE}}},
  url = {http://interface.ufg.ac.at/blog/digital-square/},
  urldate = {2023-04-04},
  file = {/home/ms/Zotero/storage/AYXVVVTL/digital-square.html}
}

@book{europeancommission.jointresearchcentre.AIWatchDefining2020,
  title = {{{AI}} Watch: Defining {{Artificial Intelligence}} : Towards an Operational Definition and Taxonomy of Artificial Intelligence.},
  shorttitle = {{{AI}} Watch},
  author = {{European Commission. Joint Research Centre.}},
  date = {2020},
  publisher = {{Publications Office}},
  location = {{LU}},
  url = {https://data.europa.eu/doi/10.2760/382730},
  urldate = {2022-01-16},
  langid = {english}
}

@online{EverythingDLVIDOREILLY,
  title = {Everything ‚Äî {{DŒõVID OREILLY}} ‚Ä¢ Computer Art \& Research},
  url = {https://www.davidoreilly.com/everything/},
  urldate = {2022-04-28},
  file = {/home/ms/Zotero/storage/KY3UKK3I/everything.html}
}

@online{ExcavatingAI,
  title = {Excavating {{AI}}},
  url = {https://excavating.ai},
  urldate = {2023-03-10},
  abstract = {An investigation into the politics of training sets, and the fundamental problems with classifying humans.},
  langid = {american},
  organization = {{-}},
  file = {/home/ms/Zotero/storage/LW9TCC5X/excavating.ai.html}
}

@online{ExploringPossibilitySpace,
  title = {Exploring {{Possibility Space}}: {{Microsoft}} \#{{TAYFAIL Smoking Gun}}: {{ALICE Open Source AI Library}} and {{AIML}}},
  url = {https://exploringpossibilityspace.blogspot.com/2016/03/microsoft-tayfail-smoking-gun-alice.html},
  urldate = {2023-03-21},
  file = {/home/ms/Zotero/storage/78SWIFJV/microsoft-tayfail-smoking-gun-alice.html}
}

@online{FFHQDatasetSearch,
  title = {{{FFHQ}} Dataset Search Form},
  url = {https://nvlabs.github.io/ffhq-dataset/search/},
  urldate = {2023-03-15},
  file = {/home/ms/Zotero/storage/BB9Q4A8A/search.html}
}

@online{francishungerArtificialIntelligenceAutomated2021,
  type = {Tweet},
  title = {1. '{{Artificial Intelligence}}' ={$>$} ' {{Automated Pattern Recognition}}' 2. '{{Machine Learning}}' ={$>$} '{{Machine Conditioning}}' {{OR}} ‚Äò{{Automated Classification}}‚Äô 3. '{{Neural Network}}' ={$>$} '{{Weighted Network}}' 4. ‚Äò{{Deep Learning}}‚Äô ={$>$} ‚Äò{{Deep Conditioning}}‚Äô 5. ‚Äò{{Neuron}}‚Äô ={$>$} ‚Äò{{Weight}}‚Äô or ‚Äò{{Node}}‚Äô},
  author = {{Francis Hunger}},
  date = {2021-07-09T11:36Z},
  url = {https://twitter.com/databaseculture/status/1413462059291975680},
  urldate = {2023-03-04},
  langid = {english},
  organization = {{Twitter}},
  file = {/home/ms/Zotero/storage/VHIUVS4G/1413462059291975680.html}
}

@online{FREEPORTANATOMIESBLACK,
  title = {{{FREEPORT}} 1: {{ANATOMIES OF A BLACK BOX}}},
  shorttitle = {{{FREEPORT}} 1},
  url = {https://www.mataderomadrid.org/en/calls/freeport-1-anatomies-black-box},
  urldate = {2022-04-23},
  abstract = {Taking Joler and Crawford‚Äôs ‚ÄúAnatomy of an AI system‚Äù as the starting point, you will be led into a roller coaster trip through the simple internet packet delivery system, following with Facebook‚Äôs sophisticated algorithmic factory, and going even deeper into fashionable corporate devices that actually operate as planetary-scale systems of knowledge extraction under the futurist label of machine learning and the likes.},
  langid = {english},
  organization = {{Matadero Madrid}},
  file = {/home/ms/Zotero/storage/ZI5HQR4J/freeport-1-anatomies-black-box.html}
}

@article{fukushimaCognitronSelforganizingMultilayered1975,
  title = {Cognitron: {{A}} Self-Organizing Multilayered Neural Network},
  shorttitle = {Cognitron},
  author = {Fukushima, Kunihiko},
  date = {1975},
  journaltitle = {Biological Cybernetics},
  shortjournal = {Biol. Cybernetics},
  volume = {20},
  number = {3-4},
  pages = {121--136},
  issn = {0340-1200, 1432-0770},
  doi = {10.1007/BF00342633},
  url = {http://link.springer.com/10.1007/BF00342633},
  urldate = {2023-03-04},
  langid = {english}
}

@article{fukushimaNeocognitronHierarchicalNeural1988,
  title = {Neocognitron: {{A}} Hierarchical Neural Network Capable of Visual Pattern Recognition},
  shorttitle = {Neocognitron},
  author = {Fukushima, Kunihiko},
  date = {1988-01},
  journaltitle = {Neural Networks},
  shortjournal = {Neural Networks},
  volume = {1},
  number = {2},
  pages = {119--130},
  issn = {08936080},
  doi = {10.1016/0893-6080(88)90014-7},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0893608088900147},
  urldate = {2023-03-04},
  langid = {english}
}

@article{gadeWhatUbuntuDifferent2012,
  title = {What Is {{{\emph{Ubuntu}}}} ,? {{Different Interpretations}} among {{South Africans}} of {{African Descent}}},
  shorttitle = {What Is {{{\emph{Ubuntu}}}} ,?},
  author = {Gade, Christian B.N.},
  date = {2012-01},
  journaltitle = {South African Journal of Philosophy},
  shortjournal = {South African Journal of Philosophy},
  volume = {31},
  number = {3},
  pages = {484--503},
  issn = {0258-0136, 2073-4867},
  doi = {10.1080/02580136.2012.10751789},
  url = {http://www.tandfonline.com/doi/full/10.1080/02580136.2012.10751789},
  urldate = {2022-01-30},
  abstract = {In this article, I describe and systematize the different answers to the question ‚ÄòWhat is ubuntu?‚Äô that I have been able to identify among South Africans of African descent (SAADs). I show that it is possible to distinguish between two clusters of answers. The answers of the first cluster all define ubuntu as a moral quality of a person, while the answers of the second cluster all define ubuntu as a phenomenon (for instance a philosophy, an ethic, African humanism, or, a worldview) according to which persons are interconnected. The concept of a person is of central importance to all the answers of both clusters, which means that to understand these answers, it is decisive to raise the question of who counts as a person according to SAADs. I show that some SAADs define all Homo sapiens as persons, whereas others hold the view that only some Homo sapiens count as persons: only those who are black, only those who have been incorporated into personhood, or only those who behave in a morally acceptable manner.},
  langid = {english},
  file = {/home/ms/Zotero/storage/NSRIRVRQ/Gade - 2012 - What is Ubuntu , Different Interpretations.pdf}
}

@online{GENDERDIVERSITYGastvortrag,
  title = {GENDER \& DIVERSITY: Gastvortrag von Ekheo - Musik und Kunst Privatuniversit√§t der Stadt Wien},
  shorttitle = {GENDER \& DIVERSITY},
  url = {https://muk.ac.at/veranstaltung/gender-diversity-gastvortrag-von-ekheo.html},
  urldate = {2022-01-24},
  abstract = {Musik und Kunst Privatuniversit√§t der Stadt Wien},
  langid = {austrian},
  file = {/home/ms/Zotero/storage/2A9BM9PL/gender-diversity-gastvortrag-von-ekheo.html}
}

@online{gershgornDataThatTransformed2017,
  title = {The Data That Transformed {{AI}} Research‚Äîand Possibly the World},
  author = {Gershgorn, Dave},
  date = {2017-07-26T11:00:59},
  url = {https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/},
  urldate = {2023-03-10},
  abstract = {The ImageNet competition ends today. But its legacy is just starting to take shape.},
  langid = {english},
  organization = {{Quartz}},
  file = {/home/ms/Zotero/storage/K6GE5E9A/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world.html}
}

@inproceedings{guntherUnconstrainedFaceDetection2017,
  title = {Unconstrained {{Face Detection}} and {{Open-Set Face Recognition Challenge}}},
  booktitle = {2017 {{IEEE International Joint Conference}} on {{Biometrics}} ({{IJCB}})},
  author = {G√ºnther, Manuel and Hu, Peiyun and Herrmann, Christian and Chan, Chi Ho and Jiang, Min and Yang, Shufan and Dhamija, Akshay Raj and Ramanan, Deva and Beyerer, J√ºrgen and Kittler, Josef and Jazaery, Mohamad Al and Nouyed, Mohammad Iqbal and Guo, Guodong and Stankiewicz, Cezary and Boult, Terrance E.},
  date = {2017-10},
  eprint = {1708.02337},
  eprinttype = {arxiv},
  eprintclass = {cs},
  pages = {697--706},
  doi = {10.1109/BTAS.2017.8272759},
  url = {http://arxiv.org/abs/1708.02337},
  urldate = {2023-03-11},
  abstract = {Face detection and recognition benchmarks have shifted toward more difficult environments. The challenge presented in this paper addresses the next step in the direction of automatic detection and identification of people from outdoor surveillance cameras. While face detection has shown remarkable success in images collected from the web, surveillance cameras include more diverse occlusions, poses, weather conditions and image blur. Although face verification or closed-set face identification have surpassed human capabilities on some datasets, open-set identification is much more complex as it needs to reject both unknown identities and false accepts from the face detector. We show that unconstrained face detection can approach high detection rates albeit with moderate false accept rates. By contrast, open-set face recognition is currently weak and requires much more attention.},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/ms/Zotero/storage/JMB3M3H6/G√ºnther et al. - 2017 - Unconstrained Face Detection and Open-Set Face Rec.pdf}
}

@online{haraDataDrivenAnalysisWorkers2017,
  title = {A {{Data-Driven Analysis}} of {{Workers}}' {{Earnings}} on {{Amazon Mechanical Turk}}},
  author = {Hara, Kotaro and Adams, Abi and Milland, Kristy and Savage, Saiph and Callison-Burch, Chris and Bigham, Jeffrey},
  date = {2017-12-28},
  number = {arXiv:1712.05796},
  eprint = {arXiv:1712.05796},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1712.05796},
  url = {http://arxiv.org/abs/1712.05796},
  urldate = {2023-03-10},
  abstract = {A growing number of people are working as part of on-line crowd work, which has been characterized by its low wages; yet, we know little about wage distribution and causes of low/high earnings. We recorded 2,676 workers performing 3.8 million tasks on Amazon Mechanical Turk. Our task-level analysis revealed that workers earned a median hourly wage of only \textasciitilde\textbackslash\$2/h, and only 4\% earned more than \textbackslash\$7.25/h. The average requester pays more than \textbackslash\$11/h, although lower-paying requesters post much more work. Our wage calculations are influenced by how unpaid work is included in our wage calculations, e.g., time spent searching for tasks, working on tasks that are rejected, and working on tasks that are ultimately not submitted. We further explore the characteristics of tasks and working patterns that yield higher hourly wages. Our analysis informs future platform design and worker tools to create a more positive future for crowd work.},
  pubstate = {preprint},
  keywords = {Computer Science - Computers and Society,Computer Science - Human-Computer Interaction},
  file = {/home/ms/Zotero/storage/3KEAB8G2/Hara et al. - 2017 - A Data-Driven Analysis of Workers' Earnings on Ama.pdf;/home/ms/Zotero/storage/7Y8GIM3F/1712.html}
}

@online{harveyExposingAi,
  title = {Exposing.Ai},
  author = {Harvey, Adam},
  url = {https://exposing.ai/},
  urldate = {2023-03-11},
  abstract = {Exposing.ai},
  organization = {{Exposing.ai}},
  file = {/home/ms/Zotero/storage/LQT7ZSHI/exposing.ai.html}
}

@online{harveyExposingAiMegaFace,
  title = {Exposing.Ai: {{MegaFace}}},
  shorttitle = {Exposing.Ai},
  author = {Harvey, Adam},
  url = {https://exposing.ai/datasets/megaface/},
  urldate = {2023-03-13},
  abstract = {MegaFace is a dataset of over 4 million faces used benchmarking and developing face recognition technologies},
  organization = {{Exposing.ai}},
  file = {/home/ms/Zotero/storage/UXQ77ISQ/megaface.html}
}

@article{hernNewAIFake2019,
  title = {New {{AI}} Fake Text Generator May Be Too Dangerous to Release, Say Creators},
  author = {Hern, Alex},
  date = {2019-02-14T17:00:54},
  journaltitle = {The Guardian},
  issn = {0261-3077},
  url = {https://www.theguardian.com/technology/2019/feb/14/elon-musk-backed-ai-writes-convincing-news-fiction},
  urldate = {2023-04-01},
  abstract = {The Elon Musk-backed nonprofit company OpenAI declines to release research publicly for fear of misuse},
  entrysubtype = {newspaper},
  journalsubtitle = {Technology},
  langid = {british},
  keywords = {Artificial intelligence (AI),Books,Computing,Elon Musk,George Orwell,Journalism books,OpenAI,Technology},
  file = {/home/ms/Zotero/storage/WR6JUDUT/elon-musk-backed-ai-writes-convincing-news-fiction.html}
}

@unpublished{heStreamingEndtoendSpeech2018,
  title = {Streaming {{End-to-end Speech Recognition For Mobile Devices}}},
  author = {He, Yanzhang and Sainath, Tara N. and Prabhavalkar, Rohit and McGraw, Ian and Alvarez, Raziel and Zhao, Ding and Rybach, David and Kannan, Anjuli and Wu, Yonghui and Pang, Ruoming and Liang, Qiao and Bhatia, Deepti and Shangguan, Yuan and Li, Bo and Pundak, Golan and Sim, Khe Chai and Bagby, Tom and Chang, Shuo-yiin and Rao, Kanishka and Gruenstein, Alexander},
  date = {2018-11-15},
  eprint = {1811.06621},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1811.06621},
  urldate = {2022-01-20},
  abstract = {End-to-end (E2E) models, which directly predict output character sequences given input speech, are good candidates for on-device speech recognition. E2E models, however, present numerous challenges: In order to be truly useful, such models must decode speech utterances in a streaming fashion, in real time; they must be robust to the long tail of use cases; they must be able to leverage user-specific context (e.g., contact lists); and above all, they must be extremely accurate. In this work, we describe our efforts at building an E2E speech recognizer using a recurrent neural network transducer. In experimental evaluations, we find that the proposed approach can outperform a conventional CTC-based model in terms of both latency and accuracy in a number of evaluation categories.},
  keywords = {Computer Science - Computation and Language},
  file = {/home/ms/Zotero/storage/64JQ2A7I/He et al. - 2018 - Streaming End-to-end Speech Recognition For Mobile.pdf;/home/ms/Zotero/storage/5L2N43LQ/1811.html}
}

@article{hillHowPhotosYour2019,
  title = {How {{Photos}} of {{Your Kids Are Powering Surveillance Technology}}},
  author = {Hill, Kashmir and Krolik, Aaron},
  date = {2019-10-11},
  journaltitle = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/interactive/2019/10/11/technology/flickr-facial-recognition.html},
  urldate = {2023-03-13},
  abstract = {Millions of Flickr images were sucked into a database called MegaFace. Now some of those faces may have the ability to sue.},
  entrysubtype = {newspaper},
  journalsubtitle = {Technology},
  langid = {american},
  keywords = {Facial Recognition Software,Flickr,Photography,SmugMug Inc,University of Washington},
  file = {/home/ms/Zotero/storage/GHAMHTXK/flickr-facial-recognition.html}
}

@article{hintonDeepNeuralNetworks2012,
  title = {Deep {{Neural Networks}} for {{Acoustic Modeling}} in {{Speech Recognition}}: {{The Shared Views}} of {{Four Research Groups}}},
  shorttitle = {Deep {{Neural Networks}} for {{Acoustic Modeling}} in {{Speech Recognition}}},
  author = {Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara and Kingsbury, Brian},
  date = {2012-11},
  journaltitle = {IEEE Signal Processing Magazine},
  shortjournal = {IEEE Signal Process. Mag.},
  volume = {29},
  number = {6},
  pages = {82--97},
  issn = {1053-5888},
  doi = {10.1109/MSP.2012.2205597},
  url = {http://ieeexplore.ieee.org/document/6296526/},
  urldate = {2022-01-20},
  langid = {english},
  file = {/home/ms/Zotero/storage/C3IAM2YE/Hinton et al. - 2012 - Deep Neural Networks for Acoustic Modeling in Spee.pdf}
}

@incollection{hoelOperativeImagesInroads2018,
  title = {Operative {{Images}}. {{Inroads}} to a {{New Paradigm}} of {{Media Theory}}},
  booktitle = {Image ‚Äì {{Action}} ‚Äì {{Space}}},
  author = {Hoel, Aud Sissel},
  date = {2018-10-08},
  pages = {11--28},
  publisher = {{De Gruyter}},
  doi = {10.1515/9783110464979-002},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110464979-002/html},
  urldate = {2023-03-07},
  abstract = {Das Kapitel Operative Images. Inroads to a New Paradigm of Media Theory erschien in Image ‚Äì Action ‚Äì Space auf Seite 11.},
  isbn = {978-3-11-046497-9},
  langid = {english},
  file = {/home/ms/Zotero/storage/8D8WR97T/Hoel - 2018 - Operative Images. Inroads to a New Paradigm of Med.pdf}
}

@book{hofstadterFluidConceptsCreative1995,
  title = {Fluid Concepts \& Creative Analogies: Computer Models of the Fundamental Mechanisms of Thought},
  shorttitle = {Fluid Concepts \& Creative Analogies},
  author = {Hofstadter, Douglas R.},
  date = {1995},
  publisher = {{Basic Books}},
  location = {{New York, NY}},
  editora = {Fluid Analogies Research Group},
  editoratype = {collaborator},
  isbn = {978-0-465-02475-9 978-0-465-05154-0},
  langid = {english},
  pagetotal = {518}
}

@online{HowReadPalms,
  title = {How to {{Read Palms}}: 9 {{Steps}} (with {{Pictures}})},
  shorttitle = {How to {{Read Palms}}},
  url = {https://www.wikihow.com/Read-Palms},
  urldate = {2023-03-08},
  abstract = {Imagine if you held everything you ever wanted to know about your fate, love life, and personality in the palm of your hand. Palm reading, also known as palmistry or chiromancy, is a mystical art practiced worldwide. It has its roots in...},
  langid = {english},
  organization = {{wikiHow}},
  file = {/home/ms/Zotero/storage/9J9ABB7W/Read-Palms.html}
}

@online{HumanguidedBurritoBots2019,
  title = {Human-Guided Burrito Bots Raise Questions about the Future of Robo-Delivery},
  date = {2019-06-03T10:54:22+00:00},
  url = {https://thehustle.co/kiwibots-autonomous-food-delivery/},
  urldate = {2022-04-28},
  abstract = {A startup called Kiwi Campus created a popular food-delivering robot at UC Berkeley -- but it still requires lots of human hands to run.},
  langid = {american},
  organization = {{The Hustle}},
  file = {/home/ms/Zotero/storage/QAPX9HF2/kiwibots-autonomous-food-delivery.html}
}

@report{hungerKuratierenUndDessen2021,
  title = {Kuratieren und dessen statistische Automatisierung mittels K√ºnstlicher 'Intelligenz'.},
  author = {Hunger, Francis},
  date = {2021-10-21},
  institution = {{Zenodo}},
  doi = {10.5281/zenodo.5589930},
  url = {https://zenodo.org/record/5589930},
  urldate = {2022-01-14},
  abstract = {Das in diesem Working Paper diskutierte Konzept des Post-AI-Curating untersucht das Kuratieren als wissensbildendes Verfahren, unterst√ºtzt durch Mustererkennung und gewichtete Netze, die als technische Mittel der K√ºnstlichen ‚ÄöIntelligenz‚Äò zum Einsatz kommen. Daf√ºr diskutiert der Text eine Reihe aufeinander aufbauende Konzepte wie Kuratieren, Kurator*in, das Kuratorische, kuratorische Forschung, Post-Human Curating und Post-AI Curating. Im Anschluss werden eine Reihe von Projekten, die sich dem Kuratieren mit Mitteln K√ºnstlicher ‚ÄöIntelligenz‚Äò n√§hern, als Fallbeispiele diskutiert: The Next Biennial Should Be Curated by a Machine von UBERMORGEN, Leonardo Impett und Joasia Krysa (2021) als Meta-Kunstwerk √ºber Kuratieren und Biennalen; Tillmann Ohms Projekt Artificial Curator (2020), welches in eine automatisiert kuratierte Ausstellung m√ºndete; und \#Exstrange von Rebekah Modrak and Marialaura Ghidini und weiteren (2017), welches auf der Plattform Ebay die Kunstwerke als Datenobjekte inszeniert. Schlie√ülich sch√§lt der Text zusammenfassend Eingebettet-Sein, Big-Data-Infrastrukturen, R√§umlichkeit und Informationsmodell, Solutionismus und Digital Humanities, Auswahl, √Ñhnlichkeit als Momente des Post-AI-Curating heraus.},
  langid = {deu},
  keywords = {Das Kuratorische,Daten,K√ºnstliche Intelligenz,Kuratieren,Kurator*in,Medienkunst,Post-Internet,Training the Archive},
  file = {/home/ms/Zotero/storage/GGQPFBWI/Hunger - 2021 - Kuratieren und dessen statistische Automatisierung.pdf}
}

@online{hungerTalkUnhypeAI2021,
  title = {Talk: {{Unhype AI}} (2021)},
  shorttitle = {Talk},
  author = {Hunger, Francis},
  date = {2021-04-28T18:42:08+00:00},
  url = {https://www.irmielin.org/unhype-ai/},
  urldate = {2023-03-05},
  abstract = {Francis Hunger Irmielin.org},
  langid = {american},
  file = {/home/ms/Zotero/storage/FPY9SFQA/unhype-ai.html}
}

@online{ImageNet,
  title = {{{ImageNet}}},
  url = {https://image-net.org/index.php},
  urldate = {2023-03-04},
  file = {/home/ms/Zotero/storage/57XAZD4C/index.html}
}

@online{ImageNetRouletteTrevor,
  title = {{{ImageNet Roulette}} ‚Äì {{Trevor Paglen}}},
  url = {https://paglen.studio/2020/04/29/imagenet-roulette/},
  urldate = {2023-03-11},
  file = {/home/ms/Zotero/storage/6RRZP9BF/imagenet-roulette.html}
}

@online{InceptionismGoingDeeper2015,
  title = {Inceptionism: {{Going Deeper}} into {{Neural Networks}}},
  shorttitle = {Inceptionism},
  date = {2015-06-17},
  url = {https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html},
  urldate = {2023-03-04},
  langid = {english},
  file = {/home/ms/Zotero/storage/HF2RDHT2/inceptionism-going-deeper-into-neural.html}
}

@online{InternetYamiIchi,
  title = {The Internet Yami-Ichi},
  url = {https://ars.electronica.art/keplersgardens/de/the-internet-yami-ichi/},
  urldate = {2023-03-20},
  abstract = {Shut down your computer and join the third edition of\,The Internet\,Yami-Ichi\,in Linz!\,The Internet\,Yami-Ichi\,derives\,from the Japanese\,for\,"Internet Black Market," but also\,for\,"sickness" and "addiction." It is\,a flea market where people consumed by the Internet can sha},
  langid = {ngerman},
  organization = {{In Kepler's Gardens}},
  file = {/home/ms/Zotero/storage/NZUSWF48/the-internet-yami-ichi.html}
}

@online{JabberwackyThoughtsArtificial2006,
  title = {Jabberwacky - {{About Thoughts}} - {{An Artificial Intelligence AI}} Chatbot, Chatterbot or Chatterbox, Learning {{AI}}, Database, Dynamic - Models Way Humans Learn - Simulate Natural Human Chat - Interesting, Humorous, Entertaining},
  date = {2006-07-01},
  url = {https://web.archive.org/web/20060701052309/http://www.jabberwacky.com/j2about},
  urldate = {2023-03-21},
  file = {/home/ms/Zotero/storage/MNXW3RTB/j2about.html}
}

@online{jacobSoftwareTricksPeople,
  title = {Software Tricks People into Thinking It Is Human},
  author = {Jacob, Aron},
  url = {https://www.newscientist.com/article/dn20865-software-tricks-people-into-thinking-it-is-human/},
  urldate = {2023-03-22},
  abstract = {Cleverbot tricked 59 per cent of people that they were talking to another human ‚Äì suggesting it has passed the Turing test},
  langid = {american},
  organization = {{New Scientist}},
  file = {/home/ms/Zotero/storage/HQGCGR6R/dn20865-software-tricks-people-into-thinking-it-is-human.html}
}

@article{jemineMasterThesisAutomatic,
  title = {Master Thesis : {{Automatic Multispeaker Voice Cloning}}},
  author = {Jemine, C},
  pages = {38},
  langid = {english},
  file = {/home/ms/Zotero/storage/JNVUEWWZ/Jemine - Master thesis  Automatic Multispeaker Voice Cloni.pdf}
}

@software{jemineRealTimeVoiceCloning2022,
  title = {Real-{{Time Voice Cloning}}},
  author = {Jemine, Corentin},
  date = {2022-01-26T14:01:33Z},
  origdate = {2019-05-26T08:56:15Z},
  url = {https://github.com/CorentinJ/Real-Time-Voice-Cloning},
  urldate = {2022-01-26},
  abstract = {Clone a voice in 5 seconds to generate arbitrary speech in real-time},
  keywords = {deep-learning,python,pytorch,tensorflow,tts,voice-cloning}
}

@article{jeremijenkoDialogueMonologueVoice,
  title = {Dialogue with a {{Monologue}}: {{Voice Chips}} and the {{Products}} of {{Abstract Speech}}},
  author = {Jeremijenko, Natalie},
  pages = {32},
  abstract = {This paper examines the use of integrated circuits that produce speech in consumer products, commonly called voice chips. The goal of this paper is to document what these products actually say and to try to understand what the voices of these products represent, specifically, what they say about techno-social relations. The paper describes how voice chip technology differs from other 'talking hardware' of the recording and communications industries, and places it in a unique social position. I then survey the voice chip patent literature and sample the products currently on the market. Finally, I investigate how the voices of these products can be interpreted as speech and interaction, drawing largely upon Suchman's examination of human-machine interaction. I conclude by using the chips‚Äô voice to question their performance of abstract speech, if they demonstrate preprogrammable interaction, and therefore what we mean when we attribute speech as literal agency to technological products.},
  langid = {english},
  file = {/home/ms/Zotero/storage/HPIRFENX/Jeremijenko - Dialogue with a Monologue Voice Chips and the Pro.pdf}
}

@unpublished{jiaTransferLearningSpeaker2019,
  title = {Transfer {{Learning}} from {{Speaker Verification}} to {{Multispeaker Text-To-Speech Synthesis}}},
  author = {Jia, Ye and Zhang, Yu and Weiss, Ron J. and Wang, Quan and Shen, Jonathan and Ren, Fei and Chen, Zhifeng and Nguyen, Patrick and Pang, Ruoming and Moreno, Ignacio Lopez and Wu, Yonghui},
  date = {2019-01-02},
  eprint = {1806.04558},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/1806.04558},
  urldate = {2022-01-26},
  abstract = {We describe a neural network-based system for text-to-speech (TTS) synthesis that is able to generate speech audio in the voice of different speakers, including those unseen during training. Our system consists of three independently trained components: (1) a speaker encoder network, trained on a speaker verification task using an independent dataset of noisy speech without transcripts from thousands of speakers, to generate a fixed-dimensional embedding vector from only seconds of reference speech from a target speaker; (2) a sequence-to-sequence synthesis network based on Tacotron 2 that generates a mel spectrogram from text, conditioned on the speaker embedding; (3) an auto-regressive WaveNet-based vocoder network that converts the mel spectrogram into time domain waveform samples. We demonstrate that the proposed model is able to transfer the knowledge of speaker variability learned by the discriminatively-trained speaker encoder to the multispeaker TTS task, and is able to synthesize natural speech from speakers unseen during training. We quantify the importance of training the speaker encoder on a large and diverse speaker set in order to obtain the best generalization performance. Finally, we show that randomly sampled speaker embeddings can be used to synthesize speech in the voice of novel speakers dissimilar from those used in training, indicating that the model has learned a high quality speaker representation.},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/home/ms/Zotero/storage/5VZZTST8/Jia et al. - 2019 - Transfer Learning from Speaker Verification to Mul.pdf}
}

@online{karrasAnalyzingImprovingImage2020,
  title = {Analyzing and {{Improving}} the {{Image Quality}} of {{StyleGAN}}},
  author = {Karras, Tero and Laine, Samuli and Aittala, Miika and Hellsten, Janne and Lehtinen, Jaakko and Aila, Timo},
  date = {2020-03-23},
  number = {arXiv:1912.04958},
  eprint = {arXiv:1912.04958},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1912.04958},
  urldate = {2023-03-20},
  abstract = {The style-based GAN architecture (StyleGAN) yields state-of-the-art results in data-driven unconditional generative image modeling. We expose and analyze several of its characteristic artifacts, and propose changes in both model architecture and training methods to address them. In particular, we redesign the generator normalization, revisit progressive growing, and regularize the generator to encourage good conditioning in the mapping from latent codes to images. In addition to improving image quality, this path length regularizer yields the additional benefit that the generator becomes significantly easier to invert. This makes it possible to reliably attribute a generated image to a particular network. We furthermore visualize how well the generator utilizes its output resolution, and identify a capacity problem, motivating us to train larger models for additional quality improvements. Overall, our improved model redefines the state of the art in unconditional image modeling, both in terms of existing distribution quality metrics as well as perceived image quality.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Electrical Engineering and Systems Science - Image and Video Processing,Statistics - Machine Learning},
  file = {/home/ms/Zotero/storage/AIF65B6Z/Karras et al. - 2020 - Analyzing and Improving the Image Quality of Style.pdf}
}

@online{karrasStyleBasedGeneratorArchitecture2019,
  title = {A {{Style-Based Generator Architecture}} for {{Generative Adversarial Networks}}},
  author = {Karras, Tero and Laine, Samuli and Aila, Timo},
  date = {2019-03-29},
  number = {arXiv:1812.04948},
  eprint = {arXiv:1812.04948},
  eprinttype = {arxiv},
  doi = {10.48550/arXiv.1812.04948},
  url = {http://arxiv.org/abs/1812.04948},
  urldate = {2023-03-13},
  abstract = {We propose an alternative generator architecture for generative adversarial networks, borrowing from style transfer literature. The new architecture leads to an automatically learned, unsupervised separation of high-level attributes (e.g., pose and identity when trained on human faces) and stochastic variation in the generated images (e.g., freckles, hair), and it enables intuitive, scale-specific control of the synthesis. The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture. Finally, we introduce a new, highly varied and high-quality dataset of human faces.},
  pubstate = {preprint},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/home/ms/Zotero/storage/WUAH672H/Karras et al. - 2019 - A Style-Based Generator Architecture for Generativ.pdf;/home/ms/Zotero/storage/VPWHSARJ/1812.html}
}

@online{KATECRAWFORDTREVOR,
  title = {{{KATE CRAWFORD}} | {{TREVOR PAGLEN}}: {{TRAINING HUMANS}} ‚Äì {{Fondazione Prada}}},
  url = {https://www.fondazioneprada.org/project/training-humans/?lang=en},
  urldate = {2023-03-10},
  file = {/home/ms/Zotero/storage/7EJ38I8V/training-humans.html}
}

@book{kernighanProgrammingLanguage1988,
  title = {The {{C}} Programming Language},
  author = {Kernighan, Brian W. and Ritchie, Dennis M.},
  date = {1988},
  edition = {2nd ed},
  publisher = {{Prentice Hall}},
  location = {{Englewood Cliffs, N.J}},
  isbn = {978-0-13-110370-2 978-0-13-110362-7},
  pagetotal = {272},
  keywords = {C (Computer program language)}
}

@article{krizhevskyImageNetClassificationDeep2017,
  title = {{{ImageNet}} Classification with Deep Convolutional Neural Networks},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  date = {2017-05-24},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {60},
  number = {6},
  pages = {84--90},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3065386},
  url = {https://dl.acm.org/doi/10.1145/3065386},
  urldate = {2022-01-24},
  abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called ‚Äúdropout‚Äù that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
  langid = {english},
  file = {/home/ms/Zotero/storage/P3W6G2DH/Krizhevsky et al. - 2017 - ImageNet classification with deep convolutional ne.pdf}
}

@unpublished{krizhevskyOneWeirdTrick2014,
  title = {One Weird Trick for Parallelizing Convolutional Neural Networks},
  author = {Krizhevsky, Alex},
  date = {2014-04-26},
  eprint = {1404.5997},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1404.5997},
  urldate = {2022-01-20},
  abstract = {I present a new way to parallelize the training of convolutional neural networks across multiple GPUs. The method scales significantly better than all alternatives when applied to modern convolutional neural networks.},
  version = {2},
  keywords = {Computer Science - Distributed; Parallel; and Cluster Computing,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  file = {/home/ms/Zotero/storage/TKUJFK3G/Krizhevsky - 2014 - One weird trick for parallelizing convolutional ne.pdf;/home/ms/Zotero/storage/HAQJLTBI/1404.html}
}

@online{lavigneNewYorkApartment,
  title = {New {{York Apartment}}},
  author = {Lavigne, Sam and Brain, Tega},
  url = {https://artport.whitney.org/commissions/new-york-apartment/index.html},
  urldate = {2023-03-17},
  langid = {english},
  file = {/home/ms/Zotero/storage/T7ML7FCT/index.html}
}

@online{lavigneScrapism,
  title = {Scrapism},
  author = {Lavigne, Sam},
  url = {https://scrapism.lav.io/},
  urldate = {2023-03-15},
  abstract = {A guide to web scraping as an artistic and critical practice.},
  langid = {american},
  file = {/home/ms/Zotero/storage/7UV9IJ3K/scrapism.lav.io.html}
}

@unpublished{liuMeasuringFairnessSpeech2021,
  title = {Towards {{Measuring Fairness}} in {{Speech Recognition}}: {{Casual Conversations Dataset Transcriptions}}},
  shorttitle = {Towards {{Measuring Fairness}} in {{Speech Recognition}}},
  author = {Liu, Chunxi and Picheny, Michael and Sarƒ±, Leda and Chitkara, Pooja and Xiao, Alex and Zhang, Xiaohui and Chou, Mark and Alvarado, Andres and Hazirbas, Caner and Saraf, Yatharth},
  date = {2021-11-18},
  eprint = {2111.09983},
  eprinttype = {arxiv},
  eprintclass = {cs, eess},
  url = {http://arxiv.org/abs/2111.09983},
  urldate = {2022-01-21},
  abstract = {It is well known that many machine learning systems demonstrate bias towards specific groups of individuals. This problem has been studied extensively in the Facial Recognition area, but much less so in Automatic Speech Recognition (ASR). This paper presents initial Speech Recognition results on ‚ÄúCasual Conversations‚Äù ‚Äì a publicly released 846 hour corpus designed to help researchers evaluate their computer vision and audio models for accuracy across a diverse set of metadata, including age, gender, and skin tone. The entire corpus has been manually transcribed, allowing for detailed ASR evaluations across these metadata. Multiple ASR models are evaluated, including models trained on LibriSpeech, 14,000 hour transcribed, and over 2 million hour untranscribed social media videos. Significant differences in word error rate across gender and skin tone are observed at times for all models. We are releasing human transcripts from the Casual Conversations dataset to encourage the community to develop a variety of techniques to reduce these statistical biases.},
  langid = {english},
  keywords = {Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing},
  file = {/home/ms/Zotero/storage/QQ6SWT4X/Liu et al. - 2021 - Towards Measuring Fairness in Speech Recognition .pdf}
}

@software{Lucid2022,
  title = {Lucid},
  date = {2022-01-15T20:25:57Z},
  origdate = {2018-01-25T17:41:44Z},
  url = {https://github.com/tensorflow/lucid},
  urldate = {2022-01-16},
  abstract = {A collection of infrastructure and tools for research in neural network interpretability.},
  organization = {{tensorflow}},
  keywords = {colab,interpretability,jupyter-notebook,machine-learning,tensorflow,visualization}
}

@article{lukoseTextSpeechSynthesizerFormant2017,
  title = {Text to {{Speech Synthesizer-Formant Synthesis}}},
  author = {Lukose, Sneha and Upadhya, Savitha S},
  date = {2017},
  pages = {4},
  abstract = {In this paper, different methods of text to speech synthesizer techniques are discussed to produce intelligible and natural output and a vowel synthesizer using cascade formant technique is implemented. A text to speech output is based on generating corresponding sound output when the text is inputted. Wide range of applications use text to speech technique in medicals, telecommunications fields, etc. The Various speech synthesis methods that have been used for text to speech output for obtaining intelligible and natural output are Concatenative, Formant, Articulatory, Hidden Markov model (HMM).},
  langid = {english},
  file = {/home/ms/Zotero/storage/WUIGD37H/Lukose and Upadhya - 2017 - Text to Speech Synthesizer-Formant Synthesis.pdf}
}

@video{lyrebirdLyrebirdCreateDigital2017,
  title = {Lyrebird - {{Create}} a Digital Copy of Your Voice.},
  editor = {{Lyrebird}},
  date = {2017-09-04},
  url = {https://www.youtube.com/watch?v=YfU_sWHT8mo},
  urldate = {2022-01-24},
  abstract = {Go to www.lyrebird.ai to create a digital copy of your voice. Barack Obama. (In this video, we generate not only the audio but also parts of the video. As far as we know, this is the very first time that it is done.)},
  editortype = {director}
}

@video{matthiasschafer11kHands2018,
  title = {11k Hands},
  editor = {{Matthias Sch√§fer}},
  date = {2018-03-23},
  url = {https://www.youtube.com/watch?v=snJsKFxPlJ8},
  urldate = {2023-03-08},
  abstract = {This is a compilation of the dataset 11k hands by google used for gender recognition and biometric identification. The audio plays back part of the metada connected to each image. It can be found https://sites.google.com/view/11khands},
  editortype = {director}
}

@book{millerArtistMachineWorld2019,
  title = {The Artist in the Machine: The World of {{AI}} Powered Creativity},
  shorttitle = {The Artist in the Machine},
  author = {Miller, Arthur I.},
  date = {2019},
  publisher = {{The MIT Press}},
  location = {{Cambridge, Massachusetts}},
  isbn = {978-0-262-04285-7 978-0-262-53962-3},
  pagetotal = {399},
  keywords = {Art and computers,Computer art,Creative ability}
}

@book{mitchellArtificialIntelligenceGuide2019,
  title = {Artificial Intelligence: A Guide for Thinking Humans},
  shorttitle = {Artificial Intelligence},
  author = {Mitchell, Melanie},
  date = {2019},
  publisher = {{Farrar, Straus and Giroux}},
  location = {{New York}},
  abstract = {No recent scientific enterprise has proved as alluring, terrifying, and filled with extravagant promise and frustrating setbacks as artificial intelligence. An award-winning author and leading computer scientist reveals its turbulent history and the recent surge of successes, grand hopes, and emerging fears that surround AI},
  isbn = {978-0-374-71523-6},
  langid = {english},
  annotation = {OCLC: 1123193049},
  file = {/home/ms/Zotero/storage/V8Q55H5L/Melanie Mitchell - Artificial Intelligence_ A Guide for Thinking Humans-Farrar, Straus and Giroux (2019).epub}
}

@book{molnar10LearnedFeatures,
  title = {10.1 {{Learned Features}} | {{Interpretable Machine Learning}}},
  author = {Molnar, Christoph},
  url = {https://christophm.github.io/interpretable-ml-book/cnn-features.html},
  urldate = {2023-03-04},
  abstract = {Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable.},
  file = {/home/ms/Zotero/storage/GBV8TJV6/cnn-features.html}
}

@article{murphyWhyStanfordResearchers2017,
  title = {Why {{Stanford Researchers Tried}} to {{Create}} a ‚Äò{{Gaydar}}‚Äô {{Machine}}},
  author = {Murphy, Heather},
  date = {2017-10-09},
  journaltitle = {The New York Times},
  issn = {0362-4331},
  url = {https://www.nytimes.com/2017/10/09/science/stanford-sexual-orientation-study.html},
  urldate = {2023-03-08},
  abstract = {Scientists worried that facial recognition software could be used to detect sexual orientation. Their efforts to raise an alarm caused an uproar.},
  entrysubtype = {newspaper},
  journalsubtitle = {Science},
  langid = {american},
  keywords = {Artificial Intelligence,Computer Vision,Computers and the Internet,Face,Homosexuality and Bisexuality,Journal of Personality and Social Psychology,Kosinski; Michal,Privacy,Psychology and Psychologists,Stanford University,Wang; Yilun},
  file = {/home/ms/Zotero/storage/TK25TTZD/stanford-sexual-orientation-study.html}
}

@online{NutzungsbedingungenInstagramHilfebereich,
  title = {Nutzungsbedingungen | {{Instagram-Hilfebereich}}},
  url = {https://help.instagram.com/581066165581870},
  urldate = {2023-03-17},
  file = {/home/ms/Zotero/storage/4N8AD79X/581066165581870.html}
}

@article{olahFeatureVisualization2017,
  title = {Feature {{Visualization}}},
  author = {Olah, Chris and Mordvintsev, Alexander and Schubert, Ludwig},
  date = {2017-11-07},
  journaltitle = {Distill},
  shortjournal = {Distill},
  volume = {2},
  number = {11},
  pages = {e7},
  issn = {2476-0757},
  doi = {10.23915/distill.00007},
  url = {https://distill.pub/2017/feature-visualization},
  urldate = {2022-01-16},
  abstract = {How neural networks build up their understanding of images},
  langid = {english}
}

@unpublished{oordWaveNetGenerativeModel2016,
  title = {{{WaveNet}}: {{A Generative Model}} for {{Raw Audio}}},
  shorttitle = {{{WaveNet}}},
  author = {van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  date = {2016-09-19},
  eprint = {1609.03499},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1609.03499},
  urldate = {2022-01-24},
  abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-ofthe-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Computer Science - Sound},
  file = {/home/ms/Zotero/storage/SIAAXZCB/Oord et al. - 2016 - WaveNet A Generative Model for Raw Audio.pdf}
}

@online{OpenAIAPI,
  title = {{{OpenAI API}}},
  url = {https://openai.com/blog/openai-api},
  urldate = {2023-04-03},
  abstract = {We‚Äôre releasing an API for accessing new AI models developed by OpenAI.},
  langid = {american},
  file = {/home/ms/Zotero/storage/JUKBUMZ4/openai-api.html}
}

@online{openaiBetterLanguageModels,
  title = {Better Language Models and Their Implications},
  author = {OpenAI},
  url = {https://openai.com/research/better-language-models},
  urldate = {2023-04-01},
  abstract = {We‚Äôve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading comprehension, machine translation, question answering, and summarization‚Äîall without task-specific~training.},
  langid = {american},
  file = {/home/ms/Zotero/storage/KTI2H5J9/better-language-models.html}
}

@online{OpenAIGPT3Language2020,
  title = {{{OpenAI}}'s {{GPT-3 Language Model}}: {{A Technical Overview}}},
  shorttitle = {{{OpenAI}}'s {{GPT-3 Language Model}}},
  date = {2020-06-03},
  url = {https://lambdalabs.com/blog/demystifying-gpt-3},
  urldate = {2023-04-03},
  abstract = {Chuan Li, PhD reviews  GPT-3, the new NLP model from OpenAI. This paper empirically shows that language model performance scales as a power-law with model size, datataset size, and the amount of computation.},
  langid = {english},
  file = {/home/ms/Zotero/storage/88HKU5DJ/demystifying-gpt-3.html}
}

@online{OpenFutureOpen,
  title = {Open {{Future}} ‚Äì {{Open Future Foundation}}},
  url = {https://openfuture.eu},
  urldate = {2023-03-13},
  abstract = {Open Future is a think tank that develops new approaches to an open internet that maximize societal benefits of shared data, knowledge and culture.},
  langid = {american},
  organization = {{Open Future}},
  file = {/home/ms/Zotero/storage/WSLMEAZC/openfuture.eu.html}
}

@inproceedings{panayotovLibrispeechASRCorpus2015,
  title = {Librispeech: {{An ASR}} Corpus Based on Public Domain Audio Books},
  shorttitle = {Librispeech},
  booktitle = {2015 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  author = {Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  date = {2015-04},
  pages = {5206--5210},
  publisher = {{IEEE}},
  location = {{South Brisbane, Queensland, Australia}},
  doi = {10.1109/ICASSP.2015.7178964},
  url = {http://ieeexplore.ieee.org/document/7178964/},
  urldate = {2022-01-21},
  abstract = {This paper introduces a new corpus of read English speech, suitable for training and evaluating speech recognition systems. The LibriSpeech corpus is derived from audiobooks that are part of the LibriVox project, and contains 1000 hours of speech sampled at 16 kHz. We have made the corpus freely available for download, along with separately prepared language-model training data and pre-built language models. We show that acoustic models trained on LibriSpeech give lower error rate on the Wall Street Journal (WSJ) test sets than models trained on WSJ itself. We are also releasing Kaldi scripts that make it easy to build these systems.},
  eventtitle = {{{ICASSP}} 2015 - 2015 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})},
  isbn = {978-1-4673-6997-8},
  langid = {english},
  file = {/home/ms/Zotero/storage/B6C6XH92/Panayotov et al. - 2015 - Librispeech An ASR corpus based on public domain .pdf}
}

@article{pasquinelliArborescentMindIntelligence,
  title = {The {{Arborescent Mind}}: {{The Intelligence}} of an {{Inverted Tree}}},
  shorttitle = {The {{Arborescent Mind}}},
  author = {Pasquinelli, Matteo},
  url = {https://www.academia.edu/27431916/The_Arborescent_Mind_The_Intelligence_of_an_Inverted_Tree},
  urldate = {2022-01-29},
  abstract = {The aim of this text is not to prove a linear academic thesis, yet to record a spectrum of homologies and resonances across the history of the tree as a symbolic and logic form. The inspiration for this sort of Warburgian excursus comes from the},
  langid = {english},
  file = {/home/ms/Zotero/storage/FZ4LMNN4/The_Arborescent_Mind_The_Intelligence_of.pdf;/home/ms/Zotero/storage/K2R9DGW7/27431916.html}
}

@book{pavlovConditionedReflexesInvestigation1927,
  title = {Conditioned Reflexes: An Investigation of the Physiological Activity of the Cerebral Cortex},
  shorttitle = {Conditioned Reflexes},
  author = {Pavlov, I. P.},
  date = {1927},
  series = {Conditioned Reflexes: An Investigation of the Physiological Activity of the Cerebral Cortex},
  pages = {xv, 430},
  publisher = {{Oxford Univ. Press}},
  location = {{Oxford, England}},
  abstract = {The present volume is the first complete discussion of conditioned reflexes to be translated into one of the more familiar European languages. It contains 23 lectures, most of which were delivered in the spring of 1924 at the Military Medical Academy in Leningrad. After an initial discussion of historical background and of the technical methods employed, Pavlov discusses the following topics: the formation of conditioned reflexes by means of conditioned and direct stimuli; external and internal inhibition of conditioned reflexes; the analyzing and synthesizing activity of the cerebral hemisphere; irradiation and concentration of nervous processes in the cerebral cortex; mutual induction of excitation and inhibition; interaction of irradiation and concentration with induction; the cortex as a mosaic of functions; development of inhibition in the cortex under the influence of conditioned stimuli; internal inhibition and sleep as one and the same process with regard to their intimate mechanism; transition stages between the alert state and complete sleep-hypnotic stages; different types of nervous system; pathological disturbances of the cortex, result of functional and surgical interference; general characteristics of the present investigation and its special difficulties; discovery of certain errors necessitating the modification of some earlier interpretations; and the experimental results obtained with animals in their application to man. Attention is drawn to the similarity of the neuroses and psychoses to behavior observed in the dog during certain of the experiments. A bibliography is given of all papers published from Pavlov's laboratories upon the physiology of conditioned reflexes. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  pagetotal = {xv, 430},
  file = {/home/ms/Zotero/storage/ECG4SZ7U/1927-02531-000.html}
}

@article{pierceHowAppleFinally,
  title = {How {{Apple Finally Made Siri Sound More Human}}},
  author = {Pierce, David},
  journaltitle = {Wired},
  issn = {1059-1028},
  url = {https://www.wired.com/story/how-apple-finally-made-siri-sound-more-human/},
  urldate = {2022-01-23},
  abstract = {If Apple can make Siri sound less like a robot and more like someone you know and trust, it can make the virtual assistant great‚Äîeven when it fails.},
  entrysubtype = {magazine},
  langid = {american},
  keywords = {apple,artificial intelligence,iphone,siri},
  file = {/home/ms/Zotero/storage/JVSU5RMD/how-apple-finally-made-siri-sound-more-human.html}
}

@audio{PoliticiansDiscussingLyrebird,
  title = {Politicians discussing about Lyrebird},
  url = {https://soundcloud.com/user-535691776/dialog},
  urldate = {2022-01-24},
  abstract = {Listen to Politicians discussing about Lyrebird by Lyrebird \#np on \#SoundCloud},
  langid = {ngerman},
  file = {/home/ms/Zotero/storage/74TDKLTL/dialog.html}
}

@online{reaHowImageNetRoulette2019,
  title = {How {{ImageNet Roulette}}, a {{Viral Art Project That Exposed Facial Recognition}}'s {{Biases}}, {{Is Changing Minds About AI}}},
  author = {Rea, Naomi},
  date = {2019-09-23T14:38:28+00:00},
  url = {https://news.artnet.com/art-world/imagenet-roulette-trevor-paglen-kate-crawford-1658305},
  urldate = {2023-03-11},
  abstract = {An art project by Trevor Paglen and researcher Kate Crawford exposes the prejudices in facial recognition technology.},
  langid = {american},
  organization = {{Artnet News}},
  file = {/home/ms/Zotero/storage/3UXPIFJ9/imagenet-roulette-trevor-paglen-kate-crawford-1658305.html}
}

@article{rosenblattPerceptronProbabilisticModel1958,
  title = {The Perceptron: {{A}} Probabilistic Model for Information Storage and Organization in the Brain.},
  shorttitle = {The Perceptron},
  author = {Rosenblatt, F.},
  date = {1958},
  journaltitle = {Psychological Review},
  shortjournal = {Psychological Review},
  volume = {65},
  number = {6},
  pages = {386--408},
  issn = {1939-1471, 0033-295X},
  doi = {10.1037/h0042519},
  url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0042519},
  urldate = {2023-03-04},
  langid = {english}
}

@online{RuDALLE,
  title = {{{ruDALL-E}}},
  url = {http://rudalle.ru/en/},
  urldate = {2022-04-28},
  abstract = {Look, which image generated ruDALL-E},
  langid = {english},
  organization = {{ruDALL-E}},
  file = {/home/ms/Zotero/storage/HJQAD2IN/en.html}
}

@online{samlavigneJustDiscoveredOpen2020,
  type = {Tweet},
  title = {Just Discovered an Open Source Hair Detector and Have Used It on Hundreds of Images of {{Mark Zuckerberg}} to Build What {{I}} Believe Is the Most Comprehensive Archive of {{Zuckerberg}} Haircuts in Existence. {{Thank}} You {{AI}} Researchers! {{https://t.co/QJqXLAbqyw}}},
  author = {{Sam Lavigne}},
  date = {2020-02-16T17:38Z},
  url = {https://twitter.com/sam_lavigne/status/1229097648818446336},
  urldate = {2023-03-17},
  langid = {english},
  organization = {{Twitter}},
  file = {/home/ms/Zotero/storage/K3AHVG5B/1229097648818446336.html}
}

@online{schaferDogggArt,
  title = {Doggg.Art},
  author = {Sch√§fer, Matthias},
  url = {https://doggg.art/},
  urldate = {2023-03-17},
  langid = {english},
  organization = {{doggg.art}},
  file = {/home/ms/Zotero/storage/SR6896E7/doggg.art.html}
}

@online{schaferMissingPictures,
  title = {Missing.Pictures},
  shorttitle = {Https},
  author = {Sch√§fer, Matthias},
  url = {https://missing.pictures/},
  urldate = {2023-03-17},
  file = {/home/ms/Zotero/storage/F7MVY3WB/missing.pictures.html}
}

@online{schaferThisPersonDoes,
  title = {This {{Person Does Exist}}},
  author = {Sch√§fer, Matthias},
  url = {https://this-person-does-exist.com},
  urldate = {2023-03-15},
  abstract = {This Person Does Exist and was used by Nvidia to create their StyleGAN model.},
  langid = {english},
  file = {/home/ms/Zotero/storage/Q9GMG8RR/this-person-does-exist.com.html}
}

@article{schaferThisPersonDoes2021,
  title = {This {{Person Does Exist}}},
  author = {Sch√§fer, Matthias},
  date = {2021-07-22},
  journaltitle = {Temes de Disseny},
  shortjournal = {TdD},
  number = {37},
  pages = {214--225},
  issn = {2604-6032, 2604-9155},
  doi = {10.46467/TdD37.2021.214-225},
  url = {https://raco.cat/index.php/Temes/article/view/390550},
  urldate = {2023-03-09},
  abstract = {Computer Vision, Creative Commons, Dataset Art, Data Mining, Machine Learning, Photography.},
  langid = {english},
  file = {/home/ms/Zotero/storage/VR9ZY795/Sch√§fer - 2021 - This Person Does Exist.pdf}
}

@book{serexheWolfgangKempelenMan2007,
  title = {Wolfgang von Kempelen: Man-(in the)-Machine = Wolfgang von Kempelen: Mensch-(in der)-Maschine},
  shorttitle = {Wolfgang von Kempelen},
  editor = {Serexhe, Bernhard and Weibel, Peter and von Kempelen, Wolfgang and Zentrum f√ºr Kunst und Medientechnologie Karlsruhe},
  date = {2007},
  publisher = {{Matthes \& Seitz}},
  location = {{Berlin}},
  isbn = {978-3-88221-997-5},
  langid = {ger eng},
  pagetotal = {111},
  file = {/home/ms/Zotero/storage/LHMDMRQR/Serexhe et al. - 2007 - Wolfgang von Kempelen Man-(in the)-Machine = Wolf.pdf}
}

@article{shipmanAnimalConnectionHuman2010,
  title = {The {{Animal Connection}} and {{Human Evolution}}},
  author = {Shipman, Pat},
  date = {2010-08},
  journaltitle = {Current Anthropology},
  shortjournal = {Current Anthropology},
  volume = {51},
  number = {4},
  pages = {519--538},
  issn = {0011-3204, 1537-5382},
  doi = {10.1086/653816},
  url = {https://www.journals.uchicago.edu/doi/10.1086/653816},
  urldate = {2022-01-22},
  langid = {english},
  file = {/home/ms/Zotero/storage/4TZ6ZMKQ/Shipman - 2010 - The Animal Connection and Human Evolution.pdf}
}

@article{simonitePaperThatLed,
  title = {Behind the {{Paper That Led}} to a {{Google Researcher}}‚Äôs {{Firing}}},
  author = {Simonite, Tom},
  journaltitle = {Wired},
  issn = {1059-1028},
  url = {https://www.wired.com/story/behind-paper-led-google-researchers-firing/},
  urldate = {2023-04-03},
  abstract = {Timnit Gebru was one of seven authors on a study that examined prior research on training artificial intelligence models to understand language.},
  entrysubtype = {magazine},
  langid = {american},
  keywords = {algorithms,artificial intelligence,deep learning,google,machine learning},
  file = {/home/ms/Zotero/storage/MS2KZKGE/behind-paper-led-google-researchers-firing.html}
}

@unpublished{simonyanDeepConvolutionalNetworks2014,
  title = {Deep {{Inside Convolutional Networks}}: {{Visualising Image Classification Models}} and {{Saliency Maps}}},
  shorttitle = {Deep {{Inside Convolutional Networks}}},
  author = {Simonyan, Karen and Vedaldi, Andrea and Zisserman, Andrew},
  date = {2014-04-19},
  eprint = {1312.6034},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1312.6034},
  urldate = {2022-01-20},
  abstract = {This paper addresses the visualisation of image classification models, learnt using deep Convolutional Networks (ConvNets). We consider two visualisation techniques, based on computing the gradient of the class score with respect to the input image. The first one generates an image, which maximises the class score [Erhan et al., 2009], thus visualising the notion of the class, captured by a ConvNet. The second technique computes a class saliency map, specific to a given image and class. We show that such maps can be employed for weakly supervised object segmentation using classification ConvNets. Finally, we establish the connection between the gradient-based ConvNet visualisation methods and deconvolutional networks [Zeiler et al., 2013].},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/ms/Zotero/storage/4F2FSXI8/Simonyan et al. - 2014 - Deep Inside Convolutional Networks Visualising Im.pdf;/home/ms/Zotero/storage/PTL4QYUJ/1312.html}
}

@online{simonyanVeryDeepConvolutional2015,
  title = {Very {{Deep Convolutional Networks}} for {{Large-Scale Image Recognition}}},
  author = {Simonyan, Karen and Zisserman, Andrew},
  date = {2015-04-10},
  number = {arXiv:1409.1556},
  eprint = {arXiv:1409.1556},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1409.1556},
  urldate = {2023-04-04},
  abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 √ó 3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16‚Äì19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/ms/Zotero/storage/QCMFTYYX/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf}
}

@online{stattAdobeWorkingAudio2016,
  title = {Adobe Is Working on an Audio App That Lets You Add Words Someone Never Said},
  author = {Statt, Nick},
  date = {2016-11-03T18:30:45-04:00},
  url = {https://www.theverge.com/2016/11/3/13514088/adobe-photoshop-audio-project-voco},
  urldate = {2022-01-24},
  abstract = {Adobe is working on a new piece of software that would act like a Photoshop for audio, according to Adobe developer Zeyu Jin, who spoke at the Adobe MAX conference in San Diego, California today....},
  langid = {english},
  organization = {{The Verge}},
  file = {/home/ms/Zotero/storage/J7K68F8M/adobe-photoshop-audio-project-voco.html}
}

@article{stuppFraudstersUsedAI2019,
  title = {Fraudsters {{Used AI}} to {{Mimic CEO}}‚Äôs {{Voice}} in {{Unusual Cybercrime Case}}},
  author = {Stupp, Catherine},
  date = {2019-08-30T16:52:00},
  journaltitle = {Wall Street Journal},
  issn = {0099-9660},
  url = {https://www.wsj.com/articles/fraudsters-use-ai-to-mimic-ceos-voice-in-unusual-cybercrime-case-11567157402},
  urldate = {2022-01-24},
  abstract = {Criminals used artificial intelligence-based software to impersonate a chief executive‚Äôs voice and demand a fraudulent transfer of funds in March in what cybercrime experts described as an unusual case of artificial intelligence being used in hacking.},
  entrysubtype = {newspaper},
  journalsubtitle = {WSJ Pro},
  langid = {american},
  keywords = {artificial intelligence,Artificial Intelligence/Machine Learning,Bobby Filar,business in europe,Business in Europe,business in the u.k.,Business in the U.K.,c&e executive news filter,C&E Executive News Filter,c&e industry news filter,C&E Industry News Filter,computer science,Computer Science,content types,Content Types,corporate,corporate crime,Corporate Crime/Legal Action,Corporate/Industrial News,crime,Crime/Legal Action,cybercrime,Cybercrime/Hacking,Euler Hermes Group,factiva filters,Factiva Filters,financial services,Financial Services,fraud,Fraud,general news,hacking,humanities,industrial news,insurance,Insurance,Irakli Beridze,legal action,machine learning,management,Management,non-life insurance,Non-life Insurance,Philipp Amann,political,Political/General News,PRO,R√ºdiger Kirsch,sciences,Sciences/Humanities,senior level management,Senior Level Management,trade credit insurance,Trade Credit Insurance,WSJ-PRO-CYBER,WSJ-PRO-WSJ.com},
  file = {/home/ms/Zotero/storage/5CAVQB44/fraudsters-use-ai-to-mimic-ceos-voice-in-unusual-cybercrime-case-11567157402.html}
}

@inproceedings{tappertWhoFatherDeep2019,
  title = {Who {{Is}} the {{Father}} of {{Deep Learning}}?},
  booktitle = {2019 {{International Conference}} on {{Computational Science}} and {{Computational Intelligence}} ({{CSCI}})},
  author = {Tappert, Charles C.},
  date = {2019-12},
  pages = {343--348},
  publisher = {{IEEE}},
  location = {{Las Vegas, NV, USA}},
  doi = {10.1109/CSCI49370.2019.00067},
  url = {https://ieeexplore.ieee.org/document/9070967/},
  urldate = {2023-03-04},
  eventtitle = {2019 {{International Conference}} on {{Computational Science}} and {{Computational Intelligence}} ({{CSCI}})},
  isbn = {978-1-72815-584-5},
  file = {/home/ms/Zotero/storage/9NNUBJ5P/Tappert - 2019 - Who Is the Father of Deep Learning.pdf}
}

@inproceedings{tatmanGenderDialectBias2017,
  title = {Gender and {{Dialect Bias}} in {{YouTube}}'s {{Automatic Captions}}},
  booktitle = {Proceedings of the {{First ACL Workshop}} on {{Ethics}} in {{Natural Language Processing}}},
  author = {Tatman, Rachael},
  date = {2017},
  pages = {53--59},
  publisher = {{Association for Computational Linguistics}},
  location = {{Valencia, Spain}},
  doi = {10.18653/v1/W17-1606},
  url = {http://aclweb.org/anthology/W17-1606},
  urldate = {2022-01-20},
  abstract = {This project evaluates the accuracy of YouTube‚Äôs automatically-generated captions across two genders and five dialects of English. Speakers‚Äô dialect and gender was controlled for by using videos uploaded as part of the ‚Äúaccent tag challenge‚Äù, where speakers explicitly identify their language background. The results show robust differences in accuracy across both gender and dialect, with lower accuracy for 1) women and 2) speakers from Scotland. This finding builds on earlier research finding that speaker‚Äôs sociolinguistic identity may negatively impact their ability to use automatic speech recognition, and demonstrates the need for sociolinguistically-stratified validation of systems.},
  eventtitle = {Proceedings of the {{First ACL Workshop}} on {{Ethics}} in {{Natural Language Processing}}},
  langid = {english},
  file = {/home/ms/Zotero/storage/8JEA4XT7/Tatman - 2017 - Gender and Dialect Bias in YouTube's Automatic Cap.pdf}
}

@online{TechnicallyResponsibleKnowledge,
  title = {Technically {{Responsible Knowledge}}},
  url = {http://trk.network/essay},
  urldate = {2023-03-10},
  abstract = {TRK "technically responsible knowledge" is a platform for data labelling and AI/ML training. Unlike other services, crowd-sourced workers and workers can set fair prices on this platform towards a living wage. TRK is open source, and offered under the MIT license.},
  langid = {english},
  file = {/home/ms/Zotero/storage/2X4YPWAN/essay.html}
}

@online{ThisPersonDoes2019,
  title = {This {{Person Does Not Exist}}},
  date = {2019-05-31},
  url = {https://web.archive.org/web/20190531222303/https://thispersondoesnotexist.com/},
  urldate = {2023-03-15},
  file = {/home/ms/Zotero/storage/KHCRYEGZ/thispersondoesnotexist.com.html}
}

@online{tykaDeepdreamInceptionismRecap,
  title = {Deepdream/{{Inceptionism}} - Recap},
  author = {Tyka, Mike},
  url = {http://mtyka.github.io/code/2015/07/21/one-month-after-deepdream.html},
  urldate = {2023-03-04},
  file = {/home/ms/Zotero/storage/X7DPTBZW/one-month-after-deepdream.html}
}

@online{vaswaniAttentionAllYou2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  date = {2017-12-05},
  number = {arXiv:1706.03762},
  eprint = {arXiv:1706.03762},
  eprinttype = {arxiv},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2023-03-31},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  langid = {english},
  pubstate = {preprint},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/home/ms/Zotero/storage/SJ5JPRJR/Vaswani et al. - 2017 - Attention Is All You Need.pdf}
}

@book{vlahosTalkMeAmazon2020,
  title = {Talk to Me: {{Amazon}}, {{Google}}, {{Apple}} and the Race for Voice-Controlled {{AI}}},
  shorttitle = {Talk to Me},
  author = {Vlahos, James},
  date = {2020},
  abstract = {The next great technological disruption is coming. The titans of Silicon Valley are racing to build the last, best computer that the world will ever need. They know that whoever successfully creates it will revolutionise our relationship with technology and make billions of dollars in the process. They call it conversational AI. Computers that can speak and think like humans do may seem like the stuff of science fiction, but they are rapidly moving towards reality. In Talk to Me, veteran tech journalist James Vlahos meets the researchers at Google, Amazon and Apple who are leading the way to a voice computing revolution. He explores how voice tech will transform every sector of society handing untold new powers to businesses, upending traditional notions of privacy, revolutionising access to information, and fundamentally altering the way we understand human consciousness. And he even tries to understand the significance of the revolution firsthand - by building a chatbot version of his terminally ill father. Vlahos's research leads him to one fundamental question: What happens when our computers become as articulate, compassionate, and creative as we are?},
  isbn = {978-1-84794-264-7},
  langid = {english},
  annotation = {OCLC: 1148063381}
}

@article{wangDefiningArtificialIntelligence2019,
  title = {On {{Defining Artificial Intelligence}}},
  author = {Wang, Pei},
  date = {2019-01-01},
  journaltitle = {Journal of Artificial General Intelligence},
  shortjournal = {Journal of Artificial General Intelligence},
  volume = {10},
  pages = {1--37},
  doi = {10.2478/jagi-2019-0002},
  abstract = {This article systematically analyzes the problem of defining ‚Äúartificial intelligence.‚Äù It starts by pointing out that a definition influences the path of the research, then establishes four criteria of a good working definition of a notion: being similar to its common usage, drawing a sharp boundary, leading to fruitful research, and as simple as possible. According to these criteria, the representative definitions in the field are analyzed. A new definition is proposed, according to it intelligence means ‚Äúadaptation with insufficient knowledge and resources.‚Äù The implications of this definition are discussed, and it is compared with the other definitions. It is claimed that this definition sheds light on the solution of many existing problems and sets a sound foundation for the field.},
  file = {/home/ms/Zotero/storage/VXAT5EST/Wang - 2019 - On Defining Artificial Intelligence.pdf}
}

@unpublished{wanGeneralizedEndtoEndLoss2020,
  title = {Generalized {{End-to-End Loss}} for {{Speaker Verification}}},
  author = {Wan, Li and Wang, Quan and Papir, Alan and Moreno, Ignacio Lopez},
  date = {2020-11-09},
  eprint = {1710.10467},
  eprinttype = {arxiv},
  eprintclass = {cs, eess, stat},
  url = {http://arxiv.org/abs/1710.10467},
  urldate = {2022-01-26},
  abstract = {In this paper, we propose a new loss function called generalized end-to-end (GE2E) loss, which makes the training of speaker verification models more efficient than our previous tuple-based endto-end (TE2E) loss function. Unlike TE2E, the GE2E loss function updates the network in a way that emphasizes examples that are difficult to verify at each step of the training process. Additionally, the GE2E loss does not require an initial stage of example selection. With these properties, our model with the new loss function decreases speaker verification EER by more than 10\%, while reducing the training time by 60\% at the same time. We also introduce the MultiReader technique, which allows us to do domain adaptation ‚Äîtraining a more accurate model that supports multiple keywords (i.e., ‚ÄúOK Google‚Äù and ‚ÄúHey Google‚Äù) as well as multiple dialects.},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Audio and Speech Processing,Statistics - Machine Learning},
  file = {/home/ms/Zotero/storage/KWSS9QLC/Wan et al. - 2020 - Generalized End-to-End Loss for Speaker Verificati.pdf}
}

@unpublished{wangTacotronEndtoEndSpeech2017,
  title = {Tacotron: {{Towards End-to-End Speech Synthesis}}},
  shorttitle = {Tacotron},
  author = {Wang, Yuxuan and Skerry-Ryan, R. J. and Stanton, Daisy and Wu, Yonghui and Weiss, Ron J. and Jaitly, Navdeep and Yang, Zongheng and Xiao, Ying and Chen, Zhifeng and Bengio, Samy and Le, Quoc and Agiomyrgiannakis, Yannis and Clark, Rob and Saurous, Rif A.},
  date = {2017-04-06},
  eprint = {1703.10135},
  eprinttype = {arxiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1703.10135},
  urldate = {2022-01-24},
  abstract = {A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module. Building these components often requires extensive domain expertise and may contain brittle design choices. In this paper, we present Tacotron, an end-to-end generative text-to-speech model that synthesizes speech directly from characters. Given {$<$}text, audio{$>$} pairs, the model can be trained completely from scratch with random initialization. We present several key techniques to make the sequence-tosequence framework perform well for this challenging task. Tacotron achieves a 3.82 subjective 5-scale mean opinion score on US English, outperforming a production parametric system in terms of naturalness. In addition, since Tacotron generates speech at the frame level, it‚Äôs substantially faster than sample-level autoregressive methods.},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound},
  file = {/home/ms/Zotero/storage/8LBZTJI6/Wang et al. - 2017 - Tacotron Towards End-to-End Speech Synthesis.pdf}
}

@online{WaveNetLaunchesGoogle,
  title = {WaveNet launches in the Google Assistant},
  url = {https://deepmind.com/blog/article/wavenet-launches-google-assistant},
  urldate = {2022-01-24},
  abstract = {Just over a year ago we presented WaveNet, a new deep neural network for generating raw audio waveforms that is capable of producing better and more realistic-sounding speech than existing techniques. At that time, the model was a research prototype and was too computationally intensive to work in consumer products. ~But over the last 12 months we have worked hard to significantly improve both the speed and quality of our model and today we are proud to announce that an updated version of WaveNet is being used to generate the Google Assistant voices for US English and Japanese across all platforms.Using the new WaveNet model results in a range of more natural sounding voices for the Assistant.},
  langid = {ALL},
  organization = {{Deepmind}},
  file = {/home/ms/Zotero/storage/45Z2BUJB/wavenet-launches-google-assistant.html}
}

@online{weibelAAA,
  title = {AAA},
  author = {Weibel, Peter},
  url = {https://www.kunstforum.de/artikel/aaa/},
  urldate = {2022-01-16},
  abstract = {AAA Art, Algorithmen, Artificial Intelligence von Peter Weibel K√ºnstliche Intelligenz (K.I.) bzw. Artificial Intelligence (A.I.) gibt es nicht. Aber ein Ensemble von Maschinen, Medien, Programmen, Algorithmen, Hardware und Software hat zu einem au√üerordentlich gro√üen, vielteiligen und produktiven Forschungsfeld gef√ºhrt, das A.I. genannt wird. Anl√§sslich einer Konferenz im Dartmouth College haben 1956 John McCarthy und Marvin ‚Ä¶ Continued},
  langid = {ngerman},
  organization = {{www.kunstforum.de}},
  file = {/home/ms/Zotero/storage/3MJK7YXC/aaa.html}
}

@book{weizenbaumComputerPowerHuman1976,
  title = {Computer Power and Human Reason: From Judgment to Calculation},
  shorttitle = {Computer Power and Human Reason},
  author = {Weizenbaum, Joseph},
  date = {1976},
  publisher = {{W. H. Freeman}},
  location = {{San Francisco}},
  isbn = {978-0-7167-0464-5},
  pagetotal = {300},
  keywords = {Computer programming,Computers,Computers and civilization},
  file = {/home/ms/Zotero/storage/P4RA6HBD/Joseph Weizenbaum - Computer Power and Human Reason_ From Judgement to Calculation-W.H.Freeman & Co Ltd (1976).djvu}
}

@software{woolfGpt2simple2023,
  title = {Gpt-2-Simple},
  author = {Woolf, Max},
  date = {2023-04-04T14:30:43Z},
  origdate = {2019-04-13T20:00:52Z},
  url = {https://github.com/minimaxir/gpt-2-simple},
  urldate = {2023-04-04},
  abstract = {Python package to easily retrain OpenAI's GPT-2 text-generating model on new texts},
  keywords = {openai,tensorflow,text-generation,textgenrnn}
}

@online{xiangHeWouldStill2023,
  title = {'{{He Would Still Be Here}}': {{Man Dies}} by {{Suicide After Talking}} with {{AI Chatbot}}, {{Widow Says}}},
  shorttitle = {'{{He Would Still Be Here}}'},
  author = {Xiang, Chloe},
  date = {2023-03-30T19:59:35},
  url = {https://www.vice.com/en/article/pkadgm/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says},
  urldate = {2023-04-04},
  abstract = {The incident raises concerns about guardrails around quickly-proliferating conversational AI models.},
  langid = {english},
  organization = {{Vice}},
  keywords = {AI chatbots,AI ethics,ELIZA,Gpt,Worldnews},
  file = {/home/ms/Zotero/storage/U4M3HRJL/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says.html}
}

@online{XTRAMarkHansen,
  title = {X-{{TRA}} ‚Üí {{Mark Hansen}} and {{Ben Rubin}}: {{Listening Post}}},
  url = {https://www.x-traonline.org/article/mark-hansen-and-ben-rubin-listening-post},
  urldate = {2023-03-20},
  file = {/home/ms/Zotero/storage/7BKLDS2K/mark-hansen-and-ben-rubin-listening-post.html}
}

@book{zarkadakesOurOwnImage2016,
  title = {In Our Own Image: Savior or Destroyer?: The History and Future of Artificial Intelligence},
  shorttitle = {In Our Own Image},
  author = {Zarkadakƒìs, Gi≈çrgos},
  date = {2016},
  edition = {First Pegasus books hardcover edition},
  publisher = {{Pegasus Books LLC}},
  location = {{New York, NY}},
  isbn = {978-1-60598-964-8 978-1-84604-435-9 978-1-84604-436-6 978-1-84604-437-3 978-1-5046-8648-8},
  pagetotal = {362},
  keywords = {Artificial intelligence,Computers and civilization,Human-computer interaction,Machine theory,Popular works,Social aspects},
  annotation = {OCLC: ocn911364564}
}
